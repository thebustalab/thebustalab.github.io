--- 
title: "Integrated Bioanalytics"
author: "Lucas Busta and members of the Busta lab"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: krantz
bibliography: [book.bib, packages.bib]
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  Integrated Bioanalytics is a book describing how to perform chemical, phylogenetic, and genomic analyses.
biblio-style: apalike
csl: chicago-fullnote-bibliography.csl
output:
  bookdown::bs4_book:
    theme:
      primary: "#3860b6" #links  
      base_font: 
        google: 
          family: Lato
      heading_font:
        google:
          family: Montserrat
          wght: 600
      code_font:
        google: 
          family: Roboto Mono
      bg: "#fefefe" #backgrounds
      fg: "#000000" #fonts
    repo: 
      base: https://github.com/thebustalab/thebustalab.github.io/tree/master/integrated_bioanalytics
      branch: main
    includes:
      in_header: style/ga.html
    template: style/bs4_book.html
    css: style/style.css
---

```{r setup, include=FALSE}
knitr:::opts_chunk$set(echo = TRUE, prompt = FALSE, eval = TRUE, 
                      warning = FALSE, comment = "##", cache = TRUE,
                      fig.width = 4, fig.height = 3, #results = "hide",
                      collapse = TRUE, results = 'markup', max.print = 6,
                      out.width = "100%", fig.align = "center")
  
options(pillar.sigfig = 3)
```

# WELCOME {-}

<!-- start preface-->
```{r fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), results="markup", fig.width = 2}
image_files <- c(
  "https://thebustalab.github.io/integrated_bioanalytics/images/cover1.png",
  "https://thebustalab.github.io/integrated_bioanalytics/images/cover2.png",
  "https://thebustalab.github.io/integrated_bioanalytics/images/cover3.png"
)
random_image <- sample(image_files, 1)
knitr:::include_graphics(random_image, dpi = NA)
```

Integrated Bioanalytics documents methods for analyzing chemical and sequence data in R as well as some basics of scientific writing. It is maintained by Lucas Busta and members of the Busta lab. To run the analyses described in this book you will need to run a source script that will set up your R environment with a variety of packages, custom functions, and datasets. If you don't have R, see "installation" under "Data Analysis In R" in the table of contents. Run the source script by pasting and executing the following in your R command line (RStudio recommended). If you are in the Busta Lab (or want access to full features), define an object `bustalab = TRUE` before running the source command. If you have trouble running the source script, please reach out to Lucas Busta at: bust0037@d.umn.edu. The source script: 

```{r, message = FALSE, eval = FALSE}
source("https://thebustalab.github.io/phylochemistry/phylochemistry.R")
```
```{r, message = FALSE, echo = FALSE}
bustalab <- TRUE
source("https://thebustalab.github.io/phylochemistry/phylochemistry.R")
```
________________________________________________________________________________________________
________________________________________________________________________________________________
________________________________________________________________________________________________

# (PART) GETTING STARTED 

```{r child="chapters/1_overview.Rmd"}
```

```{r child="chapters/2_installation.Rmd"}
```
________________________________________________________________________________________________
________________________________________________________________________________________________
________________________________________________________________________________________________

# (PART) DATA VISUALIZATION

```{r child="chapters/3_datavis_1.Rmd"}
```

```{r child="chapters/4_datavis_2.Rmd"}
```

```{r child="chapters/5_datavis_3.Rmd"}
```
________________________________________________________________________________________________
________________________________________________________________________________________________
________________________________________________________________________________________________

# (PART) STATISTICAL METHODS


```{r child="chapters/6_wrangling_summaries.Rmd"}
```

```{r child="chapters/7_hierarchical_clustering.Rmd"}
```

```{r child="chapters/8_dimensional_reduction.Rmd"}
```

```{r child="chapters/9_flat_clustering.Rmd"}
```

```{r child="chapters/10_comparing_means.Rmd"}
```

________________________________________________________________________________________________
________________________________________________________________________________________________
________________________________________________________________________________________________

# (PART) MODELS

```{r child="chapters/11_numerical_models.Rmd"}
```

```{r child="chapters/12_embedding_models.Rmd"}
```

________________________________________________________________________________________________
________________________________________________________________________________________________
________________________________________________________________________________________________

# (PART) SEQUENCE ANALYSIS {-}

```{r child="chapters/15_homology.Rmd"}
```

```{r child="chapters/16_alignments.Rmd"}
```

```{r child="chapters/17_phylogenies.Rmd"}
```

```{r child="chapters/18_phylogenetic_analysis.Rmd"}
```

________________________________________________________________________________________________
________________________________________________________________________________________________
________________________________________________________________________________________________


# (PART) ANALYTICAL REPORTS {-}

<!-- start WRITING -->

<!-- # overview {-} -->

<!-- For your final project in this course you will use the techniques we have learned in class to analyze a large dataset, prepare high quality figures, and write a miniature manuscript describing the results: -->

<!-- ```{r fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), results="markup"} -->
<!-- knitr:::include_graphics('https://thebustalab.github.io/integrated_bioanalytics/images/project_overview.png', dpi = NA) -->
<!-- ``` -->

<!-- 1. **Find a data set: Large!** >10ish variables, >5ish categories -->
<!-- + Sources: your research supervisor, CHEM5725 database spreadsheet, Google searches, Kaggle.com! -->
<!-- + Relevant to your research or interests (ideally). -->
<!-- + Requires approval from Dr. Busta. -->

<!-- 2. **Ask at least three scientific questions.** -->
<!-- + These should drive your data analyses. -->
<!-- + Requires approval from Dr. Busta. -->

<!-- 3. **Analyze your data using what you learned in class.** -->
<!-- + Refer to our book. -->
<!-- + Ask Dr. Busta for assistance. -->

<!-- 4. **Create a written overview of your analysis**. A mini-manuscript in R Markdown: -->
<!-- + *Content* similar to the articles we looked at in class, though shorter. -->
<!-- + *Layout* similar to this example ([pdf](https://github.com/thebustalab/thebustalab.github.io/blob/master/integrated_bioanalytics/final_project/final_project_example.pdf), [rmd](https://github.com/thebustalab/thebustalab.github.io/blob/master/integrated_bioanalytics/final_project/final_project_example.Rmd)). -->

<!-- ## scope {-} -->

<!-- When conducting a project of this type, it is very common for there to be mismatches in the scope of how the project was conducted and how the written report is presented (see image below). We often spend LOTS of time exploring our data and running into dead ends, conclusions that are mundane, or questions we can't answer. When we write a report on the project, we often focus the report of a specific discovery we made during our vast avenues of exploration, rather than boring the reader with all the mundane details. -->

<!-- ```{r fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), results="markup"} -->
<!-- knitr:::include_graphics('https://thebustalab.github.io/integrated_bioanalytics/images/scope.jpeg', dpi = NA) -->
<!-- ``` -->

<!-- ## order and content {-} -->

<!-- The manuscript will be comprised of a title, abstract, introduction, results and discussion section, figures and captions, conclusions section, and at least five references. Please note the following when preparing your manuscript: the orders of presentation and preparation do not have to be the same (see the images below)! While in some instances a scientist may choose to write the components of a manuscript in the same order in which they appear on the page, this is not always the case. The order of preparation suggsted above is designed to minimize the amount of revision / re-writing that needs to be performed during the manuscript preparation process. Note that the suggested order of composition is in line with the class schedule for the rest of the semester. -->

<!-- ```{r fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), results="markup"} -->
<!-- knitr:::include_graphics('https://thebustalab.github.io/integrated_bioanalytics/images/writing_order2.png', dpi = NA) -->
<!-- ``` -->

<!-- Here is a guide for documenting analysis in a format that is polished and comprehensible. Note that each section is written for a specific and slightly unique audience. Utilizing R Markdown, the document created will convey findings and narrate the research process. In crafting your R Markdown document, ensure that code remains concealed in the final presentation by including echo = FALSE within chunk headers. This action hides the R code blocks in the output, yet permits their execution for generating figures and results. -->

<!-- TITLE: Craft a title that’s both clear and descriptive. It should be accessible to specialists in the field as well as the wider scientific audience, avoiding overly technical language that might limit its broader appeal. -->

<!-- ABSTRACT: Summarize the study in the abstract, providing detail that will be informative to experts and also comprehensible to those outside the field. It should briefly outline the study’s aims, methods, key results, and conclusions, offering a snapshot of the entire project. -->

<!-- INTRODUCTION: In the introduction, present the context and significance of the research in a way that's understandable to researchers and those not as versed in the subject. Clearly enumerate the multiple research questions that the you aim to answer, highlighting the research's relevance and framing the inquiry. -->

<!-- METHODS: Describe where the dataset was sourced, any data processing steps taken, and provide a detailed description of the analysis procedures utilized in RStudio. This section should be detailed enough to allow for replication and validation, yet clearly written to be accessible to non-experts. The explanation of the methods should help readers understand how the research questions were addressed. -->

<!-- RESULTS AND DISCUSSION WITH FIGURES AND CAPTIONS: Integrate your findings with clear, illustrative figures and captions within this section, ensuring they can be understood independently of the text for visual learners. The written portion should concisely interpret the results in light of the research questions, discussing the significance of the findings in a way that appeals to both those interested in the analytical nuances and those seeking to understand the overall implications. -->

<!-- CONCLUSION: Summarize the primary insights and their relevance, keeping this section succinct and to the point. It should crystallize the main findings and their contribution to the field, suited for readers who seek a quick synopsis without delving into the full text. -->

<!-- REFERENCES: Include at least five references to substantiate your research, ensuring they are pertinent and formatted to facilitate easy follow-up for interested readers. The references should be organized to serve both as a trail for fellow researchers and a resource for those who are less experienced in the academic discourse. -->

<!-- ## scientific questions {-} -->

<!-- Scientific questions are pivotal in plant chemistry research, especially when examining the quantification of compounds in various plants, tissues, or environments. They orient the scope of inquiry and dictate the choice of analytical methods to draw pertinent conclusions from data. -->

<!-- DESCRIPTIVE questions might catalog the variety or concentration of phytochemicals present in a given species, often employing summary statistics to encapsulate the data: -->

<!-- - What is the average concentration of alkaloids found in the leaves of nightshade plants in temperate zones? -->

<!-- - How do the levels of flavonoids vary among different tissues of the grapevine? -->

<!-- - What is the frequency distribution of terpene profiles in pine populations across different altitudes? -->

<!-- CORRELATIVE questions investigate the relationships between environmental factors and chemical expression in plants, typically utilizing regression modeling: -->

<!-- - Does the level of UV radiation correlate with the production of protective anthocyanins in vineyard grape varieties? -->

<!-- - How is the accumulation of heavy metals in fern tissues related to soil pollution levels? -->

<!-- COMPARATIVE questions explore variations or consistencies across groups or conditions, often answered through statistical comparisons or pattern recognition methods like clustering: -->

<!-- - Which are more similar in their secondary metabolite profiles, medicinal herbs grown in greenhouse conditions or in the wild? -->

<!-- - What distinguishes the phenolic compound content in shade-grown coffee plants versus those grown in direct sunlight? -->

<!-- - Is there a significant difference in essential oil compositions between lavender plants cultivated in different soil types? -->

<!-- Unclear: How should social networking sites address the harm they cause?
Clear: What action should social networking sites like MySpace and Facebook take to protect users’ personal information and privacy?

The unclear version of this question doesn’t specify which social networking sites or suggest what kind of harm the sites might be causing. It also assumes that this “harm” is proven and/or accepted. The clearer version specifies sites (MySpace and Facebook), the type of potential harm (privacy issues), and who may be experiencing that harm (users). A strong research question should never leave room for ambiguity or interpretation.

Unfocused: What is the effect on the environment from global warming?
Focused: What is the most significant effect of glacial melting on the lives of penguins in Antarctica?

The unfocused research question is so broad that it couldn’t be adequately answered in a book-length piece, let alone a standard college-level paper. The focused version narrows down to a specific effect of global warming (glacial melting), a specific place (Antarctica), and a specific animal that is affected (penguins). It also requires the writer to take a stance on which effect has the greatest impact on the affected animal. When in doubt, make a research question as narrow and focused as possible.

Too simple: How are doctors addressing diabetes in the U.S.?
Appropriately Complex:  What main environmental, behavioral, and genetic factors predict whether Americans will develop diabetes, and how can these commonalities be used to aid the medical community in prevention of the disease? -->


# figures & captions {-}

## {-}

## figures {-}

One of the first components in preparing a scientific manuscript is creating high quality figures. Considering the following for your figures:

- General Appearance:

Create plots that are clean, professional, and easy to view from a distance. Ensure axes tick labels are clear, non-overlapping, and utilize the available space efficiently for enhanced readability and precision. Use an appealing (and color blind-friendly) color palette to differentiate data points or categories. Tailor axes labels to be descriptive, and select an appropriate theme that complements the data and maintains professionalism.

- Representing Data:

Appropriate Geoms and Annotations: Choose geoms that best represent the data and help the viewer evaluate the hypothesis or make the desired comparison. Include raw data points where possible for detailed data distribution understanding. Consider apply statistical transformations like smoothing lines or histograms where appropriate to provide deeper insights into the data. Consider using facets for visualizing multiple categories or groups, allowing for easier comparison while maintaining a consistent scale and layout. Adhere to specific standards or conventions relevant to your field, including the representation of data, error bars, or statistical significance markers.

```{r fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), results="markup"}
knitr:::include_graphics('https://thebustalab.github.io/integrated_bioanalytics/images/plot_quality.jpg', dpi = NA)
```

### advanced figure elements {-}

### insets {-}

- zoomed insets

Zoom in on certain plot regions

```{r}
p <- ggplot(mpg, aes(displ, hwy, colour = factor(cyl))) +
  geom_point() 

data.tb <- 
  tibble(x = 7, y = 44, 
         plot = list(p + 
                       coord_cartesian(xlim = c(4.9, 6.2), 
                                       ylim = c(13, 21)) +
                       labs(x = NULL, y = NULL) +
                       theme_bw(8) +
                       scale_colour_discrete(guide = "none")))

ggplot(mpg, aes(displ, hwy, colour = factor(cyl))) +
  geom_plot(data = data.tb, aes(x, y, label = plot)) +
  annotate(geom = "rect", 
           xmin = 4.9, xmax = 6.2, ymin = 13, ymax = 21,
           linetype = "dotted", fill = NA, colour = "black") +
  geom_point() 
```

- plot insets

```{r}
p <- ggplot(mpg, aes(factor(cyl), hwy, fill = factor(cyl))) +
  stat_summary(geom = "col", fun = mean, width = 2/3) +
  labs(x = "Number of cylinders", y = NULL, title = "Means") +
  scale_fill_discrete(guide = "none")

data.tb <- tibble(x = 7, y = 44, 
                  plot = list(p +
                                theme_bw(8)))

ggplot(mpg, aes(displ, hwy, colour = factor(cyl))) +
  geom_plot(data = data.tb, aes(x, y, label = plot)) +
  geom_point() +
  labs(x = "Engine displacement (l)", y = "Fuel use efficiency (MPG)",
       colour = "Engine cylinders\n(number)") +
  theme_bw()
```

- image insets

```{r}
Isoquercitin_synthase <- magick::image_read("https://thebustalab.github.io/integrated_bioanalytics/images/homology2.png")
grobs.tb <- tibble(x = c(0, 10, 20, 40), y = c(4, 5, 6, 9),
                   width = c(0.05, 0.05, 0.01, 1),
                   height =  c(0.05, 0.05, 0.01, 0.3),
                   grob = list(grid::circleGrob(), 
                               grid::rectGrob(), 
                               grid::textGrob("I am a Grob"),
                               grid::rasterGrob(image = Isoquercitin_synthase)))

ggplot() +
  geom_grob(data = grobs.tb, 
            aes(x, y, label = grob, vp.width = width, vp.height = height),
            hjust = 0.7, vjust = 0.55) +
  scale_y_continuous(expand = expansion(mult = 0.3, add = 0)) +
  scale_x_continuous(expand = expansion(mult = 0.2, add = 0)) +
  theme_bw(12)
```

```{r}
# ggplot() +
#   annotate("grob", x = 1, y = 3, vp.width = 0.5,
#            label = grid::rasterGrob(image = Isoquercitin_synthase, width = 1)) +
#   theme_bw(12)
```


```{r}
# bloom_example_pics <- ggplot(data = data.frame(x = c(0,1), y = c(0.5,0.5))) +
#   geom_point(aes(x = x, y = y), color = "white") +
#   theme_void() +
#   annotation_custom(
#       rasterGrob(
#           png::readPNG(
#               "https://thebustalab.github.io/integrated_bioanalytics/images/homology2.png"
#           ), interpolate=TRUE
#       ), xmin=0, xmax=1, ymin=0, ymax=1
#   )

```

### composite figures {-}

Many high quality figures are composite figures in which there is more than one panel. Here is a simple way to make such figures in R. First, make each component of the composite figure and send the plot to a new object:

```{r, fig.height = 5, fig.width = 6}
color_palette <- RColorBrewer::brewer.pal(11, "Paired")
names(color_palette) <- unique(alaska_lake_data$element)

plot1 <- ggplot(
  data = filter(alaska_lake_data, element_type == "bound"),
  aes(y = lake, x = mg_per_L)
) +
  geom_col(
    aes(fill = element), size = 0.5, position = "dodge",
    color = "black"
  ) +
  facet_grid(park~., scales = "free", space = "free") +
  theme_bw() + 
  scale_fill_manual(values = color_palette) +
  scale_y_discrete(name = "Lake Name") +
  scale_x_continuous(name = "Abundance mg/L)") +
  theme(
    text = element_text(size = 14)
  )

plot2 <- ggplot(
  data = filter(alaska_lake_data, element_type == "free"),
  aes(y = lake, x = mg_per_L)
) +
  geom_col(
    aes(fill = element), size = 0.5, position = "dodge",
    color = "black"
  ) +
  facet_grid(park~., scales = "free", space = "free") +
  theme_bw() + 
  scale_fill_manual(values = color_palette) +
  scale_y_discrete(name = "Lake Name") +
  scale_x_continuous(name = "Abundance mg/L)") +
  theme(
    text = element_text(size = 14)
  )
```

Now, add them together to lay them out. Let's look at various ways to lay this out:

```{r, fig.height = 5, fig.width = 10}
plot_grid(plot1, plot2)
```

```{r, fig.height = 8, fig.width = 6}
plot_grid(plot1, plot2, ncol = 1)
```

```{r, fig.height = 8, fig.width = 10}
plot_grid(plot_grid(plot1,plot2), plot1, ncol = 1)
```

### exporting graphics {-}

To export graphics from R, consider the code below. The <path_to_file_you_want_to_create> should be something like: "C:\\Desktop\\the_file.png" (i.e. a path to a specific file with a .png suffix. It should be a file that does not yet exist - if it does already exist, it will be overwritten. You should adjust with height and width to get the image to look how you want, then once you have that dialed in, crank the resolution to 1200 or 2400 and export a final version.

```{r, eval = FALSE}
plot <- ggplot(data, aes(x = x, y = y)) + geom_point()

png(filename = <path_to_file_you_want_to_create>, width = 8, height = 8, res = 600, units = "in")

plot

dev.off()
```

```{r, eval = FALSE}
plot <- ggplot(data, aes(x = x, y = y)) + geom_point()

pdf(filename = <path_to_file_you_want_to_create>, width = 8, height = 8)

plot

dev.off()
```

## captions {-}

Figures are critical tools for clearly and effectively communicating scientific results. However, as Reviewer 2 will tell you, a figure is only as good as its caption. Captions provide essential context, guiding the reader through the significance, structure, and details of the visual information presented. Below are some guidelines to help you craft informative captions. The recommendations are organized into categories, covering essential components like figure titles, panel descriptions, variable definitions, data representation details, statistical analyses, and data sources. Some example captions and a helpful interactive tool (`buildCaption()`) are also included to streamline caption construction and ensure consistency in your scientific communication.

### title and text {-}

- **Figure Title:**  
- Provide a concise, descriptive title that summarizes the overall message or purpose of the figure.
- Ensure the title quickly informs the reader about the main topic, experimental system, or hypothesis addressed by the figure.

- **In All Caption Text:**
- Avoid using unexplained abbreviations or jargon. If abbreviations are necessary, provide definitions at first use.

### panel-by-panel descriptions {-}

- **Panel Identification:**  
  - Label each panel (e.g., A, B, C, etc.) and refer to these labels consistently in the caption.

- **Graph Type and Layout:**  
  - State the type of plot (line plot, bar chart, scatter plot, histogram, etc.). When in doubt, "plot" is okay.
  - Describe any special features such as insets, overlays, or embedded plots (e.g., zoomed regions, additional mini-panels).

- **Axes and Variables:**  
  - Clearly define what is on each axis (x vs. y) in descriptive terms, including units of measurement (e.g., time in seconds, concentration in µM).
  - Explain if additional dimensions (such as color coding, marker sizes, or symbols) are used to represent extra variables.

- **Data Representation Details:**
  - Describe what the individual data points, bars, or error bars represent. For example:
    - **Data Points/Bars:** Explain whether they indicate individual measurements, means, medians, or other summary statistics.
    - **Error Bars:** Specify whether these indicate standard error, standard deviation, 95% confidence intervals, or another metric.
  - Note any graphical elements like trend lines or regression lines and what model or fit has been applied.

- **Sample Size and Replicates:**  
  - Indicate the number of independent samples or experimental replicates underlying each element of the graph.

- **Statistical Analysis and Comparisons:**
  - Describe any control experiments or baseline data presented in the figure, including how they were used to validate or compare with experimental results.
  - State any statistical tests used (e.g., t-test, ANOVA, regression analysis) and the significance level(s).
  - Describe how statistical significance is indicated in the figure (e.g., asterisks, brackets, p-value annotations).
  - Provide any necessary details about data normalization, transformation, or curve fitting that influence data interpretation.
  - For figures with scale bars or reference markers (e.g., microscopy images), specify the scale explicitly.
  
### data source and methodology {-}

- **Data Origins and Methodology:**  
  - Clearly state where the data come from (e.g., experimental assays, clinical samples, simulations, or databases).
  - If the data are derived from previously published work or a public repository, include proper references or accession numbers, if reasonable / possible.
  - Consider including a summary of the methods used to obtain or generate the data. This is standard practice in some fields - have a look at what articles from your field typically include.
  - Consider including information on experimental conditions (e.g., treatment concentrations, temperature, environmental conditions) or computational parameters (e.g., algorithm settings), assuming these weren't already mentioned when describing the axes.
  - Mention any image processing steps (e.g., brightness/contrast adjustments, background subtraction) if these steps are critical for understanding the visual data.

### example captions {-}

```{r, fig.height = 8, fig.width = 12, fig.cap = "Figure 1: Carbon, nitrogen, and phosphorous in Alaskan lakes. A) A bar chart showing the abundance (in mg per L, x-axis) of the bound elements (C, N, and P) in various Alaskan lakes (lake names on y-axis) that are located in one of three parks in Alaska (park names on right y groupings). B) A bar chart showing the abundance (in mg per L, x-axis) of the free elements (Cl, S, F, Br, Na, K, Ca, and Mg) in various Alaskan lakes (lake names on y-axis) that are located in one of three parks in Alaska (park names on right y groupings). The data are from a public chemistry data repository. Each bar represents the result of a single measurement of a single analyte, the identity of which is coded using color as shown in the color legend. Abbreviations: BELA - Bering Land Bridge National Preserve, GAAR - Gates Of The Arctic National Park & Preserve, NOAT - Noatak National Preserve.", echo = FALSE}
plot_grid(plot1, plot2, labels = c("A", "B"))
```

### buildCaption {-}

To help you manage the suggestions above, please consider using the `buildCaption()` tool, which you can open using the command below. That command should open an interactive window with a checklist to help you quickly build quality captions.

```{r, eval = FALSE}
buildCaption()
```

## {-}

## further reading {-}

- [Grammar extensions and insets with `ggpp`](https://docs.r4photobiology.info/ggpp/articles/grammar-extensions.html#geom_plot)  
  This article explains how to use the `ggpp` extension to add insets and annotations to `ggplot2` graphics in R. It introduces grammar extensions that allow you to insert subplots, highlight specific regions, and incorporate custom graphical elements in a composable and expressive way. Particularly useful for emphasizing detail or providing context within complex figures.

- [Patchwork: Simple plot layout with ggplot2](https://patchwork.data-imaginist.com/index.html)  
  `Patchwork` is an elegant and intuitive package for arranging multiple `ggplot2` plots into a single composite figure. With a minimal syntax that mirrors mathematical layout expressions, it allows users to combine plots vertically, horizontally, or in nested arrangements—ideal for creating figure panels for publications or presentations.

- [Cowplot: Versatile plot composition](https://wilkelab.org/cowplot/articles/plot_grid.html)  
  `Cowplot` is another popular package for composing multiple `ggplot2` plots. It offers more control and customization than `patchwork`, particularly for aligning plots, adjusting spacing, and embedding annotations. This makes it well-suited for fine-tuned figure design when preparing publication-quality graphics.


# question-driven report {-}

<!-- * Objective: Walk your reader through your results, drawing conclusions as you go. -->

<!-- * Tense: past tense and passive voice, because we are talking about what happened in the experiments, and reflecting with distance on the results.
 -->
<!-- * As you go: make notes of what should go into the introduction. -->

- A structured report with the following components:
  + Cover page: Title and author, Introductory paragraph
  + One section for each of three scientific question. Each section has one figure + caption, as well as one or more paragraphs explaining that figure and any conclusions that follow from it.
  + References

```{r fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), results="markup"}
knitr:::include_graphics('https://thebustalab.github.io/integrated_bioanalytics/images/report_outline.jpg', dpi = NA)
```

## {-}

## brief structural example {-}

> **Chemical Pollutants in Minnesota Soils**\
>
>
>In order to better understand pollution in the state of Minnesota, this study focused on a detailed analyses of chemical measurements from soil samples from 300 sites around the state. The analyses consisted of a principal components analysis to determine which sites were similar to one another, thus answering the question of what sites exhibited similar pollutant profiles (Section 2.1). This first analysis was followed by statistical tests to see whether differences could be detected in the sites' chemistry, answering the question of whether there were any significant differences in the pollutant profiles at each site (Section 2.2).\
>
>
>*2.1 Principal Components Analysis*\
>
>
>To understand relationships between the sites from which soil chemistry was sampled, a principal components analysis was used. Each of the 20 different analytes, all of which contained halogen atoms, were included in the analysis. A scatter plot showing the position of each of the 300 samples in a space defined by dimesions 1 and 2 (which explain 54% and 35% of the total variance of the dataset, respectively), revealed that two major clusters are present, with a small number of outliers (Fig. 1). By color coding these two clusters according to whether the samples were collected from rural versus urban areas, it was possible to see that the first cluster was made out of almost exclusively samples from urban areas, while the second cluster was made up of almost entirely samples from rural areas. This suggested that variance in pollutant chemistry among the samples collected was assocaited with urban versus rural environments.\
>
>
>*2.2 Statistical Analyses*\
>
>
>Using the groupings that were identified via principal components analysis, statistical tests were conducted to determine if chemical abundances differed between groups. Tests for normality and homogeneity of variance (Shapiro and Levene tests) revealed that the data could not be assessed using ANOVA but instead required the use of a non-parametric test. Accordingly, the Kruskall-Wallis test followed by post-hoc Dunn tests were applied, which showed that the abundances of halogenated pollutants is significantly higher in urban versus rural areas (p = 0.0035, Fig. 2A). These direct observations are consistent with conclusions drawn by others in recent literature reviews focused on hydrocarbon compounds (Petrucci et al., 2018; Hendrix et al., 2019). *Thus, the new chemical analyses presented here demonstrate that the discrepancy in urban versus rural pollution is true not only for hydrocarbon compounds (as had been found previously), but also for halogenated compounds.* Together, these findings strongly suggest that either cities are a source of more pollution or that there is some other mechanism that concentrates pollution in cities.\
>

## structure {-}

(key: **number of suggested sentences**: *purpose*: "example")

* Title and Author
  + **1** Use about 75-140 characters (ideally no more than 125 characters). There are essentially two types of titles: descriptive titles and mechanistic titles. 
    + If your manuscript is exploratory research, consider using a descriptive title. For example: "Comparative analysis of carbon, sulfur, and phoshorous chemistry in six Alaskan lakes."
    + If your manuscript is hypothesis-driven research, consider using a mechanistic title. For example: "Dissolved organic carbon in Alaskan lakes is heavily influenced by water pH and temperature."
    + A good title should:
      + Be indicative of the content of the paper
      + Attract the interest of potential readers
      + Reflect whether the article is deascriptive or mechanistic
      + Include important keywords

* Introductory paragraph:
  + **1**: *State the aim of the report*: "The objective of this report is to..."
  + **3-4**: *Call out the subsections of the report according to methodology and scientific questions*: "We used method X to quantify property Y of our study subject and address the question "Does property Y vary based on the date the sample was collected?" (section 2.1)."

* Each subsection paragraph:
  <!-- + 1: *Statement of observation or lead-in*: "Based on the observation of X..." -->
  + **1**: *Purpose of the work described in this paragraph*: "In order to determine..."
  + **1**: *Review methods or experimental design specific to this subsection (if necessary)*
  + **4-5**: *Results of that method or experiment (i.e. data features)*
  + **1-2**: *Comparison of new results against those in literature (if possible)*
  + **1-2**: *Conclusion from the combined results or some other concluding remark* "Thus, analysis X revealed that..."
  <!-- + **1**: *Interpretation of the conclusion in a larger context (if possible / reasonable)* -->

<!-- * Introductory paragraph: -->
<!--   + **1**: *Review the aim of the paper*: "In order to understand…" -->
<!--   + **3-4**: *Use a methods summary to call out subsections*: "We used method X to quantify property Y of our study subject (section 2.1)" -->

<!-- * Each subsection paragraph: -->
<!--   <!-- + 1: *Statement of observation or lead-in*: "Based on the observation of X..." -->
<!--   + **1**: *Purpose of the work described in this paragraph*: "In order to determine..." -->
<!--   + **1**: *Review methods or experimental design specific to this subsection (if necessary)* -->
<!--   + **4-5**: *Results of that method or experiment (i.e. data features)* -->
<!--   + **1-2**: *Comparison of new results against those in literature (if possible)* -->
<!--   + **1-2**: *Conclusion from the combined results or some other concluding remark* "Thus, analysis X revealed that..." -->
<!--   <!-- + **1**: *Interpretation of the conclusion in a larger context (if possible / reasonable)* -->

## suggestions {-}

Is there an efficient way to write in the format outlined above? Yes. Follow the step-by-step instructions below:

### outline then draft paragraphs {-}

```{r fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), results="markup"}
knitr:::include_graphics('https://thebustalab.github.io/integrated_bioanalytics/images/res_disc_1.jpg', dpi = NA)
```

1. **Identify "data features" -> "conclusion" combinations.** Using your figures, make a list of all the potentially interesting features in your data, then pair each feature with a possible conclusiona it could lead to. Example:
  + "The GC-MS data presented here indicates that cities have higher levels of pollution than rural areas (Fig. 1)," (a data feature)
  + "suggesting that either cities are a source of more pollution or that there is some other mechanism that concentrates pollution in cities." (a conclusion)
  
2. **Perform targeted literature searches.** Expand your "data feature" -> "conclusion" combinations with "supplementary information" or "literature information". Example:
  + "The GC-MS data presented here indicates that cities have higher levels of pollution than rural areas." (data feature)
  + "These direct observations are consistent with conclusions drawn by others in recent literature reviews (Petrucci., 2018; Hendrix et al., 2019)" (literature information)
  + "Overall, this suggests that either cities are a source of more pollution or that there is some other mechanism that concentrates pollution in cities." (conclusion)
  
3. **Group "data feature" -> "supp/lit info" -> "conclusion" combinations into paragraphs.** Edit each conclusion so that it highlights what new contribution your data makes to the situation. Also consider whether any of the parargaphs now suggest the existence of mechanisms. Example (note the conclusion sentence in italics that highlights the new findings):
  + "The GC-MS data presented here indicates that cities have higher levels of pollution than rural areas (Fig. 1). These direct observations are consistent with meta-analyses of previously published observations (Supplemental Figure 1), as well as with conclusions drawn by others in recent literature reviews (So and so et al., 2018; The other person et al., 2019). *The new chemical analyses presented here thus confirm this is true for hydrocarbon compounds, and extend the observation to halogenated compounds in the atmosphere.* Together these findings strongly suggest that either cities are a source of more pollution or that there is some other mechanism that concentrates pollution in cities.

### order then edit paragraphs {-}

1. **Identify paragraph characteristics and group**
  + Consider whether any of your paragraphs are prerequisites for others and whether any paragraphs can be grouped according to topic.
  + Group paragraphs according to topic and prerequisite dependencies (putting prereq dependencies as close to eachother as possible.)

2. **Rearrange paragraph groups** Create the most natural flow. Consider:
  + Starting with group of paragraphs most relevant to the overall pitch/goal of the paper
  + Ending on the group of paragraphs that has the most future perspective
  + Ending in a strong suit (i.e. not something too speculative)
  + Consider putting orphaned paragraphs (or a shortened version of them) into the conclusion section.

3. **Edit transitions between groups.** Edit each paragraph, particularly its first and last sentences, to connect the paragraphs into a flowing document. Specifically, this means several things:
  + There should be no implicit cross-paragraph references (i.e. a new paragraph should not begin "The compound described above exhibited other interesting properties", rather, "3-hydroxycinnamic acid exhibited other interesting properties.").
  + There should be no abrupt jumps in subject between paragraphs, if there are consider breaking the discussion into subsections to help the reader identify logical resting points.
  + The discussion should not require the reader to go back and read its first half in order to understand its second half.

<!-- ### other thoughts -->

<!-- * Somewhere in the discussion, be sure to list out what any unsolved problems you faced are. -->

<!-- end -->

<!-- start Conclusions -->

<!-- # conclusion and introduction {-} -->

<!-- * Objective (conclusion): to convey a short statement of the take-home messages of your study. What are the most important things that you want the reader to remember from your study? -->

<!-- * Objective (introduciton): to prepare the reader by giving the reader sufficient background to understand the study as a whole. It therefore should only contain information pertinent to understanding the study and its broader significance.  -->

<!-- * Make sure that the scope of your introduction is in-line with the scope of the conclusion. That way, the reader will not be underwhelmed, nor will your work be undersold. -->

<!-- ## structure {-} -->

<!-- **Conclusion:** -->

<!-- * *One paragraph* -->
<!--   <!-- first sentence of the conclusion should be a restatment of the goal -->
<!--   + **2-3**: Summarize over-arching conclusions from each section of the paper (omit the details described in results or discussion) -->
<!--   + **2-3**: Based on a general description of findings, use pros and cons to argue for, if possible, alternative hypotheses. -->
<!--   + **1-2**: Suggest experiments to test these hypotheses. -->
<!--   + **1-2**: Describe future directions. -->
<!-- <!-- * Integrate over-arching conclusions to discuss new avenues, i.e. integrating chain length specificity and secondary functional group installation to discuss how both might affect physical properties of wax mixtures, then how these might have evolved. -->

<!-- **Introduction:** -->

<!-- ```{r fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), results="markup"} -->
<!-- knitr:::include_graphics('https://thebustalab.github.io/integrated_bioanalytics/images/knowledge_gaps.jpeg', dpi = NA) -->
<!-- ``` -->

<!-- * *Paragraph 1: Introduce the topic* -->
<!--   + **1**: Introduce a topic and, ideally, an application of the research you will describe. Grab reader's attention. -->
<!--   + **1**: State why the topic is important. -->
<!--   + **1**: Describe what is known about the topic (at least, as pertains to the work at hand). -->
<!--   + **1**: Identify a gap in knowledge: "despite research in this area, here is what we don't know about the topic." -->
<!--   + **1**: List the negative things that will happen if we don't fill this gap in knowledge. -->

<!-- * *Paragraph 2: Provide background information* -->
<!--   + **3-5**: Describe, in moderate detail, the background information (concepts, literature) relevant to the study. -->
<!--   + **1**: End by saying how the details you just described relate to the application/topic described in the first paragraph. -->

<!-- * *Paragraph 3: Objectives of this study* -->
<!--   + **1**: State the objective of this study. -->
<!--   + **1**: Briefly describe what was done and the techniques or instruments used. -->
<!--   + **1-2**: For this project, briefly describe where you got the data, how you cleaned it up, if you merged multiple datasets, etc. -->
<!--   + **1**: (optional) State the major conclusion from the work and what it means for the application described in paragraph 1. -->

<!-- ## suggestions {-} -->

<!--   + If something is well-established, say so. -->
<!--   + Be clear about what is speculation. -->
<!--   + Last paragraph can mention objectives in list form. -->
<!--   + Last sentence can briefly mention methods (specific techniques or instruments) that were used. -->

<!-- end -->

<!-- start Abstract -->

<!-- # abstract and title {-} -->

<!-- ## abstract -->

<!-- ```{r fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), results="markup"} -->
<!-- knitr:::include_graphics('https://thebustalab.github.io/integrated_bioanalytics/images/abstract_guide.jpeg', dpi = NA) -->
<!-- ``` -->

<!-- * **Structure** *One paragraph* Use about 200 - 500 words (ideally no more than 400 words) -->
<!--   + **1-2 sentences**: Introduction: Describe the topic, the motivation, and overall purpose of the research (Why is this research interesting and important? What gap in our knowledge does it fill?) -->
<!--   + **1-2 sentences**: Objective: Specific research objective, and potentially hypotheses/predictions, if any. -->
<!--   + **1-2 sentences**: Methods: Very concise overview of the methods used to address the research questions. -->
<!--   + **2-3 sentences**: Results/Discussion: Describe the major results (what you found) and interpretation of the results (what the results mean). -->
<!--   + **1-2 sentences**: Conclusions: Synthesizes the major contributions of the study into the context of the larger field to which the study belongs. What did we learn about the bigger picture of this field in general from doing this study? -->

<!-- * **Function: an abstract proves a short summary of the entire study.** The abstract should include the motivation or reason for conducting the study, what the research question or hypothesis was, how the experiments were conducted, what the results were, how the results are interpreted in light of the research question or hypothesis, and a concluding sentence about the general contribution or importance of the study. A good abstract should: -->
<!--   + Inform readers about the article’s content -->
<!--   + Summarize complex information in a clear, concise manner -->
<!--   + Help readers decide whether or not to read the article -->
<!--   + Used in conferences to summarize what the speaker will say during his/her presentation -->

<!-- ### other thoughts -->

<!-- * Whatever you identify as the strongest sentences in the main text, make sure those are reflected in the abstract -->

<!-- ## further reading {-} -->

<!-- * [Titles Guide](https://libguides.usc.edu/writingguide/title) -->

<!-- * [Abstract Guide] (https://www.cbs.umn.edu/sites/default/files/public/downloads/Annotated_Nature_abstract.pdf) -->

<!-- end -->
________________________________________________________________________________________________
________________________________________________________________________________________________
________________________________________________________________________________________________

# (PART) APPENDIX {-}

<!-- start links -->

# links {-}

## geoms {-}

[geoms and ggplot2 cheatsheet](https://thebustalab.github.io/integrated_bioanalytics/images/ggplot2_geoms.pdf)

## colors {-}

[ColorBrewer2](https://colorbrewer2.org/)

<!-- end -->

# datasets {-}

## alaska_lake_data {-}

The Alaska Lake Data was collected as part of a water quality monitoring initiative across various lakes in protected national parks, aimed at assessing the chemical composition and environmental conditions of these unique ecosystems. Researchers took water samples from several lakes, measuring key environmental parameters like water temperature and pH, along with analyzing the abundance of different chemical elements, such as carbon, nitrogen, and phosphorus. By comparing the concentrations of both bound and free elements, the study aimed to understand the health of these aquatic environments and the impact of natural and anthropogenic factors on the water chemistry. The dataset will be used to inform conservation strategies for maintaining the ecological balance in these sensitive regions.
- lake (Categorical): The name of the lake from which the water sample was collected. This refers to the sample.
- park (Categorical): The park or national park code where the lake is located. This is part of the sample identification.
water_temp (Continuous): The water temperature (in degrees Celsius) of the sample at the time of collection. This is an analyte describing an environmental condition of the sample.
- pH (Continuous): The pH value of the water, representing its acidity or alkalinity. This is an analyte providing an environmental characteristic of the sample.
- element (Categorical): The chemical element being measured in the water (e.g., C for carbon, N for nitrogen). This is an analyte.
- mg_per_L (Continuous): The concentration (in milligrams per liter) of the corresponding analyte from the element column, indicating the abundance of each analyte in the water sample.
- element_type (Categorical): Describes whether the element is in a "bound" or "free" state, providing context for the form of the analyte.

## algae_data {-}

This dataset was generated as part of a study investigating the biochemical composition of different algae strains under varying harvesting conditions. The goal of the research was to examine how different algae strains and harvesting regimes affect the abundance of various chemical species, particularly fatty acids and amino acids, which have potential applications in biofuel production and nutritional supplements. Replicates were performed to ensure consistency, and a wide range of chemical species was measured to provide insights into the algae's metabolic profile and its response to environmental or harvesting changes.

- replicate (Categorical): The replicate number of the sample for the experiment, indicating which iteration of the algae sample was analyzed.
- algae_strain (Categorical): The specific strain of algae used in the experiment (e.g., "Tsv1"). This refers to the strain from which each sample was collected.
- harvesting_regime (Categorical): The method or condition under which the algae sample was harvested (e.g., "Heavy" regime).
- chemical_species (Categorical): The type of chemical species or analyte measured in the algae sample, including various fatty acids (FAs) and amino acids (Aas).
- abundance (Continuous): The measured abundance of the chemical species or analyte in the algae sample, expressed in a continuous quantitative form (e.g., mg/L or similar units).

## beer_components {-}

This dataset captures the volatile compounds released from different ingredients like barley and corn, likely as part of a study on food aroma profiles. Researchers measured the abundance of specific analytes (such as 2-Methylpropanal) and classified them by chemical group (e.g., Aldehydes). The goal is to assess how different ingredients contribute to the overall aroma by linking each analyte to sensory descriptors, which include odor characteristics such as "Green," "Pungent," and "Malty." The dataset could be useful in food science research.

- ingredient (Categorical): The ingredient from which the analytes were measured (e.g., "barley," "corn"). This refers to the ingredient from which the sample was collected.
- replicate (Categorical): The replicate number of the sample for the experiment, indicating the repetition of the measurement for consistency.
- analyte (Categorical): The specific volatile compound or chemical measured in the ingredient (e.g., "2-Methylpropanal").
- analyte_class (Categorical): The chemical classification of the analyte (e.g., "Aldehyde").
- abundance (Continuous): The concentration of the analyte measured in the sample, likely in a quantitative unit such as mg/L.
- analyte_odor (Categorical): A sensory descriptor for the odors associated with the analyte, listed as a combination of descriptors (e.g., "Green; Pungent; Burnt; Malty; Toasted").

## hawaii_aquifers {-}

This dataset represents water quality measurements from various wells within an aquifer system, collected as part of a study on groundwater composition. Researchers measured the abundance of different dissolved elements and compounds, such as silica (SiO2) and chloride (Cl), from different wells in an aquifer. The dataset could be used to assess the chemical profile of groundwater and monitor any changes in water quality over time. Note the absence of geospatial data (latitude and longitude) for certain samples, and note that some samples come from the same well and aquifer but have different latitude and longitude coordinates.

- aquifer_code (Categorical): The code assigned to identify the aquifer system (e.g., "aquifer_1") that the sample came from.
- well_name (Categorical): The name of the well from which the water sample was collected (e.g., "Alewa_Heights_Spring").
- longitude (Continuous): The longitudinal coordinates of the well location from which the sample was take.
- latitude (Continuous): The latitudinal coordinates of the well location from which the sample was take.
- analyte (Categorical): The specific dissolved compound or element measured in the water sample (e.g., "SiO2," "Cl").
- abundance (Continuous): The concentration of the analyte in the water sample, expressed in a quantitative unit (mg/L).

## hops_components {-}

This dataset contains detailed information on various hop varieties used in brewing, including their country of origin, brewing usage (aroma or bittering), and the chemical composition of their essential oils and acids. The dataset serves as a resource for brewers to select hop varieties based on their aroma profiles and chemical content, such as alpha acids and essential oils like humulene and myrcene, which influence the bitterness, flavor, and aroma of beer. The goal of this dataset is to help optimize the hop selection process in brewing for specific flavor profiles and brewing techniques like dry hopping or bittering.

- hop_variety (Categorical): The specific variety of hop used (e.g., "Cascade," "Chinook").
- hop_origin (Categorical): The country of origin for the hop variety (e.g., "USA," "England").
- hop_brewing_usage (Categorical): The primary use of the hop in brewing, either for aroma or bittering, or techniques like dry hopping.
- hop_aroma (Categorical): The sensory description of the hop's aroma profile, which can include terms like "floral," "citrus," or "spicy."
- total_oil (Continuous): The total essential oil content of the hop, typically measured in milliliters per 100 grams.
- alpha_acids (Continuous): The percentage of alpha acids in the hop, which contribute to the bitterness of the beer.
- beta_acids (Continuous): The percentage of beta acids in the hop, which also contribute to the bitterness but degrade more slowly over time.
- humulene (Continuous): A compound contributing to the hop's woody, earthy aroma.
- myrcene (Continuous): A compound that contributes to the hop's citrus and floral aroma.
- humulone (Continuous): Another compound found in hop oils, related to bitterness and aroma.
- caryophyllene (Continuous): A compound contributing to spicy, peppery aromas.
- farnesene (Continuous): A compound contributing to green, woody, or fruity aromas.

<!-- start R FAQ -->
# r faq {-}

## Updating R and R Packages {-}

Close RStudio, open the plain R GUI, then run the following:

On Mac:

```{r, eval = FALSE}
install.packages('remotes') #assuming it is not remotes installed
remotes::install_github('andreacirilloac/updateR')
updateR::updateR()
```

On PC:

```{r, eval = FALSE}
install.packages("installr")
installr::updateR()
```

## ordering {-}

A list of numeric element has an inherent order to it: -inf -> +inf. A list of character element also has an inherent order to it: A -> Z, or if it's a mixed number and letter list (which is interpreted by R as a character list): 0 -> 9 -> A -> Z.

However, there are cases where we will want a list of character elements to have some order other than A -> Z. In these cases, we want to convert the list of character elements into a list of factor elements. Factors are lists of character elements that have an inherent order that is not A -> Z. For example, in the plot below, the y axis is not, perhaps, in the "correct" order:

```{r}
ggplot(periodic_table) +
  geom_point(aes(y = group_number, x = atomic_mass_rounded))
```

How do we fix this? We need to convert the column `group_number` into a list of factors that have the correct order (see below). For this, we will use the command `factor`, which will accept an argument called `levels` in which we can define the order the the characters should be in:

```{r}
periodic_table$group_number <- factor(
  periodic_table$group_number,
  levels = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "lanthanides", "actinides")
)

periodic_table
```

Notice that now when we look at the type of data that is contained in the column `group_number` it says "<fct>". This is great! It means we have converted that column into a list of factors, instead of characters. Now what happens when we make our plot?

```{r}
ggplot(periodic_table) +
  geom_point(aes(y = group_number, x = atomic_mass_rounded))
```

VICTORY!

## column manipulation {-}


How to select specific columns:

```{r}
alaska_lake_data %>%
  select(water_temp, pH)
```

How to remove certain columns:
```{r}
alaska_lake_data %>%
  select(!water_temp)
```

## user color palettes {-}

Suppose we want to create a specific color palette for each pack in `alaska_lake_data`. There are three unique parks:

```{r}
unique(alaska_lake_data$park)
```

First we define the colors we want:

```{r}
custom_colors_for_lakes <- c("#1a9850", "#ffffbf", "#d73027")
custom_colors_for_lakes
```

Then we name that vector according to which park we want to be which color:

```{r}
names(custom_colors_for_lakes) <- c("GAAR", "NOAT", "BELA")
custom_colors_for_lakes
```

Now we feed that object to the `values` argument of scale_color_manual (or scale_fill_manual, if you want fill):

```{r}
ggplot(alaska_lake_data) + 
  geom_point(aes(x = pH, y = water_temp, fill = park), size = 5, shape = 21, color = "black") +
  scale_fill_manual(values = custom_colors_for_lakes) +
  theme_classic()
```

# templates {-}

## matrix analyses

### basic `runMatrixAnalyses()` template

```{r, eval = FALSE}

runMatrixAnalyses(   
  data = NULL,
  analysis = c("hclust", "pca", "pca_ord", "pca_dim"),
  columns_w_values_for_single_analyte = NULL,
  columns_w_sample_ID_info = NULL
)
```

### advanced `runMatrixAnalysis()` template

```{r, eval = FALSE}

runMatrixAnalysis(
  data, # data to use for analysis
  analysis = c(
      "pca", "pca_ord", "pca_dim", # PCA
      "mca", "mca_ord", "mca_dim", # MCA (PCA on categorical data)
      "mds", "mds_ord", "mds_dim", # MDS
      "tsne", "dbscan", "kmeans", # Clustering
      "hclust", "hclust_phylo" # Hierarchical clustering
  ),
  parameters = NULL,
  column_w_names_of_multiple_analytes = NULL,
  column_w_values_for_multiple_analytes = NULL,
  columns_w_values_for_single_analyte = NULL,
  columns_w_additional_analyte_info = NULL,
  columns_w_sample_ID_info = NULL,
  transpose = FALSE, # default = FALSE, this chooses whether to transpose the data
  distance_method = c( # the distance metric to use in computing a distance matrix
    "euclidean", "maximum",
    "manhattan", "canberra",
    "binary", "minkowski",
    "coeff_unlike"
  ),
  agglomeration_method = c( # the clustering method to use in heirarchical clustering
      "ward.D2", "ward.D", "single", "complete",
      "average", # (= UPGMA)
      "mcquitty", # (= WPGMA)
      "median", # (= WPGMC)
      "centroid" # (= UPGMC)
  ),
  tree_method = c("nj"),
  unknown_sample_ID_info = NULL,
  components_to_return = 2, # how many principal components to return
  scale_variance = NULL, ## default = TRUE, except for hclust, then default = FALSE
  na_replacement = c("mean", "none", "zero", "drop"), # default = "mean", this chooses what to do with missing values
  output_format = c("wide", "long"), # default = "wide", this chooses whether to output a wide or long format
)
```

# loading analyzeGCMSdata {-}

This page explains how to load a simple application for integrating and analyzing GC-MS data. With the app, you can analyze .CDF.csv files. CDF.csv files contain essentially all the data from a GC-MS run, and can be exported from most GC-MS systems using the software provided by the manufacturer. To run the application, use the following guidelines:

1. Create a new folder on your hard drive and place your CDF.csv file into that folder. It doesn't matter what the name of that folder is, but it must not contain special characters (including a space ` ` in the name). For example, if my CDF.csv file is called "sorghum_bicolor.CDF.csv", then I might create a folder called `gc_data` on my hard drive, and place the "sorghum_bicolor.CDF.csv" file in that folder.

2. In R or RStudio, run the source command shown below. You will need to do this every time you re-open R or RStudio. This command will load the `analyzeGCMSdata` function into your R or RStudio environment. Note that you will need to be connected to the internet for this to work. The first time you run this command, a bunch of tools required for the analysis will be installed. It might take a while! Later runs of the command will not have this install portion - the app will just open straight away.

```{r, message = FALSE, eval = FALSE}
source("https://thebustalab.github.io/phylochemistry/gcms.R")
```

If the command was run successfully you should see something like:
```{r fig.align='center', echo=FALSE, include=identical(knitr:::pandoc_to(), 'html'), results="markup"}
knitr:::include_graphics('https://thebustalab.github.io/integrated_bioanalytics/images/success.png', dpi = NA)
```
 \

3. In R or RStudio, run the `analyzeGCMSdata` command on the *folder* that contains your CDF.csv file. Do not run the command on the CDF.csv file itself, that will not work. For example, if my CDF.csv file is called "sorghum_bicolor.CDF.csv", and is inside the folder called `gc_data`, then I would run the following:
 \

If you are on a Mac, *use single forward slashes*. For example:
```{r, message = FALSE, eval = FALSE}
analyzeGCMSdata("/Volumes/My_Drive/gc_data")
```
 \

If you are on a PC, you may need to use double back slashes. For example:
```{r, message = FALSE, eval = FALSE}
analyzeGCMSdata("C:\\Users\\My_Profile\\gc_data")
```
 \

The first time you open your CDF.csv datafile, it may take a while to load. Once the new RShiny window opens, press shift+q to load the chromatogram(s).

# using analyzeGCMSdata {-}

## basic usage of analyteGCMSdata {-}

As a reference, below are the key commands used to operate the integration app. This is the information that is covered in the overview video.

To control the chromatogram window:

* shift + q = update
* shift + a = add selected peak
* shift + r = remove selected peak
* shift + z = save table

To control the mass spectrum window:

* shift+1 = extract mass spectra from highlighted chromatogram region, plot average mass spectrum in panel 1.
* shift+2 = refresh mass spectrum in panel 1. This is used for zooming in on a region of the mass spectrum that you have highlighted. A spectrum needs to first be extracted for this to be possible.
* shift+3 = extract mass spectra from highlighted chromatogram region, subtract their average from the mass spectrum in panel 1.