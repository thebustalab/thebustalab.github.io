[{"path":"index.html","id":"welcome","chapter":"WELCOME","heading":"WELCOME","text":"Integrated Bioanalytics documents methods analyzing chemical sequence data R well basics scientific writing. maintained Lucas Busta members Busta lab. run analyses described book need run source script set R environment variety packages, custom functions, data sets. don’t R, see “installation” “Data Analysis R” table contents. Run source script pasting executing following R command line (RStudio recommended). Busta Lab (want access full features), define object bustalab = TRUE running source command. trouble running source script, please reach Lucas Busta : bust0037@d.umn.edu. source script:Features provided source script:–Analysis visualization tools–GC-MS data analysis application MS reference library.sequence alignment analysis application trimming alignments.Functions dimensionality reduction, clustering, modeling, visualization.–Useful data–12 chemical data sets running practice analyses.phylogeny >30,000 plant species, including nearly 30,000 angiosperms, >500 gymnosperms, nearly 500 pteridophytes, 100 bryophytes (https://thebustalab.github.io/data/plant_phylogeny.newick).list nearly 400,000 plant species well families, orders, phyla belong (https://thebustalab.github.io/data/plant_species.csv).","code":"\nsource(\"https://thebustalab.github.io/phylochemistry/phylochemistry.R\")"},{"path":"overview.html","id":"overview","chapter":"overview","heading":"overview","text":"bioanalytical science, separate, identify, quantify matter - DNA, RNA, proteins, small molecules, even atoms. connect data world around us answer scientific questions, multiple chemical entities must separated, quantified, identified. ability collect analytical data expands, must ability effectively analyze data - whether ’s 10 data points 10,000. chapter, explore, critique, practice methods handling visualizing data generated large analytical projects. ’ll also look answer common quesions may data: “samples closely related?”, “analytes driving differences among samples?”, “samples fall definable clusters?”, “variables related?”, “distributions different?”.","code":""},{"path":"installation.html","id":"installation","chapter":"installation","heading":"installation","text":"","code":""},{"path":"installation.html","id":"r","chapter":"installation","heading":"R","text":"R computing language use run analyses produce high quality plots. already R installed (need least version 4.1.1), can go straight installing RStudio. , follow steps install R:Go https://cran.r-project.org/Go https://cran.r-project.org/Click “Download R <operating system>” (see footnote), depending operating system select “Download R Linux”, “Download R (Mac) OS X”, “Download R Windows”.Click “Download R <operating system>” (see footnote), depending operating system select “Download R Linux”, “Download R (Mac) OS X”, “Download R Windows”.use <notation> quite bit. indicates place insert information, data, something similar corresponds particular situation. example means insert “operating system”, .e. Linux, (Mac) OS X, Windows.Mac: download .pkg file latest release. PC: click “install R first time”, click “Download R <version> Windows”.Mac: download .pkg file latest release. PC: click “install R first time”, click “Download R <version> Windows”.executable finishes downloading (Windows, file .exe extension; Mac, .dmg file .dmg inside .pkg file), open file administrator, follow installation instructions. R install without problems. can click OK windows pop-installation, choose “regular” installation (given choice).executable finishes downloading (Windows, file .exe extension; Mac, .dmg file .dmg inside .pkg file), open file administrator, follow installation instructions. R install without problems. can click OK windows pop-installation, choose “regular” installation (given choice).trouble installing R please google “Install R Mac” “Install R PC” follow one many video tutorials . tried still trouble, please contact .","code":""},{"path":"installation.html","id":"rstudio","chapter":"installation","heading":"RStudio","text":"install R, can install RStudio, essentially convenient way interacting R. people like RStudio prefer interact R directly. fine, many beginning R users find RStudio helpful, recommend . Follow steps install RStudio:Go https://rstudio.com/Go https://rstudio.com/Click “DOWNLOAD” top page.Click “DOWNLOAD” top page.Click “DOWNLOAD” button corresponds RStudio Desktop free Open Source License.Click “DOWNLOAD” button corresponds RStudio Desktop free Open Source License.page may automatically detect operating system using recommend version . , download file (.exe PC .dmg Mac). , scroll “Installers” section download file right . Open file administrator, follow installation instructions. RStudio install without problems. can click OK windows pop-installation, choose “regular” installation (given choice).page may automatically detect operating system using recommend version . , download file (.exe PC .dmg Mac). , scroll “Installers” section download file right . Open file administrator, follow installation instructions. RStudio install without problems. can click OK windows pop-installation, choose “regular” installation (given choice).trouble installing RStudio please google “Install RStudio Mac” “Install RStudio PC” following one many video tutorials . tried still trouble, please contact .","code":""},{"path":"installation.html","id":"verification","chapter":"installation","heading":"verification","text":"Open RStudio clicking appropriate file applications folder, wherever saved computer. Windows, sure run RStudio administrator. see several windows. One Code Editor, one R Console, one Workspace History, one Plots Files window.R Console window > . Type head(Indometh). display first six lines data set describing pharmacokinets indomethacin. one built datasets R - need additional files run test.Next, type plot(Indometh) R Console. plot indomethacin dataset basic way.commands (head(Indometh) plot(Indometh)) worked error messages installation, ready proceed.","code":"\nhead(Indometh)\n## Grouped Data: conc ~ time | Subject\n##   Subject time conc\n## 1       1 0.25 1.50\n## 2       1 0.50 0.94\n## 3       1 0.75 0.78\n## 4       1 1.00 0.48\n## 5       1 1.25 0.37\n## 6       1 2.00 0.19\nplot(Indometh)"},{"path":"installation.html","id":"tex","chapter":"installation","heading":"TeX","text":"class generate high quality reports suitable submission supervisors, academic journals, etc. , need typesetting engine TeX. ways . easiest way using following commands:Mac, may get error “able write path” something like . case probably need open terminal run following two commands:thenThen, Mac PC, need :options : Windows, download install MikTeX. OSX, can download install MacTeX.","code":"\ninstall.packages(c('tinytex', 'rmarkdown'))sudo chown -R \\`whoami\\`:admin /usr/local/bin~/Library/TinyTeX/bin/\\*/tlmgr path add\ntinytex::install_tinytex()"},{"path":"installation.html","id":"phylochemistry","chapter":"installation","heading":"phylochemistry","text":"addition tidyverse, variety packages need, well datasets custom functions. call loaded following.First, attempt load phylochemistry, Windows, sure ’ve opened RStudio administrator (right click, “run administrator”):first time try , likely say: “need install following packages proceeding […] okay phylochemistry installs ?” say “yes”.","code":"\nbustalab <- TRUE\nsource(\"https://thebustalab.github.io/phylochemistry/phylochemistry.R\")"},{"path":"installation.html","id":"updating-r-and-r-packages","chapter":"installation","heading":"Updating R and R Packages","text":"Close RStudio, open plain R GUI, run following:Mac:PC:","code":"\ninstall.packages('remotes') #assuming it is not remotes installed\nremotes::install_github('andreacirilloac/updateR')\nupdateR::updateR()\ninstall.packages(\"installr\")\ninstallr::updateR()"},{"path":"installation.html","id":"r-scripts-on-google-drive","chapter":"installation","heading":"R scripts on Google Drive","text":"Sometimes want save R scripts Google Drive. R script Google Drive want open RStudio, get share link file use following command:, “IN_USE___” appear front file name Google Drive, others know using . done using file, can save close using:","code":"\nopenRGD(\"file_share_link_here\")\ncloseRGD(\"file_share_link_here\")"},{"path":"data-visualization.html","id":"data-visualization","chapter":"data visualization","heading":"data visualization","text":"Visualization one fun parts working data. section, jump visualization quickly possible - just prerequisites. Please note data visualization whole field (just google “data visualization” see happens). Data visualization also rife “trendy” visuals, misleading visuals, visuals look cool don’t actually communicate much information. touch topics briefly, spend time practicing represent data intuitive interpretable ways. Let’s get started!","code":""},{"path":"data-visualization.html","id":"section","chapter":"data visualization","heading":"","text":"","code":""},{"path":"data-visualization.html","id":"objects","chapter":"data visualization","heading":"objects","text":"R, data stored objects. can think objects “files” inside R session. phylochemistry provides variety objects us work . Let’s look create object. , can use arrow: <- . arrow take something store inside object. example:Now ’ve got new object called new_object, inside number 1. look ’s inside object, can simply type name object console:Easy! Let’s look one objects comes class code base. dimensions “algae_data” data set?","code":"\nnew_object <- 1\nnew_object \n## [1] 1\nalgae_data\n## # A tibble: 180 × 5\n##    replicate algae_strain harvesting_regime chemical_species\n##        <dbl> <chr>        <chr>             <chr>           \n##  1         1 Tsv1         Heavy             FAs             \n##  2         1 Tsv1         Heavy             saturated_Fas   \n##  3         1 Tsv1         Heavy             omega_3_polyuns…\n##  4         1 Tsv1         Heavy             monounsaturated…\n##  5         1 Tsv1         Heavy             polyunsaturated…\n##  6         1 Tsv1         Heavy             omega_6_polyuns…\n##  7         1 Tsv1         Heavy             lysine          \n##  8         1 Tsv1         Heavy             methionine      \n##  9         1 Tsv1         Heavy             essential_Aas   \n## 10         1 Tsv1         Heavy             non_essential_A…\n## # … with 170 more rows, and 1 more variable:\n## #   abundance <dbl>"},{"path":"data-visualization.html","id":"functions","chapter":"data visualization","heading":"functions","text":"Excellent - ’ve got data. Now need manipulate . need functions:function command tells R perform action!function begins ends parentheses: this_is_a_function()stuff inside parentheses details want function perform action: run_this_analysis(on_this_data)Let’s illustrate example. algae_data pretty big object. next chapter visualization, nice smaller dataset object work . Let’s use another tidyverse command called filter filter algae_data object. need tell filter command filter using “logical predicates” (things like equal : ==, less : <, greater : >, greater---equal-: <=, etc.). Let’s filter algae_data rows chemical_species equal FAs (fatty acids) preserved. look like chemical_species == \"FAs\". go:Cool! Now ’s just showing us 18 rows chemical_species fatty acids (FAs). Let’s write new, smaller dataset new object. use <-, remember?","code":"\nfilter(algae_data, chemical_species == \"FAs\")\n## # A tibble: 18 × 5\n##    replicate algae_strain harvesting_regime chemical_species\n##        <dbl> <chr>        <chr>             <chr>           \n##  1         1 Tsv1         Heavy             FAs             \n##  2         2 Tsv1         Heavy             FAs             \n##  3         3 Tsv1         Heavy             FAs             \n##  4         1 Tsv1         Light             FAs             \n##  5         2 Tsv1         Light             FAs             \n##  6         3 Tsv1         Light             FAs             \n##  7         1 Tsv2         Heavy             FAs             \n##  8         2 Tsv2         Heavy             FAs             \n##  9         3 Tsv2         Heavy             FAs             \n## 10         1 Tsv2         Light             FAs             \n## 11         2 Tsv2         Light             FAs             \n## 12         3 Tsv2         Light             FAs             \n## 13         1 Tsv11        Heavy             FAs             \n## 14         2 Tsv11        Heavy             FAs             \n## 15         3 Tsv11        Heavy             FAs             \n## 16         1 Tsv11        Light             FAs             \n## 17         2 Tsv11        Light             FAs             \n## 18         3 Tsv11        Light             FAs             \n## # … with 1 more variable: abundance <dbl>\nalgae_data_small <- filter(algae_data, chemical_species == \"FAs\")\nalgae_data_small\n## # A tibble: 18 × 5\n##    replicate algae_strain harvesting_regime chemical_species\n##        <dbl> <chr>        <chr>             <chr>           \n##  1         1 Tsv1         Heavy             FAs             \n##  2         2 Tsv1         Heavy             FAs             \n##  3         3 Tsv1         Heavy             FAs             \n##  4         1 Tsv1         Light             FAs             \n##  5         2 Tsv1         Light             FAs             \n##  6         3 Tsv1         Light             FAs             \n##  7         1 Tsv2         Heavy             FAs             \n##  8         2 Tsv2         Heavy             FAs             \n##  9         3 Tsv2         Heavy             FAs             \n## 10         1 Tsv2         Light             FAs             \n## 11         2 Tsv2         Light             FAs             \n## 12         3 Tsv2         Light             FAs             \n## 13         1 Tsv11        Heavy             FAs             \n## 14         2 Tsv11        Heavy             FAs             \n## 15         3 Tsv11        Heavy             FAs             \n## 16         1 Tsv11        Light             FAs             \n## 17         2 Tsv11        Light             FAs             \n## 18         3 Tsv11        Light             FAs             \n## # … with 1 more variable: abundance <dbl>"},{"path":"data-visualization.html","id":"ggplot-geoms","chapter":"data visualization","heading":"ggplot & geoms","text":"Now nice, small table can use practice data visualization. visualization, ’re going use ggplot2 - powerful set commands plot generation.three steps setting ggplot:Define data want use.using ggplot function’s data argument. run line, just shows grey plot space. ? ’s ’ve done told ggplot () want make plot (ii) data used. haven’t explained represent features data using ink.Define variables map onto axes.called aesthetic mapping done aes() function. aes() placed inside ggplot command. Now run , get axes!Use geometric shapes represent variables data.Map variables onto geometric features shapes. define shape used, use geom_* command. options , example, geom_point(), geom_boxplot(), geom_violin(). functions added plot using + sign. can use new line keep code getting wide, just make sure + sign end fo top line. Let’s try :way mapped variables dataset plot axes, can map variables dataset geometric features shapes using represent data. , , use aes() map variables onto geometric features shapes:plot , points bit small, fix ? can modify features shapes adding additional arguments geom_*() functions. change size points created geom_point() function, means need add size = argument. IMPORTANT! Please note map feature shape variable data(color/harvesting regime, ) goes inside aes(). contrast, map feature shape constant, goes outside aes(). ’s example:One powerful aspect ggplot ability quickly change mappings see alternative plots effective bringing trends data. example, modify plot switching harvesting_regime mapped:** Important note: Inside aes() function, map aesthetics (features geom’s shape) variable. Outside aes() function, map aesthetics constants. can see two plots - first one, color inside aes() mapped variable called harvesting_regime, size outside aes() call set constant 5. second plot, situation reversed, size inside aes() function mapped variable harvesting_regime, color outside aes() call mapped constant “black”.can also stack geoms top one another using multiple + signs. also don’t assign mappings geom.can probably guess right now, lots mappings can done, lots different ways look data!","code":"\nggplot(data = algae_data_small)\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance))\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) +\n  geom_point()\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) + \n  geom_point(aes(color = harvesting_regime))\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) + \n  geom_point(aes(color = harvesting_regime), size = 5)\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) +\n  geom_point(aes(size = harvesting_regime), color = \"black\")\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) + \n  geom_violin() +\n  geom_point(aes(color = harvesting_regime), size = 5)\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) +\n  geom_violin(aes(fill = algae_strain)) +\n  geom_point(aes(color = harvesting_regime, size = replicate))\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) +\n  geom_boxplot()"},{"path":"data-visualization.html","id":"markdown","chapter":"data visualization","heading":"markdown","text":"Now able filter data make plots, ready make reports show others data processing visualization . , use R Markdown. can open new markdown document RStudio clicking: File -> New File -> R Markdown. get template document compiles press “knit”.Customize document modifying title, add author: \"your_name\" header. Delete content header, compile . get page blank except title author name.can think markdown document stand-alone R Session. means need load class code base new markdown doument create. can adding “chunk” R code. looks like :can compilie document pdf. can also run R chunks right inside document create figures. notice things compile document:Headings: compile code, “# first analysis” creates header. can create headers various levels increasing number hashtags use front header. example, “## Part 1” create subheading, “### Part 1.1” create sub-subheading, .Headings: compile code, “# first analysis” creates header. can create headers various levels increasing number hashtags use front header. example, “## Part 1” create subheading, “### Part 1.1” create sub-subheading, .Plain text: Plain text R Markdown document creates plan text entry compiled document. can use explain analyses figures, etc.Plain text: Plain text R Markdown document creates plan text entry compiled document. can use explain analyses figures, etc.can modify output code chunk adding arguments header. Useful arguments fig.height, fig.width, fig.cap. Dr. Busta show class.can modify output code chunk adding arguments header. Useful arguments fig.height, fig.width, fig.cap. Dr. Busta show class.","code":""},{"path":"data-visualization.html","id":"exercises-i","chapter":"data visualization","heading":"exercises I","text":"set exercises ’re going practice filtering plotting data R Markdown. ’re going work two datasets: () algae_data (ii) alaska_lake_data. exercises, write code answers questions R Markdown report, compile pdf, submit Canvas. questions please let knowSome pointers:code goes page, don’t afraid wrap across multiple lines, shown examples.code goes page, don’t afraid wrap across multiple lines, shown examples.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.","code":""},{"path":"data-visualization.html","id":"algae","chapter":"data visualization","heading":"algae","text":"algae_data stored object called algae_data soon run source(\"https://thebustalab.github.io/phylochemistry/phylochemistry.R\"). question, filter data entries shown chemical_species “FAs” (remember quotes needed around FAs !). dimensions (.e. number rows columns) resulting dataset?algae_data stored object called algae_data soon run source(\"https://thebustalab.github.io/phylochemistry/phylochemistry.R\"). question, filter data entries shown chemical_species “FAs” (remember quotes needed around FAs !). dimensions (.e. number rows columns) resulting dataset?Now filter dataset entries algae_strain “Tsv1” shown. dimensions resulting dataset?Now filter dataset entries algae_strain “Tsv1” shown. dimensions resulting dataset?Now filter dataset entries abundance greater 250 shown. Note > can used filter command instead ==, numbers inside filter command require quotes around . dimensions resulting dataset?Now filter dataset entries abundance greater 250 shown. Note > can used filter command instead ==, numbers inside filter command require quotes around . dimensions resulting dataset?Make ggplot algae_strain x axis abundance y axis. Remember aes(). Use points (geom_point()) represent compound. don’t need color points. algae strain abundant compound compounds dataset?Make ggplot algae_strain x axis abundance y axis. Remember aes(). Use points (geom_point()) represent compound. don’t need color points. algae strain abundant compound compounds dataset?Make ggplot abundance x axis chemical_species y axis. Use points represent compound. don’t need color points. Generally speaking, two abundant classes chemical species algae strains? (FAs/Fas stand fatty acids, AAs/Aas stand amino acids.)Make ggplot abundance x axis chemical_species y axis. Use points represent compound. don’t need color points. Generally speaking, two abundant classes chemical species algae strains? (FAs/Fas stand fatty acids, AAs/Aas stand amino acids.)going show example can filter plot time. , nest filter command inside ggplot’s data argument:going show example can filter plot time. , nest filter command inside ggplot’s data argument:Using template, make plot shows just omega_3_polyunsaturated_Fas, algae_strain x axis, abundance y axis. Color points correspond harvesting_regime. Remember mapping feature shape onto variable must done inside aes(). Change plot points size = 5. Remember mapping features shape constant needs done outside aes(). harvesting regime leads higher levels omega_3_polyunsaturated_Fas?Use combination filtering plotting show abundance different chemical species just algae_strain called “Tsv1”. Use x y axis, well points represent measurements. Make point size correspond replicate, color points according harvesting regime.Use combination filtering plotting show abundance different chemical species just algae_strain called “Tsv1”. Use x y axis, well points represent measurements. Make point size correspond replicate, color points according harvesting regime.Make plot checks see chemical_species abundant light opposed heavy harvesting_regime three replicates. Use filtered data just one algae_strain shown, x y axis, points represent measurements. Make points size = 5 also set point’s alpha = 0.6. points colored according harvesting_regime. Make 3 plots, one strain algae.Make plot checks see chemical_species abundant light opposed heavy harvesting_regime three replicates. Use filtered data just one algae_strain shown, x y axis, points represent measurements. Make points size = 5 also set point’s alpha = 0.6. points colored according harvesting_regime. Make 3 plots, one strain algae.Take code made question . Remove filtering. Add following line end plot: facet_grid(.~algae_strain). Remember adding things plots done + sign, code look something like:Take code made question . Remove filtering. Add following line end plot: facet_grid(.~algae_strain). Remember adding things plots done + sign, code look something like:Also try, instead facet_grid(.~algae_strain), facet_grid(algae_strain~.) end plot command. (note swap position .~ relative algae_strain). means code look something like:advantages one extra line (.e. facet_grid) provide question 8?","code":"\nggplot(\n  data = filter(algae_data, chemical_species == \"essential_Aas\"),\n  aes(x = algae_strain, y = abundance)) +\ngeom_point()ggplot(data = algae_data, aes(x = <something>, y = <something else>)) +\n  geom_point(aes(<some things>), <some here too>) +\n  facet_grid(.~algae_strain)ggplot(data = algae_data, aes(x = <something>, y = <something else>)) +\n  geom_point(aes(<some things>), <some here too>) +\n  facet_grid(algae_strain~.)"},{"path":"data-visualization.html","id":"alaska-lakes","chapter":"data visualization","heading":"alaska lakes","text":"Use R view first lines alaska_lake_data dataset. best describe, written format, kind data data set.Use R view first lines alaska_lake_data dataset. best describe, written format, kind data data set.many variables Alaska lakes dataset?many variables Alaska lakes dataset?Filter data set meausurements free elements (.e. element_type “free”) shown. Remember, ’s ==, =. dimensions resulting dataset?Filter data set meausurements free elements (.e. element_type “free”) shown. Remember, ’s ==, =. dimensions resulting dataset?Make plot shows water temperatures lake. Don’t worry get warning message R “missing values”. hottest lake? coolest?Make plot shows water temperatures lake. Don’t worry get warning message R “missing values”. hottest lake? coolest?Make plot shows water temperature lake. x axis park, y axis water temp. Add geom_violin() plot first, geom_point(). Make points size = 5. Color points according water_temp. park four lakes similar temperatures?Make plot shows water temperature lake. x axis park, y axis water temp. Add geom_violin() plot first, geom_point(). Make points size = 5. Color points according water_temp. park four lakes similar temperatures?plot made question 5, apparent one lake NOAT much warmer others. Filter data entries park == \"NOAT\" shown (note double equals sign quotes around NOAT…). Combine filtering plotting use geom_point() make plot shows specific lake .plot made question 5, apparent one lake NOAT much warmer others. Filter data entries park == \"NOAT\" shown (note double equals sign quotes around NOAT…). Combine filtering plotting use geom_point() make plot shows specific lake .Make plot shows lake highest abundance sulfur.Make plot shows lake highest abundance sulfur.Make plot uses geom_point(). Set “shape” aesthetic points 21, .e. geom_point(aes(...), shape = 21). gives access new aesthetics: fill. also changes behaviour color aesthetic slightly, now controls border color, internal color. example (though doesn’t make nice plot):Make plot uses geom_point(). Set “shape” aesthetic points 21, .e. geom_point(aes(...), shape = 21). gives access new aesthetics: fill. also changes behaviour color aesthetic slightly, now controls border color, internal color. example (though doesn’t make nice plot):Now lots aesthetics can map : x, y, size, color, fill (leave shape set 21 now). Make plot design. include filtering, aesthetics listed , though whether map variable constant .done plot, take screen shot . Go GOOGLE SHEET, make slide (don’t include name), paste screen shot . Add small caption explains variables mapped.","code":"\nggplot(\n  data = filter(alaska_lake_data, lake == \"Lake_Narvakrak\"),\n  aes(x = lake, y = mg_per_L)\n) +\n  geom_point(\n    shape = 21, size = 10,\n    color = \"black\", fill = \"green\"\n  )"},{"path":"data-visualization.html","id":"section-1","chapter":"data visualization","heading":"","text":"","code":""},{"path":"data-visualization.html","id":"more-geoms","chapter":"data visualization","heading":"more geoms","text":"’ve looked filter data map variables data geometric shapes make plots. Let’s look things. examples, ’re going use data set called solvents. examples, ’d like introduce two new geoms. first geom_smooth() used two continuous variables. particularly nice geom_point() stacked top .Also, please aware geom_tile(), nice situations two discrete variables one continuous variable. geom_tile() makes often referred heat maps. Note geom_tile() somewhat similar geom_point(shape = 21), fill color aesthetics control fill color border color, respectively.examples illustrate , degree, correspondence type data interested plotting (number discrete continuous variables) types geoms can effectively used represent data.handy cheat sheet can help identify right geom situation. Please keep cheat sheet mind future plotting needs…can also combine geoms create detailed representations distributions:","code":"\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth() +\n  geom_point()\n## `geom_smooth()` using method = 'loess' and formula = 'y ~\n## x'\nggplot(\n  data = filter(algae_data, harvesting_regime == \"Heavy\"),\n  aes(x = algae_strain, y = chemical_species)\n) + \n  geom_tile(aes(fill = abundance), color = \"black\", size = 1)\ni2 <- iris %>%\n  mutate(Species2 = rep(c(\"A\",\"B\"), 75))\np <- ggplot(i2, aes(Sepal.Width, Sepal.Length, color = Species)) +\n  geom_point()\n\np + geom_xsidedensity(aes(y=stat(density), xfill = Species), position = \"stack\")+\n  geom_ysidedensity(aes(x=stat(density), yfill = Species2), position = \"stack\") +\n  theme_bw() + \n  facet_grid(Species~Species2, space = \"free\", scales = \"free\") +\n  labs(title = \"FacetGrid\", subtitle = \"Collapsing All Side Panels\") +\n  ggside(collapse = \"all\") +\n  scale_xfill_manual(values = c(\"darkred\",\"darkgreen\",\"darkblue\")) +\n  scale_yfill_manual(values = c(\"black\",\"gold\"))\nmpg %>% filter(cyl %in% c(4,6,8)) %>%\n  ggplot(aes(x = factor(cyl), y = hwy, fill = factor(cyl))) +\n  ggdist::stat_halfeye(\n    adjust = 0.5, justification = -0.2, .width = 0, point_colour = NA\n  ) +\n  geom_boxplot(width = 0.12, outlier.color = NA, alpha = 0.5) +\n  ggdist::stat_dots(side = \"left\", justification = 1.1, binwidth = .25)"},{"path":"data-visualization.html","id":"facets","chapter":"data visualization","heading":"facets","text":"alluded Exercises 1, possible map variables dataset geometric features shapes (.e. geoms). One common way facets. Faceting creates small multiples plot, shows different subset data based categorical variable choice. Let’s check ., can facet horizontal direction:can facet vertical direction:can time:Faceting great way describe variation plot without make geoms complicated. situations need generate lots lots facets, consider facet_wrap instead facet_grid:","code":"\nggplot(data = algae_data, aes(x = algae_strain, y = chemical_species)) + \n  geom_tile(aes(fill = abundance), color = \"black\") + \n  facet_grid(.~replicate)\nggplot(data = algae_data, aes(x = algae_strain, y = chemical_species)) + \n  geom_tile(aes(fill = abundance), color = \"black\") + \n  facet_grid(replicate~.)\nggplot(data = algae_data, aes(x = algae_strain, y = chemical_species)) + \n  geom_tile(aes(fill = abundance), color = \"black\") + \n  facet_grid(harvesting_regime~replicate)\nggplot(data = algae_data, aes(x = replicate, y = algae_strain)) + \n  geom_tile(aes(fill = abundance), color = \"black\") + \n  facet_wrap(chemical_species~.)"},{"path":"data-visualization.html","id":"scales","chapter":"data visualization","heading":"scales","text":"Every time define aesthetic mapping (e.g. aes(x = algae_strain)), defining new scale added plot. can control scales using scale_* family commands. Consider faceting example . , use geom_tile(aes(fill = abundance)) map abundance variable fill aesthetic tiles. creates scale called fill can adjust using scale_fill_*. case, fill mapped continuous variable fill scale color gradient. Therefore, scale_fill_gradient() command need change . Remember always type ?scale_fill_ console help find relevant help topics provide detail. Another option google: “modify color scale ggplot geom_tile”, undoubtedly turn wealth help.One particularly useful type scale color scales provided RColorBrewer:","code":"\nggplot(data = algae_data, aes(x = algae_strain, y = chemical_species)) + \n  geom_tile(aes(fill = abundance), color = \"black\") + \n  facet_grid(harvesting_regime~replicate) +\n  scale_fill_gradient(low = \"white\", high = \"black\") +\n  theme_classic()\ndisplay.brewer.all()\nggplot(mtcars) +\n  geom_point(\n    aes(x = mpg, y = factor(cyl), fill = factor(carb)), \n    shape = 21, size = 6\n  ) +\n  scale_fill_brewer(palette = \"Set1\")"},{"path":"data-visualization.html","id":"themes","chapter":"data visualization","heading":"themes","text":"far ’ve just looked control means data represented plot. also components plot , strictly speaking, data per se, rather non-data ink. controlled using theme() family commands. two ways go .ggplot comes handful built “complete themes”. change appearance plots respect non-data ink. Compare following plots:can also change individual components themes. can bit tricky, ’s explained run ?theme(). Hare example (google provide many, many ).Last, example combining scale_* theme* previous commands really get plot looking sharp.\nFigure 1.1: Vapor pressure function boiling point. scatter plot trendline showing vapor pressure thirty-two solvents (y-axis) function boiling points (x-axis). point represents boiling point vapor pressure one solvent. Data ‘solvents’ dataset used UMD CHEM5725.\n","code":"\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth() +\n  geom_point() +\n  theme_classic()\n## `geom_smooth()` using method = 'loess' and formula = 'y ~\n## x'\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth() +\n  geom_point() +\n  theme_dark()\n## `geom_smooth()` using method = 'loess' and formula = 'y ~\n## x'\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth() +\n  geom_point() +\n  theme_void()\n## `geom_smooth()` using method = 'loess' and formula = 'y ~\n## x'\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth() +\n  geom_point() +\n  theme(\n    text = element_text(size = 20, color = \"black\")\n  )\n## `geom_smooth()` using method = 'loess' and formula = 'y ~\n## x'\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth(color = \"#4daf4a\") +\n  scale_x_continuous(\n    name = \"Boiling Point\", breaks = seq(0,200,25), limits = c(30,210)\n  ) +\n  scale_y_continuous(\n    name = \"Vapor Pressure\", breaks = seq(0,600,50)\n  ) +\n  geom_point(color = \"#377eb8\", size = 4, alpha = 0.6) +\n  theme_bw() +\n  theme(\n    axis.text = element_text(color = \"black\"),\n    text = element_text(size = 16, color = \"black\")\n  )\n## `geom_smooth()` using method = 'loess' and formula = 'y ~\n## x'"},{"path":"data-visualization.html","id":"subplots","chapter":"data visualization","heading":"subplots","text":"can make subplots using patchwork package, comes source() command. Let’s see:","code":"\nplot1 <-  ggplot(\n            filter(alaska_lake_data, element_type == \"free\")\n          ) +\n          geom_violin(aes(x = park, y = mg_per_L)) + theme_classic() +\n          ggtitle(\"A\")\n\nplot2 <-  ggplot(\n            filter(alaska_lake_data, element_type == \"bound\")\n          ) +\n          geom_violin(aes(x = park, y = mg_per_L)) + theme_classic() +\n          ggtitle(\"B\")\n\nplot3 <-  ggplot(\n            filter(alaska_lake_data, element == \"C\")\n          ) +\n          geom_violin(aes(x = park, y = mg_per_L)) + theme_classic() +\n          coord_flip() + ggtitle(\"C\")\n\n(plot1 + plot2) / plot3"},{"path":"data-visualization.html","id":"d-scatter-plots","chapter":"data visualization","heading":"3D scatter plots","text":"phylochemistry contains function help make somewhat decent 3D scatter plots. Let’s look example (see ). , use function points3D. Se give data argument gives vectors data x, y, z axes, along vector uniquely identifies observation. also tell angle z axis want, integer ticks rounded, tick intervals. function returns data can pass ggplot make 3D plot.output points3D contains grid, axes, ticks, plotted using geom_segment. also contains points plotted geom_point, point segments plotted geom_segement. can take output points3D join original data, occurr according sample_unique_ID column. , can also plot point metadata:","code":"\npivot_wider(hawaii_aquifers, names_from = \"analyte\", values_from = \"abundance\") %>%\n  mutate(sample_unique_ID = paste0(aquifer_code, \"_\", well_name)) -> aquifers\n\noutput <- points3D(\n  data = data.frame(\n    x = aquifers$SiO2,\n    y = aquifers$Cl,\n    z = aquifers$Mg,\n    sample_unique_ID = aquifers$sample_unique_ID\n  ),\n  angle = pi/2.4,\n  tick_round = 10,\n  x_tick_interval = 10,\n  y_tick_interval = 20,\n  z_tick_interval = 20\n)\n\nstr(output)\n## List of 6\n##  $ grid          :'data.frame':  14 obs. of  4 variables:\n##   ..$ y   : num [1:14] 0 0 0 0 0 ...\n##   ..$ yend: num [1:14] 96.6 96.6 96.6 96.6 96.6 ...\n##   ..$ x   : num [1:14] 10 20 30 40 50 ...\n##   ..$ xend: num [1:14] 35.9 45.9 55.9 65.9 75.9 ...\n##  $ ticks         :'data.frame':  37 obs. of  4 variables:\n##   ..$ y   : num [1:37] 0 0 0 0 0 0 0 0 0 0 ...\n##   ..$ yend: num [1:37] 1.93 1.93 1.93 1.93 1.93 ...\n##   ..$ x   : num [1:37] 10 20 30 40 50 60 70 80 10 20 ...\n##   ..$ xend: num [1:37] 10.5 20.5 30.5 40.5 50.5 ...\n##  $ labels        :'data.frame':  29 obs. of  3 variables:\n##   ..$ y    : num [1:29] -11.2 -11.2 -11.2 -11.2 -11.2 -11.2 -11.2 -11.2 0 20 ...\n##   ..$ x    : num [1:29] 7.2 17.2 27.2 37.2 47.2 57.2 67.2 77.2 4.4 4.4 ...\n##   ..$ label: num [1:29] 10 20 30 40 50 60 70 80 0 20 ...\n##  $ axes          :'data.frame':  3 obs. of  4 variables:\n##   ..$ x   : num [1:3] 10 10 80\n##   ..$ xend: num [1:3] 80 10 106\n##   ..$ y   : num [1:3] 0 0 0\n##   ..$ yend: num [1:3] 0 280 96.6\n##  $ point_segments:'data.frame':  106 obs. of  4 variables:\n##   ..$ x   : num [1:106] 13 33.1 39.4 53.1 22.5 ...\n##   ..$ xend: num [1:106] 13 33.1 39.4 53.1 22.5 ...\n##   ..$ y   : num [1:106] 27.3 81.6 82.6 109.5 19.5 ...\n##   ..$ yend: num [1:106] 7.34 11.59 12.56 15.45 5.51 ...\n##  $ points        :'data.frame':  106 obs. of  3 variables:\n##   ..$ x               : num [1:106] 13 33.1 39.4 53.1 22.5 ...\n##   ..$ y               : num [1:106] 27.3 81.6 82.6 109.5 19.5 ...\n##   ..$ sample_unique_ID: chr [1:106] \"aquifer_1_Alewa_Heights_Spring\" \"aquifer_1_Beretania_High_Service\" \"aquifer_1_Beretania_Low_Service\" \"aquifer_1_Kuliouou_Well\" ...\noutput$points <- left_join(output$points, aquifers)\n## Joining, by = \"sample_unique_ID\"\n  \nggplot() +\n  geom_segment(\n    data = output$grid, aes(x = x, xend = xend, y = y, yend = yend),\n    color = \"grey80\"\n  ) +\n  geom_segment(data = output$axes, aes(x = x, xend = xend, y = y, yend = yend)) +\n  geom_segment(data = output$ticks, aes(x = x, xend = xend, y = y, yend = yend)) +\n  geom_text(\n    data = output$labels, aes(x = x, y = y, label = label),\n    hjust = 0.5\n  ) +\n  geom_segment(\n    data = output$point_segments,\n    aes(x = x, xend = xend, y = y, yend = yend),\n    linetype = \"dotted\", color = \"black\"\n  ) +\n  geom_point(\n    data = output$points, aes(x = x, y = y, fill = aquifer_code),\n    size = 3, shape = 21\n  ) +\n  theme_void() +\n  scale_fill_manual(values = discrete_palette)"},{"path":"data-visualization.html","id":"data-vis-exercises-ii","chapter":"data visualization","heading":"data vis exercises II","text":"set exercises ’re going practice making plots using dataset solvents. Well, don’t use solvents, use something else want, solvents fun one explore. Since now familiar filtering plotting data, prompts assignment going relatively open ended - care variables map x, y, fill, color, etc. Rather, expect submission demonstrate explored new topics covered previous chapter. includes geoms beyond geom_point() geom_violin(), facets, scale modifications, theme adjustments. creative! Explore solvents dataset. Find something interesting! Show mastered material. Don’t forget ggplot cheat sheet (see “Links” section book)., exercises, write code answers questions Script Editor window RStudio R Markdown document. compile file pdf submit Canvas. questions please let know.pointers:code goes page, don’t afraid wrap across multiple lines, shown examples previous set exercises.code goes page, don’t afraid wrap across multiple lines, shown examples previous set exercises.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.Create plot x y axes continuous variables. Add plot facet_grid, specify facets based categorical variable (ideally categorical variable small number total categories). Now make two versions plot, one uses scales = \"free\" feature facet_grid second (.e. one use facet_grid(<things>), uses facet_grid(<things>, scales = \"free\")). Write single caption describes plots, highlighting advantages provided plot . additional tips writing captions, please see “Writing” chapter book.Create plot x y axes continuous variables. Add plot facet_grid, specify facets based categorical variable (ideally categorical variable small number total categories). Now make two versions plot, one uses scales = \"free\" feature facet_grid second (.e. one use facet_grid(<things>), uses facet_grid(<things>, scales = \"free\")). Write single caption describes plots, highlighting advantages provided plot . additional tips writing captions, please see “Writing” chapter book.Using continuous variable one axis discrete (categorical) variable , create two plots identical except one uses geom_point(), uses geom_jitter(). Write single caption describes plots. caption highlight differences bewteen two plots describe case(s) think appropriate use geom_jitter() geom_point().Using continuous variable one axis discrete (categorical) variable , create two plots identical except one uses geom_point(), uses geom_jitter(). Write single caption describes plots. caption highlight differences bewteen two plots describe case(s) think appropriate use geom_jitter() geom_point().Make plot four aesthetic mappings (x y mappings count). Use scales_* family commands modify aspect scale create four mappings. Hint: scales somewhat tricky modify (alpha, linetype, …), scales easier modify (x, y, color, fill, shape). may need use google searches help . Queries along lines “modify point color ggplot” direct useful resource.Make plot four aesthetic mappings (x y mappings count). Use scales_* family commands modify aspect scale create four mappings. Hint: scales somewhat tricky modify (alpha, linetype, …), scales easier modify (x, y, color, fill, shape). may need use google searches help . Queries along lines “modify point color ggplot” direct useful resource.Make plot manually modify least three aspects theme (.e. use one build complete themes theme_classic(), rather, manually modify components theme using theme()). means inside theme() command, three arguments separated commas.Make plot manually modify least three aspects theme (.e. use one build complete themes theme_classic(), rather, manually modify components theme using theme()). means inside theme() command, three arguments separated commas.Identify relationship two variables dataset. Create plot optimized (see note) highlight features relationship. Write short caption describes plot trend ’ve identified highlighted. Note: realize word “optimize” clearly defined . ’s ok! judge optimized . Use caption make case plot optimized. Defend ideas argument!Identify relationship two variables dataset. Create plot optimized (see note) highlight features relationship. Write short caption describes plot trend ’ve identified highlighted. Note: realize word “optimize” clearly defined . ’s ok! judge optimized . Use caption make case plot optimized. Defend ideas argument!Watch video bar plots. Add section end R Markdown document made Part 2 describes problem outlined video one potential solution problem.Watch video bar plots. Add section end R Markdown document made Part 2 describes problem outlined video one potential solution problem.","code":""},{"path":"data-visualization.html","id":"section-2","chapter":"data visualization","heading":"","text":"","code":""},{"path":"data-visualization.html","id":"further-reading","chapter":"data visualization","heading":"further reading","text":"additional explanations ggplot2: ggplot2-book.Check incredible geoms easy access using R ggplot2: R Graph Gallery. Use make figures attractive easy interpret!challenge, try implementing awesome color scales: Famous R Color Palettes. Note optimized colorblind individuals optimized continuous hue gradients, etc.list data visualization sins: Friends Don’t Let Friends. interesting things !information data visualization graphics theory, check works Edward Tufte: Edward Tufte. digital text covers similar topics : [Look Data] (https://socviz.co/lookatdata.html).examples award winning data visualization: Information Beautiful Awards Data Vis Inspiration.Additional color palettes: MetBrewer Paletteer.","code":""},{"path":"data-wrangling.html","id":"data-wrangling","chapter":"data wrangling","heading":"data wrangling","text":"Data wrangling refers process organizing, cleaning , making “raw” data set ready downstream analysis. key piece data analysis process. look different aspects wrangling, including data import, subsetting, pivoting, summarizing data.","code":""},{"path":"data-wrangling.html","id":"data-import","chapter":"data wrangling","heading":"data import","text":"analyze data stored computer can indeed import RStudio.easiest way use interactive command readCSV(), function comes phylochemistry source command. run readCSV() console, navigate data hard drive.Another option read data path. , need know “path” data file. essentially street address data computer’s hard drive. Paths look different Mac PC.Mac: /Users/lucasbusta/Documents/sample_data_set.csv (note forward slashes!)PC: C:\\\\Computer\\\\Documents\\\\sample_data_set.csv (note double backward slashes!)can quickly find paths files via following:Mac: Locate file Finder. Right-click file, hold Option key, click “Copy  Pathname”PC: Locate file Windows Explorer. Hold Shift key right-click file. Click “Copy Path”paths, can read data using read_csv command. ’ll run read_csv(\"<path_to_your_data>\"). Note use QUOTES \"\"! necessary. Also make sure path uses appropriate direction slashes operating system.","code":""},{"path":"data-wrangling.html","id":"subsetting","chapter":"data wrangling","heading":"subsetting","text":"far, always passing whole data sets ggplot plotting. However, suppose wanted get just certain portions dataset, say, specific columns, specific rows? ways :","code":"\n# To look at a single column (the third column)\nhead(alaska_lake_data[,3])\n## # A tibble: 6 × 1\n##   water_temp\n##        <dbl>\n## 1       6.46\n## 2       6.46\n## 3       6.46\n## 4       6.46\n## 5       6.46\n## 6       6.46\n\n# To look at select columns:\nhead(alaska_lake_data[,2:5])\n## # A tibble: 6 × 4\n##   park  water_temp    pH element\n##   <chr>      <dbl> <dbl> <chr>  \n## 1 BELA        6.46  7.69 C      \n## 2 BELA        6.46  7.69 N      \n## 3 BELA        6.46  7.69 P      \n## 4 BELA        6.46  7.69 Cl     \n## 5 BELA        6.46  7.69 S      \n## 6 BELA        6.46  7.69 F\n\n# To look at a single row (the second row)\nhead(alaska_lake_data[2,])\n## # A tibble: 1 × 7\n##   lake  park  water_temp    pH element mg_per_L element_type\n##   <chr> <chr>      <dbl> <dbl> <chr>      <dbl> <chr>       \n## 1 Devi… BELA        6.46  7.69 N          0.028 bound\n\n# To look at select rows:\nhead(alaska_lake_data[2:5,])\n## # A tibble: 4 × 7\n##   lake  park  water_temp    pH element mg_per_L element_type\n##   <chr> <chr>      <dbl> <dbl> <chr>      <dbl> <chr>       \n## 1 Devi… BELA        6.46  7.69 N          0.028 bound       \n## 2 Devi… BELA        6.46  7.69 P          0     bound       \n## 3 Devi… BELA        6.46  7.69 Cl        10.4   free        \n## 4 Devi… BELA        6.46  7.69 S          0.62  free\n\n# To look at just a single column, by name\nhead(alaska_lake_data$pH)\n## [1] 7.69 7.69 7.69 7.69 7.69 7.69\n\n# To look at select columns by name\nhead(select(alaska_lake_data, park, water_temp))\n## # A tibble: 6 × 2\n##   park  water_temp\n##   <chr>      <dbl>\n## 1 BELA        6.46\n## 2 BELA        6.46\n## 3 BELA        6.46\n## 4 BELA        6.46\n## 5 BELA        6.46\n## 6 BELA        6.46"},{"path":"data-wrangling.html","id":"tidy-data","chapter":"data wrangling","heading":"tidy data","text":"make data tables hand, ’s often easy make wide-style table like following. , abundances 7 different fatty acids 10 different species tabulated. fatty acid gets row, species, column.format nice filling hand (lab notebook similar), groove ggplot tidyverse functions well. need convert long-style table. done using pivot_longer(). can think function transforming data’s column names (column names) data matrix’s values (case, measurements) variables (.e. columns). can fatty acid dataset using command . , specify data want transform (data = fadb_sample), need tell columns want transform (cols = 2:11), want new variable contains column names called (names_to = \"plant_species\") want new variable contains matrix values called (values_to = \"relative_abundance\"). together now:Brilliant! Now tidy, long-style table can used ggplot.","code":"\nhead(fadb_sample)\n## # A tibble: 6 × 11\n##   fatty_acid         Agonandra_brasiliensis Agonandra_silva…\n##   <chr>                               <dbl>            <dbl>\n## 1 Hexadecanoic acid                     3.4              1  \n## 2 Octadecanoic acid                     6.2              0.1\n## 3 Eicosanoic acid                       4.7              3.5\n## 4 Docosanoic acid                      77.4              0.4\n## 5 Tetracosanoic acid                    1.4              1  \n## 6 Hexacosanoic acid                     1.9             12.6\n## # … with 8 more variables: Agonandra_excelsa <dbl>,\n## #   Heisteria_silvianii <dbl>, Malania_oleifera <dbl>,\n## #   Ximenia_americana <dbl>, Ongokea_gore <dbl>,\n## #   Comandra_pallida <dbl>, Buckleya_distichophylla <dbl>,\n## #   Nuytsia_floribunda <dbl>\npivot_longer(data = fadb_sample, cols = 2:11, names_to = \"plant_species\", values_to = \"relative_abundance\")\n## # A tibble: 70 × 3\n##    fatty_acid        plant_species          relative_abunda…\n##    <chr>             <chr>                             <dbl>\n##  1 Hexadecanoic acid Agonandra_brasiliensis              3.4\n##  2 Hexadecanoic acid Agonandra_silvatica                 1  \n##  3 Hexadecanoic acid Agonandra_excelsa                   1.2\n##  4 Hexadecanoic acid Heisteria_silvianii                 2.9\n##  5 Hexadecanoic acid Malania_oleifera                    0.7\n##  6 Hexadecanoic acid Ximenia_americana                   3.3\n##  7 Hexadecanoic acid Ongokea_gore                        1  \n##  8 Hexadecanoic acid Comandra_pallida                    2.3\n##  9 Hexadecanoic acid Buckleya_distichophyl…              1.6\n## 10 Hexadecanoic acid Nuytsia_floribunda                  3.8\n## # … with 60 more rows"},{"path":"data-wrangling.html","id":"the-pipe","chapter":"data wrangling","heading":"the pipe (%>%)","text":"seen create new objects using <-, filtering plotting data using, example:However, analyses get complex, code can get long hard read. ’re going use pipe %>% help us . Check :Neat! Another way think pipe:pipe become important analyses become sophisticated, happens quickly start working summary statistics, shall now see…","code":"\nggplot(filter(alaska_lake_data, park == \"BELA\"), aes(x = pH, y = lake)) + geom_col()\nalaska_lake_data %>%\n  filter(park == \"BELA\") %>%\n  ggplot(aes(x = pH, y = lake)) + geom_col()"},{"path":"data-wrangling.html","id":"summary-statistics","chapter":"data wrangling","heading":"summary statistics","text":"far, plotting raw data. well good, always suitable. Often scientific questions answered looking raw data alone, sometimes much raw data plot. , need summary statistics - things like averages, standard deviations, . metrics can computed Excel, programming can time consuming, especially group statistics. Consider example , uses ny_trees dataset. NY Trees dataset contains information nearly half million trees New York City (considerable filtering simplification):300,000 observations 14 variables! ’s 4.2M data points! Now, average standard deviation height diameter tree species within NY borough? values change trees parks versus sidewalk pits?? don’t even know one begin approach questions using traditional spreadsheets. , answer questions ease using two new commands: group_by() summarize(). Let’s get .Say want know (course, visualize) mean standard deviation heights tree species NYC. can see data first columns NY trees dataset , calculate statistics? R, mean can computed mean() standard deviation can calculated sd(). use function summarize() calculate summary statistics. , can calculate average standard deviation trees data set follows:Great! species? need subdivide data species, compute mean standard deviation, recombine results new table. First, use group_by(). Note ny_trees, species indicated column called spc_latin. data grouped, can use summarize() compute statistics.Bam. Mean height tree species. can also count number observations using n():Cool! summarize() powerful though, can many summary statistics :Now can use data plotting. , use new geom, geom_pointrange, takes x y aesthetics, usual, also requires two additional y-ish aesthetics ymin ymax (xmin xmax want vary along x). Also, note aesthetic mappings xmin xmax, can use mathematical expression: mean-stdev mean+stdev, respectivey. case, mean_height - stdev_height mean_height + stdev_height. Let’s see action:Cool! Just like , ’ve found (visualized) average standard deviation tree heights, species, NYC. doesn’t stop . can use group_by() summarize() multiple variables (.e. groups). can examine properties tree species NYC borough. Let’s check :Now summary statistics tree species within borough. different previous plot now additional variable (boroname) summarized dataset. additional variable needs encoded plot. Let’s map boroname x facet tree species, used x. ’ll also manually modify theme element strip.text.y get species names readable position.Excellent! really want go something pretty:Now getting somewhere. looks like really big maple trees (Acer) Queens.","code":"\nhead(ny_trees)\n## # A tibble: 6 × 14\n##   tree_height tree_diameter address        tree_loc pit_type\n##         <dbl>         <dbl> <chr>          <chr>    <chr>   \n## 1        21.1             6 1139 57 STREET Front    Sidewal…\n## 2        59.0             6 2220 BERGEN A… Across   Sidewal…\n## 3        92.4            13 2254 BERGEN A… Across   Sidewal…\n## 4        50.2            15 2332 BERGEN A… Across   Sidewal…\n## 5        95.0            21 2361 EAST   7… Front    Sidewal…\n## 6        67.5            19 2409 EAST   7… Front    Continu…\n## # … with 9 more variables: soil_lvl <chr>, status <chr>,\n## #   spc_latin <chr>, spc_common <chr>, trunk_dmg <chr>,\n## #   zipcode <dbl>, boroname <chr>, latitude <dbl>,\n## #   longitude <dbl>\nny_trees %>%\n  summarize(mean_height = mean(tree_height))\n## # A tibble: 1 × 1\n##   mean_height\n##         <dbl>\n## 1        72.6\n\nny_trees %>%\n  summarize(stdev_height = sd(tree_height))\n## # A tibble: 1 × 1\n##   stdev_height\n##          <dbl>\n## 1         28.7\nny_trees %>%\n  group_by(spc_latin) %>%\n  summarize(mean_height = mean(tree_height))\n## # A tibble: 12 × 2\n##    spc_latin              mean_height\n##    <chr>                        <dbl>\n##  1 ACER PLATANOIDES              82.6\n##  2 ACER RUBRUM                  106. \n##  3 ACER SACCHARINUM              65.6\n##  4 FRAXINUS PENNSYLVANICA        60.6\n##  5 GINKGO BILOBA                 90.4\n##  6 GLEDITSIA TRIACANTHOS         53.0\n##  7 PLATANUS ACERIFOLIA           82.0\n##  8 PYRUS CALLERYANA              21.0\n##  9 QUERCUS PALUSTRIS             65.5\n## 10 QUERCUS RUBRA                111. \n## 11 TILIA CORDATA                 98.8\n## 12 ZELKOVA SERRATA              101.\nny_trees %>%\n  group_by(spc_latin) %>%\n  summarize(number_of_individuals = n())\n## # A tibble: 12 × 2\n##    spc_latin              number_of_individuals\n##    <chr>                                  <int>\n##  1 ACER PLATANOIDES                       67260\n##  2 ACER RUBRUM                            11506\n##  3 ACER SACCHARINUM                       13161\n##  4 FRAXINUS PENNSYLVANICA                 16987\n##  5 GINKGO BILOBA                          15672\n##  6 GLEDITSIA TRIACANTHOS                  48707\n##  7 PLATANUS ACERIFOLIA                    80075\n##  8 PYRUS CALLERYANA                       39125\n##  9 QUERCUS PALUSTRIS                      37058\n## 10 QUERCUS RUBRA                          10020\n## 11 TILIA CORDATA                          25970\n## 12 ZELKOVA SERRATA                        13221\nny_trees %>%\n  group_by(spc_latin) %>%\n  summarize(\n    mean_height = mean(tree_height),\n    stdev_height = sd(tree_height)\n  ) -> ny_trees_by_spc_summ\nny_trees_by_spc_summ\n## # A tibble: 12 × 3\n##    spc_latin              mean_height stdev_height\n##    <chr>                        <dbl>        <dbl>\n##  1 ACER PLATANOIDES              82.6        17.6 \n##  2 ACER RUBRUM                  106.         15.7 \n##  3 ACER SACCHARINUM              65.6        16.6 \n##  4 FRAXINUS PENNSYLVANICA        60.6        21.3 \n##  5 GINKGO BILOBA                 90.4        24.5 \n##  6 GLEDITSIA TRIACANTHOS         53.0        13.0 \n##  7 PLATANUS ACERIFOLIA           82.0        16.0 \n##  8 PYRUS CALLERYANA              21.0         5.00\n##  9 QUERCUS PALUSTRIS             65.5         6.48\n## 10 QUERCUS RUBRA                111.         20.7 \n## 11 TILIA CORDATA                 98.8        32.6 \n## 12 ZELKOVA SERRATA              101.         10.7\nny_trees_by_spc_summ %>%\nggplot() +\n  geom_pointrange(\n      aes(\n        y = spc_latin,\n        x = mean_height,\n        xmin = mean_height - stdev_height,\n        xmax = mean_height + stdev_height\n      )\n    )\nny_trees %>%\n  group_by(spc_latin, boroname) %>%\n  summarize(\n    mean_diam = mean(tree_diameter),\n    stdev_diam = sd(tree_diameter)\n  ) -> ny_trees_by_spc_boro_summ\nny_trees_by_spc_boro_summ\n## # A tibble: 48 × 4\n## # Groups:   spc_latin [12]\n##    spc_latin        boroname  mean_diam stdev_diam\n##    <chr>            <chr>         <dbl>      <dbl>\n##  1 ACER PLATANOIDES Bronx         13.9        6.74\n##  2 ACER PLATANOIDES Brooklyn      15.4       14.9 \n##  3 ACER PLATANOIDES Manhattan     11.6        8.45\n##  4 ACER PLATANOIDES Queens        15.1       12.9 \n##  5 ACER RUBRUM      Bronx         11.4        7.88\n##  6 ACER RUBRUM      Brooklyn      10.5        7.41\n##  7 ACER RUBRUM      Manhattan      6.63       4.23\n##  8 ACER RUBRUM      Queens        14.1        8.36\n##  9 ACER SACCHARINUM Bronx         19.7       10.5 \n## 10 ACER SACCHARINUM Brooklyn      22.2       10.1 \n## # … with 38 more rows\nny_trees_by_spc_boro_summ %>%\nggplot() +\n  geom_pointrange(\n    aes(\n      y = boroname,\n      x = mean_diam,\n      xmin = mean_diam-stdev_diam,\n      xmax = mean_diam+stdev_diam\n    )\n  ) +\n  facet_grid(spc_latin~.) +\n  theme(\n    strip.text.y = element_text(angle = 0)\n  )\nny_trees_by_spc_boro_summ %>%\nggplot() +\n  geom_pointrange(\n    aes(\n      y = boroname,\n      x = mean_diam,\n      xmin = mean_diam-stdev_diam,\n      xmax = mean_diam+stdev_diam,\n      fill = spc_latin\n    ), color = \"black\", shape = 21\n  ) +\n  labs(\n    y = \"Borough\", \n    x = \"Trunk diameter\",\n    caption = str_wrap(\"Figure 1: Diameters of trees in New York City. Points correspond to average diameters of each tree species in each borough. Horizontal lines indicate the standard deviation of tree diameters. Points are colored according to tree species.\", width = 80)\n  ) +\n  facet_grid(spc_latin~.) +\n  guides(fill = \"none\") +\n  scale_fill_brewer(palette = \"Paired\") +\n  theme_bw() +\n  theme(\n    strip.text.y = element_text(angle = 0),\n    plot.caption = element_text(hjust = 0.5)\n  )"},{"path":"data-wrangling.html","id":"ordering","chapter":"data wrangling","heading":"ordering","text":"can also sort order data frame based specific column command arrange(). Let’s quick look. Suppose wanted know lake coldest:suppose wanted know warmest?arrange() work grouped data, particularly useful combination slice(), can show us first n elements group:looks like coldest lakes three parks Devil Mountain Lake, Wild Lake, Desperation Lake!","code":"\narrange(alaska_lake_data, water_temp)\n## # A tibble: 220 × 7\n##    lake             park  water_temp    pH element mg_per_L\n##    <chr>            <chr>      <dbl> <dbl> <chr>      <dbl>\n##  1 Desperation_Lake NOAT        2.95  6.34 C          2.1  \n##  2 Desperation_Lake NOAT        2.95  6.34 N          0.005\n##  3 Desperation_Lake NOAT        2.95  6.34 P          0    \n##  4 Desperation_Lake NOAT        2.95  6.34 Cl         0.2  \n##  5 Desperation_Lake NOAT        2.95  6.34 S          2.73 \n##  6 Desperation_Lake NOAT        2.95  6.34 F          0.01 \n##  7 Desperation_Lake NOAT        2.95  6.34 Br         0    \n##  8 Desperation_Lake NOAT        2.95  6.34 Na         1.11 \n##  9 Desperation_Lake NOAT        2.95  6.34 K          0.16 \n## 10 Desperation_Lake NOAT        2.95  6.34 Ca         5.87 \n## # … with 210 more rows, and 1 more variable:\n## #   element_type <chr>\narrange(alaska_lake_data, desc(water_temp))\n## # A tibble: 220 × 7\n##    lake      park  water_temp    pH element mg_per_L\n##    <chr>     <chr>      <dbl> <dbl> <chr>      <dbl>\n##  1 Lava_Lake BELA        20.2  7.42 C          8.3  \n##  2 Lava_Lake BELA        20.2  7.42 N          0.017\n##  3 Lava_Lake BELA        20.2  7.42 P          0.001\n##  4 Lava_Lake BELA        20.2  7.42 Cl         2.53 \n##  5 Lava_Lake BELA        20.2  7.42 S          0.59 \n##  6 Lava_Lake BELA        20.2  7.42 F          0.04 \n##  7 Lava_Lake BELA        20.2  7.42 Br         0.01 \n##  8 Lava_Lake BELA        20.2  7.42 Na         2.93 \n##  9 Lava_Lake BELA        20.2  7.42 K          0.57 \n## 10 Lava_Lake BELA        20.2  7.42 Ca        11.8  \n## # … with 210 more rows, and 1 more variable:\n## #   element_type <chr>\nalaska_lake_data %>%\n  group_by(park) %>%\n  arrange(water_temp) %>%\n  slice(1)\n## # A tibble: 3 × 7\n## # Groups:   park [3]\n##   lake  park  water_temp    pH element mg_per_L element_type\n##   <chr> <chr>      <dbl> <dbl> <chr>      <dbl> <chr>       \n## 1 Devi… BELA        6.46  7.69 C            3.4 bound       \n## 2 Wild… GAAR        5.5   6.98 C            6.5 bound       \n## 3 Desp… NOAT        2.95  6.34 C            2.1 bound"},{"path":"data-wrangling.html","id":"mutate","chapter":"data wrangling","heading":"mutate","text":"One last thing exercises… another command called mutate(). like summarize calculates user-defined statistics, creates output per-observation level instead group. means doesn’t make data set smaller, fact makes bigger, creating new row new variables defined inside mutate(). can also take grouped data. really useful calculating percentages within groups. example: within park, percent park’s total dissolved sulfur lake ?percent columns park add 100%, , example, Devil Mountain Lake 32.3% BELA’s dissolved sulfur.","code":"\nalaska_lake_data %>%\n  filter(element == \"S\") %>%\n  group_by(park) %>%\n  select(lake, park, element, mg_per_L) %>%\n  mutate(percent_S = mg_per_L/sum(mg_per_L)*100)\n## # A tibble: 20 × 5\n## # Groups:   park [3]\n##    lake                park  element mg_per_L percent_S\n##    <chr>               <chr> <chr>      <dbl>     <dbl>\n##  1 Devil_Mountain_Lake BELA  S           0.62     32.3 \n##  2 Imuruk_Lake         BELA  S           0.2      10.4 \n##  3 Kuzitrin_Lake       BELA  S           0.29     15.1 \n##  4 Lava_Lake           BELA  S           0.59     30.7 \n##  5 North_Killeak_Lake  BELA  S           0.04      2.08\n##  6 White_Fish_Lake     BELA  S           0.18      9.38\n##  7 Iniakuk_Lake        GAAR  S          12.1      13.2 \n##  8 Kurupa_Lake         GAAR  S          12.4      13.6 \n##  9 Lake_Matcharak      GAAR  S          13.3      14.5 \n## 10 Lake_Selby          GAAR  S           7.92      8.64\n## 11 Nutavukti_Lake      GAAR  S           2.72      2.97\n## 12 Summit_Lake         GAAR  S           3.21      3.50\n## 13 Takahula_Lake       GAAR  S           5.53      6.03\n## 14 Walker_Lake         GAAR  S           5.77      6.30\n## 15 Wild_Lake           GAAR  S          28.7      31.3 \n## 16 Desperation_Lake    NOAT  S           2.73     25.8 \n## 17 Feniak_Lake         NOAT  S           4.93     46.5 \n## 18 Lake_Kangilipak     NOAT  S           0.55      5.19\n## 19 Lake_Narvakrak      NOAT  S           1.38     13.0 \n## 20 Okoklik_Lake        NOAT  S           1.01      9.53"},{"path":"data-wrangling.html","id":"exercises","chapter":"data wrangling","heading":"exercises","text":"Isn’t seven powerfully magical number? Isn’t seven powerfully magical number? Yes… think idea seven-part assignment greatly appeal alchemist.set exercises going use periodic table. run source() can load data set using periodic_table. Please use dataset run analyses answer following questions/prompts. Compile answers R Markdown document, compile pdf, upload Canvas assignment. Please let know questions. Good luck, fun!pointers:code goes page, please wrap across multiple lines, shown examples previous set exercises.code goes page, please wrap across multiple lines, shown examples previous set exercises.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.axis tick labels overlapping visible, something fix . solutions : move legend top plot (theme(legend.position = \"top\")), rotate text (theme(axis.text.x = element_text(angle = 90)), make text smaller (theme(axis.text.x = element_text(size = 8)).axis tick labels overlapping visible, something fix . solutions : move legend top plot (theme(legend.position = \"top\")), rotate text (theme(axis.text.x = element_text(angle = 90)), make text smaller (theme(axis.text.x = element_text(size = 8)).Make plot using geom_point() shows average atomic weight elements discovered year spanned dataset (.e. average weight elements discovered 1900? 1901? 1902? etc.). see trend, particularly 1950. think caused trend?Make plot using geom_point() shows average atomic weight elements discovered year spanned dataset (.e. average weight elements discovered 1900? 1901? 1902? etc.). see trend, particularly 1950. think caused trend?column state_at_RT indicates state element room temperate. Make plot shows average first ionization potential elements belonging state group indicated state_at_RT (.e. average 1st ionization potential elements solid room temp? liquid? etc.). highest?column state_at_RT indicates state element room temperate. Make plot shows average first ionization potential elements belonging state group indicated state_at_RT (.e. average 1st ionization potential elements solid room temp? liquid? etc.). highest?Filter dataset elements atomic number less 85 included. Considering elements, average standard deviation boiling points type crystal_structure? Make plot using geom_pointrange() shows mean standard deviation groups. ’s elements cubic crystal structure?Filter dataset elements atomic number less 85 included. Considering elements, average standard deviation boiling points type crystal_structure? Make plot using geom_pointrange() shows mean standard deviation groups. ’s elements cubic crystal structure?Now filter original dataset elements atomic number less 37 considered. elements dataset belong first four periods. average abundance four periods seawater? .e. average abundance elements period 1? period 2? etc. period abundant? context “CHON” mean? (rock band, though also excellent, especially song features GoYama)Now filter original dataset elements atomic number less 37 considered. elements dataset belong first four periods. average abundance four periods seawater? .e. average abundance elements period 1? period 2? etc. period abundant? context “CHON” mean? (rock band, though also excellent, especially song features GoYama)Now filter original dataset elements atomic number less 103 considered. Filter elements group number 18 excluded. Using twice-filtered dataset, compute average, minimum, maximum values electronegativiy group_number. Use geom_point() geom_errorbar() illustrate average, minimum, maximum values group number.Now filter original dataset elements atomic number less 103 considered. Filter elements group number 18 excluded. Using twice-filtered dataset, compute average, minimum, maximum values electronegativiy group_number. Use geom_point() geom_errorbar() illustrate average, minimum, maximum values group number.Filter dataset elements atomic number less 85 considered. Group color. Now filter color == \"colorless\". remaining elements, widest range specific heats? Use geom_point() geom_errorbar() illustrate mean standard deviation color’s specific heats.Filter dataset elements atomic number less 85 considered. Group color. Now filter color == \"colorless\". remaining elements, widest range specific heats? Use geom_point() geom_errorbar() illustrate mean standard deviation color’s specific heats.learned many things course far. read_csv(), filter(), ggplot(), now group_by(), summarize(), mutate(), arrange(), slice(). Using commands, create one graphics illustrate consider one interesting trends data set choosing. Use theme elements scales enhance plot. Give plot nice caption based caption guide book. Impress !learned many things course far. read_csv(), filter(), ggplot(), now group_by(), summarize(), mutate(), arrange(), slice(). Using commands, create one graphics illustrate consider one interesting trends data set choosing. Use theme elements scales enhance plot. Give plot nice caption based caption guide book. Impress !","code":""},{"path":"data-wrangling.html","id":"further-reading-1","chapter":"data wrangling","heading":"further reading","text":"sure check Tidy Data Tutor: https://tidydatatutor.com/vis.html. easy way visualize ’s going data wrangling!","code":""},{"path":"dimensionality-reduction.html","id":"dimensionality-reduction","chapter":"dimensionality reduction","heading":"dimensionality reduction","text":"previous chapters, looked explore data sets visualizing many variables manually identifying trends. Sometimes, encounter data sets many variables, reasonable manually select certain variables create plots manually search trends. cases, need dimensionality reduction - set techniques helps us identify variables driving differences among samples. course, conduct dimensionality reduction useing runMatrixAnalysis(), function loaded R Session run source() command.Matrix analyses can bit tricky set . two things can help us : () use template runMatrixAnalysis() (see ) (ii) critical think data terms samples analytes. Let’s consider Alaska lakes data set:can see dataset comprised measurements various analytes (.e. several chemical elements, well water_temp, pH), different samples (.e. lakes). need tell runMatrixAnalysis() function column relates samples analytes structure. See image explanation.","code":"\nalaska_lake_data\n## # A tibble: 220 × 7\n##    lake              park  water_temp    pH element mg_per_L\n##    <chr>             <chr>      <dbl> <dbl> <chr>      <dbl>\n##  1 Devil_Mountain_L… BELA        6.46  7.69 C          3.4  \n##  2 Devil_Mountain_L… BELA        6.46  7.69 N          0.028\n##  3 Devil_Mountain_L… BELA        6.46  7.69 P          0    \n##  4 Devil_Mountain_L… BELA        6.46  7.69 Cl        10.4  \n##  5 Devil_Mountain_L… BELA        6.46  7.69 S          0.62 \n##  6 Devil_Mountain_L… BELA        6.46  7.69 F          0.04 \n##  7 Devil_Mountain_L… BELA        6.46  7.69 Br         0.02 \n##  8 Devil_Mountain_L… BELA        6.46  7.69 Na         8.92 \n##  9 Devil_Mountain_L… BELA        6.46  7.69 K          1.2  \n## 10 Devil_Mountain_L… BELA        6.46  7.69 Ca         5.73 \n## # … with 210 more rows, and 1 more variable:\n## #   element_type <chr>"},{"path":"dimensionality-reduction.html","id":"pca","chapter":"dimensionality reduction","heading":"pca","text":"“analytes driving differences among samples?”\n“analytes data set correlated?”","code":""},{"path":"dimensionality-reduction.html","id":"theory","chapter":"dimensionality reduction","heading":"theory","text":"PCA looks variance high dimensional data set chooses new axes within data set align directions containing highest variance. new axes called principal components. Let’s look example:example , three dimensional space can reduced two dimensional space principal components analysis. New axes (principal components) selected (bold arrows left) become x y axes principal components space (right).can run visualize principal components analyses using runMatrixAnalysis() function example . can see output, command provides sample_IDs, sample information, coordinates sample 2D projection (“PCA plot”) raw data, case wish processing.Let’s plot 2D projection Alaska lakes data:Great! plot can see White Fish Lake North Killeak Lake, BELA park, quite different parks (separated others along dimension 1, .e. first principal component). time, Wild Lake, Iniakuk Lake, Walker Lake, several lakes GAAR park different others (separated others along dimension 2, .e. second principal component).Important question: makes lakes listed different others? Certainly aspect chemistry, since ’s data analysis built upon, determine analyte(s) driving differences among lakes see PCA plot?","code":"\nAK_lakes_pca <- runMatrixAnalysis(\n  data = alaska_lake_data,\n  analysis = c(\"pca\"),\n  column_w_names_of_multiple_analytes = \"element\",\n  column_w_values_for_multiple_analytes = \"mg_per_L\",\n  columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n  columns_w_additional_analyte_info = \"element_type\",\n  columns_w_sample_ID_info = c(\"lake\", \"park\"),\n  scale_variance = TRUE\n)\n## Replacing NAs in your data with mean\nhead(AK_lakes_pca)\n## # A tibble: 6 × 18\n##   sample_unique_ID      lake  park   Dim.1  Dim.2 water_temp\n##   <chr>                 <chr> <chr>  <dbl>  <dbl>      <dbl>\n## 1 Devil_Mountain_Lake_… Devi… BELA   0.229 -0.861       6.46\n## 2 Imuruk_Lake_BELA      Imur… BELA  -1.17  -1.62       17.4 \n## 3 Kuzitrin_Lake_BELA    Kuzi… BELA  -0.918 -1.15        8.06\n## 4 Lava_Lake_BELA        Lava… BELA   0.219 -1.60       20.2 \n## 5 North_Killeak_Lake_B… Nort… BELA   9.46   0.450      11.3 \n## 6 White_Fish_Lake_BELA  Whit… BELA   4.17  -0.972      12.0 \n## # … with 12 more variables: pH <dbl>, C <dbl>, N <dbl>,\n## #   P <dbl>, Cl <dbl>, S <dbl>, F <dbl>, Br <dbl>,\n## #   Na <dbl>, K <dbl>, Ca <dbl>, Mg <dbl>\nggplot(data = AK_lakes_pca, aes(x = Dim.1, y = Dim.2)) +\n  geom_point(aes(fill = park), shape = 21, size = 4, alpha = 0.8) +\n  geom_label_repel(aes(label = lake), alpha = 0.5) +\n  theme_classic()"},{"path":"dimensionality-reduction.html","id":"ordination-plots","chapter":"dimensionality reduction","heading":"ordination plots","text":"Let’s look access information analytes major contributors principal component. important tell analytes associated particular dimensions, extension, analytes associated (markers ) particular groups PCA plot. can determined using ordination plot. Let’s look example. can obtain ordination plot information using runMatrixAnalysis() analysis = \"pca_ord\":can now visualize ordination plot using standard ggplot plotting techniques. Note use geom_label_repel() filter() label certain segments ordination plot. need use geom_label_repel(), use built geom_label(), geom_label_repel() can make labelling segments easier.Great! read ordination plot:considering one analyte’s vector: vector’s projected value axis shows much variance aligned principal component.considering one analyte’s vector: vector’s projected value axis shows much variance aligned principal component.considering two analyte vectors: angle two vectors indicates correlated two variables . point direction, highly correlated. meet 90 degrees, correlated. meet ~180 degrees, negatively correlated. say one analyte “1.9” respect dimension 2 another “-1.9” respect dimension 2. Let’s also say vectors ~“0” respect dimension 1.considering two analyte vectors: angle two vectors indicates correlated two variables . point direction, highly correlated. meet 90 degrees, correlated. meet ~180 degrees, negatively correlated. say one analyte “1.9” respect dimension 2 another “-1.9” respect dimension 2. Let’s also say vectors ~“0” respect dimension 1.ordination plot , can now see abundances K, Cl, Br, Na major contributors variance first principal component (first dimension). abundances elements make White Fish Lake North Killeak Lake different lakes. can also see abundances N, S, Ca major contributors variance second dimension, means elements ar set Wild Lake, Iniakuk Lake, Walker Lake, several lakes GAAR park apart rest lakes data set. slightly easier understand look overlay two plots, often called “biplot”:Note plot ordination data circular layout segments. Sometimes much easier plot (interpret!) alternatives:","code":"## Replacing NAs in your data with mean\n## # A tibble: 6 × 3\n##   analyte      Dim.1   Dim.2\n##   <chr>        <dbl>   <dbl>\n## 1 water_temp 0.0750  -0.261 \n## 2 pH         0.686    0.0185\n## 3 C          0.290   -0.242 \n## 4 N          0.00435  0.714 \n## 5 P          0.473   -0.0796\n## 6 Cl         0.953    0.0148\nAK_lakes_pca_ord <- runMatrixAnalysis(\n  data = alaska_lake_data,\n  analysis = c(\"pca_ord\"),\n  column_w_names_of_multiple_analytes = \"element\",\n  column_w_values_for_multiple_analytes = \"mg_per_L\",\n  columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n  columns_w_additional_analyte_info = \"element_type\",\n  columns_w_sample_ID_info = c(\"lake\", \"park\")\n)\n## Replacing NAs in your data with mean\nhead(AK_lakes_pca_ord)\n## # A tibble: 6 × 3\n##   analyte      Dim.1   Dim.2\n##   <chr>        <dbl>   <dbl>\n## 1 water_temp 0.0750  -0.261 \n## 2 pH         0.686    0.0185\n## 3 C          0.290   -0.242 \n## 4 N          0.00435  0.714 \n## 5 P          0.473   -0.0796\n## 6 Cl         0.953    0.0148\n\nggplot(AK_lakes_pca_ord) +\n  geom_segment(aes(x = 0, y = 0, xend = Dim.1, yend = Dim.2, color = analyte), size = 1) +\n  geom_circle(aes(x0 = 0, y0 = 0, r = 1)) +\n  geom_label_repel(\n    data = filter(AK_lakes_pca_ord, Dim.1 > 0.9, Dim.2 < 0.1, Dim.2 > -0.1),\n    aes(x = Dim.1, y = Dim.2, label = analyte), xlim = c(1,1.5)\n  ) +\n  geom_label_repel(\n    data = filter(AK_lakes_pca_ord, Dim.2 > 0.5),\n    aes(x = Dim.1, y = Dim.2, label = analyte), direction = \"y\", ylim = c(1,1.5)\n  ) +\n  coord_cartesian(xlim = c(-1,1.5), ylim = c(-1,1.5)) +\n  theme_bw()\nAK_lakes_pca <- runMatrixAnalysis(\n  data = alaska_lake_data,\n  analysis = c(\"pca\"),\n  column_w_names_of_multiple_analytes = \"element\",\n  column_w_values_for_multiple_analytes = \"mg_per_L\",\n  columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n  columns_w_additional_analyte_info = \"element_type\",\n  columns_w_sample_ID_info = c(\"lake\", \"park\"),\n  scale_variance = TRUE\n)\n## Replacing NAs in your data with mean\n\nAK_lakes_pca_ord <- runMatrixAnalysis(\n  data = alaska_lake_data,\n  analysis = c(\"pca_ord\"),\n  column_w_names_of_multiple_analytes = \"element\",\n  column_w_values_for_multiple_analytes = \"mg_per_L\",\n  columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n  columns_w_additional_analyte_info = \"element_type\",\n  columns_w_sample_ID_info = c(\"lake\", \"park\")\n)\n## Replacing NAs in your data with mean\n\nggplot() +\n  geom_point(\n    data = AK_lakes_pca, \n    aes(x = Dim.1, y = Dim.2, fill = park), shape = 21, size = 4, alpha = 0.8\n  ) +\n  # geom_label_repel(aes(label = lake), alpha = 0.5) +\n  geom_segment(\n    data = AK_lakes_pca_ord,\n    aes(x = 0, y = 0, xend = Dim.1, yend = Dim.2, color = analyte),\n    size = 1\n  ) +\n  scale_color_manual(values = discrete_palette) +\n  theme_classic()\nAK_lakes_pca_ord %>%\n  ggplot(aes(x = Dim.1, y = analyte)) +\n    geom_point(aes(fill = analyte), shape = 22, size = 3) +\n    scale_fill_manual(values = discrete_palette) +\n    theme_bw()"},{"path":"dimensionality-reduction.html","id":"principal-components","chapter":"dimensionality reduction","heading":"principal components","text":"also can access information much variance data set explained principal component, can plot using ggplot:Cool! can see first principal component retains nearly 50% variance original dataset, second dimension contains 20%. can derive important notion PCA visualization : scales two axes need distances points x y directions comparable. can accomplished using coord_fixed() addition ggplots.","code":"\nAK_lakes_pca_dim <- runMatrixAnalysis(\n  data = alaska_lake_data,\n  analysis = c(\"pca_dim\"),\n  column_w_names_of_multiple_analytes = \"element\",\n  column_w_values_for_multiple_analytes = \"mg_per_L\",\n  columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n  columns_w_additional_analyte_info = \"element_type\",\n  columns_w_sample_ID_info = c(\"lake\", \"park\")\n)\n## Replacing NAs in your data with mean\nhead(AK_lakes_pca_dim)\n## # A tibble: 6 × 2\n##   principal_component percent_variance_explained\n##                 <dbl>                      <dbl>\n## 1                   1                      48.8 \n## 2                   2                      18.6 \n## 3                   3                      11.6 \n## 4                   4                       7.88\n## 5                   5                       4.68\n## 6                   6                       3.33\n\nggplot(\n  data = AK_lakes_pca_dim, \n  aes(x = principal_component, y = percent_variance_explained)\n) +\n  geom_line() +\n  geom_point() +\n  theme_bw()"},{"path":"dimensionality-reduction.html","id":"exercises-1","chapter":"dimensionality reduction","heading":"exercises","text":"set exercises, filling runMatrixAnalysis() template, can use colnames() function help specify long list column names rather typing hand. example, periodic table data set, can refer set columns (columns 10 20) following command:can use command template, example . notation colnames(periodic_table_subset)[c(5:7,9:25)], can mark columns 5 - 7 9 - 25 columns_w_values_for_single_analyte (note happens run c(5:7,9:25) console, happens run colnames(periodic_table_subset)[c(5:7,9:25)] console). notation colnames(periodic_table_subset)[c(1:4, 8)] can mark columns 1 - 4 column 8 columns_w_sample_ID_info (note happens run c(1:4, 8) console, happens run colnames(periodic_table_subset)[c(1:4, 8)] console).","code":"\ncolnames(periodic_table_subset)[10:20]\n##  [1] \"electronegativity_pauling\"         \n##  [2] \"first_ionization_poten_eV\"         \n##  [3] \"second_ionization_poten_eV\"        \n##  [4] \"third_ionization_poten_eV\"         \n##  [5] \"electron_affinity_eV\"              \n##  [6] \"atomic_radius_ang\"                 \n##  [7] \"ionic_radius_ang\"                  \n##  [8] \"covalent_radius_ang\"               \n##  [9] \"atomic_volume_cm3_per_mol\"         \n## [10] \"electrical_conductivity_mho_per_cm\"\n## [11] \"specific_heat_J_per_g_K\"\ncolnames(periodic_table_subset)[c(18:20, 23:25)]\n## [1] \"atomic_volume_cm3_per_mol\"         \n## [2] \"electrical_conductivity_mho_per_cm\"\n## [3] \"specific_heat_J_per_g_K\"           \n## [4] \"thermal_conductivity_W_per_m_K\"    \n## [5] \"polarizability_A_cubed\"            \n## [6] \"heat_atomization_kJ_per_mol\""},{"path":"dimensionality-reduction.html","id":"human-metabolomics","chapter":"dimensionality reduction","heading":"human metabolomics","text":"questions, work dataset describing metabolomics data (.e. abundances > 100 different biochemicals) 93 human patients, Chronic Kidney Disease. task discover biomarker Chronic Kidney Disease. means need determine metabolite whose abundance strongly associated disease. complete following:Run PCA analysis metabolomics_data (.e. runMatrixAnalysis() analysis = \"pca\")Plot results analysis determine principal component (.e. dimension) separates healthy kidney_disease samples.Obtain ordination plot coordinates analytes PCA analysis (.e. runMatrixAnalysis() analysis = \"pca_ord\"). words, plot correspond original data set?Visualize ordination plot determine analytes strongly associated principal component (.e. dimension) separates healthy kidney_disease samples.Bingo! analytes associated Chronic Kidney Disease biomarkers .Complete PCA analysis creating scree plot (.e. use analysis = \"pca_dim\"). words, plot mean?","code":""},{"path":"dimensionality-reduction.html","id":"grape-vine-chemistry","chapter":"dimensionality reduction","heading":"grape vine chemistry","text":"set quesions, work dataset describing metabolomics data (.e. abundances > 100 different biochemicals) 5 different wine grape varieties. task discover biomarker Chardonnay biomarker Cabernet Sauvignon. means need identify two metabolites, associated one two grape varieties. complete following:Run PCA analysis wine_grape_data (.e. runMatrixAnalysis() analysis = \"pca\")Plot results analysis determine principal component (.e. dimension) separates Chardonnay samples varieties Cabernet Sauvignon samples varieties.Obtain ordination plot coordinates analytes PCA analysis (.e. runMatrixAnalysis() analysis = \"pca_ord\"). words, plot correspond original data set?Visualize ordination plot determine analytes strongly associated principal component (.e. dimension) separates Chardonnay samples varieties Cabernet Sauvignon samples varieties.Bingo! analytes associated varieites biomarkers .Complete PCA analysis creating scree plot (.e. use analysis = \"pca_dim\"). words, plot mean?","code":""},{"path":"dimensionality-reduction.html","id":"further-reading-2","chapter":"dimensionality reduction","heading":"further reading","text":"","code":""},{"path":"dimensionality-reduction.html","id":"tsne-and-umap","chapter":"dimensionality reduction","heading":"tsne and umap","text":"","code":"\nset.seed(235)\nrunMatrixAnalysis(\n  data = hops_components,\n  analysis = \"pca\",\n  column_w_names_of_multiple_analytes = NULL,\n  column_w_values_for_multiple_analytes = NULL,\n  columns_w_values_for_single_analyte = colnames(hops_components)[c(5:12)],\n  columns_w_additional_analyte_info = NULL,\n  columns_w_sample_ID_info = colnames(hops_components)[c(1:4)],\n  na_replacement = \"mean\"\n) -> pca_data\npca_data$technique <- \"pca_data\"\ncolnames(pca_data) <- gsub(\"\\\\.\", \"_\", colnames(pca_data))\npca_data$Dim_1 <- as.numeric(scale(pca_data$Dim_1))\npca_data$Dim_2 <- as.numeric(scale(pca_data$Dim_2))\n\n\nrunMatrixAnalysis(\n  data = hops_components,\n  analysis = \"umap\",\n  column_w_names_of_multiple_analytes = NULL,\n  column_w_values_for_multiple_analytes = NULL,\n  columns_w_values_for_single_analyte = colnames(hops_components)[c(5:12)],\n  columns_w_additional_analyte_info = NULL,\n  columns_w_sample_ID_info = colnames(hops_components)[c(1:4)],\n  na_replacement = \"mean\"\n) -> umap_data\numap_data$technique <- \"umap_data\"\numap_data$Dim_1 <- as.numeric(scale(umap_data$Dim_1))\numap_data$Dim_2 <- as.numeric(scale(umap_data$Dim_2))\n\n\nrunMatrixAnalysis(\n  data = hops_components,\n  analysis = \"tsne\",\n  column_w_names_of_multiple_analytes = NULL,\n  column_w_values_for_multiple_analytes = NULL,\n  columns_w_values_for_single_analyte = colnames(hops_components)[c(5:12)],\n  columns_w_additional_analyte_info = NULL,\n  columns_w_sample_ID_info = colnames(hops_components)[c(1:4)],\n  na_replacement = \"mean\"\n) -> tsne_data\ntsne_data$technique <- \"tsne_data\"\ntsne_data$Dim_1 <- as.numeric(scale(tsne_data$Dim_1))\ntsne_data$Dim_2 <- as.numeric(scale(tsne_data$Dim_2))\n\n\ndata <- rbind(pca_data, umap_data, tsne_data)\n\np1 <- ggplot(data) +\n  geom_point(aes(x = Dim_1, y = Dim_2, fill = hop_origin), shape = 21, size= 4) +\n  facet_grid(technique~., scales = \"free\") +\n  scale_fill_brewer(palette = \"Set1\")\n\np2 <- ggplot(data) +\n  geom_point(aes(x = Dim_1, y = Dim_2, fill = hop_brewing_usage), shape = 21, size= 4) +\n  facet_grid(technique~., scales = \"free\") +\n  scale_fill_brewer(palette = \"Set1\")\n\np1 + p2"},{"path":"dimensionality-reduction.html","id":"further-reading-3","chapter":"dimensionality reduction","heading":"further reading","text":"https://datavizpyr.com/--make-umap-plot--r/https://datavizpyr.com/--make-tsne-plot--r/https://pair-code.github.io/understanding-umap/https://www.youtube.com/watch?v=jth4kEvJ3P8","code":""},{"path":"clustering.html","id":"clustering","chapter":"clustering","heading":"clustering","text":"","code":""},{"path":"clustering.html","id":"heirarchical-clustering","chapter":"clustering","heading":"heirarchical clustering","text":"","code":""},{"path":"clustering.html","id":"theory-1","chapter":"clustering","heading":"theory","text":"“samples closely related?”far looking plot raw data, summarize data, reduce data set’s dimensionality. ’s time look identify relationships samples data sets. example: Alaska lakes dataset, lake similar, chemically speaking, Lake Narvakrak? Answering requires calculating numeric distances samples based chemical properties. , first thing need distance matrix:Please note can get distance matrices directly runMatrixAnalysis specifying analysis = \"dist\":can distance matrices though, lots . Let’s start looking example hierarchical clustering. , just need tell runMatrixAnalysis() use analysis = \"hclust\":works! Now can plot cluster diagram ggplot add-called ggtree. ’ve seen ggplot takes “data” argument (.e. ggplot(data = <some_data>) + geom_*() etc.). contrast, ggtree takes argument called tr, though ’re using runMatrixAnalysis() function, can treat two (data tr) , , use: ggtree(tr = <output_from_runMatrixAnalysis>) + geom_*() etc.Note ggtree also comes several great new geoms: geom_tiplab() geom_tippoint(). Let’s try :Cool! Though plot use tweaking… let’s try:nice!","code":"\ndist <- runMatrixAnalysis(\n    data = alaska_lake_data,\n    analysis = c(\"dist\"),\n    column_w_names_of_multiple_analytes = \"element\",\n    column_w_values_for_multiple_analytes = \"mg_per_L\",\n    columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n    columns_w_additional_analyte_info = \"element_type\",\n    columns_w_sample_ID_info = c(\"lake\", \"park\")\n)\n## Replacing NAs in your data with mean\n\nas.matrix(dist)[1:3,1:3]\n##                          Devil_Mountain_Lake_BELA\n## Devil_Mountain_Lake_BELA                 0.000000\n## Imuruk_Lake_BELA                         3.672034\n## Kuzitrin_Lake_BELA                       1.663147\n##                          Imuruk_Lake_BELA\n## Devil_Mountain_Lake_BELA         3.672034\n## Imuruk_Lake_BELA                 0.000000\n## Kuzitrin_Lake_BELA               3.062381\n##                          Kuzitrin_Lake_BELA\n## Devil_Mountain_Lake_BELA           1.663147\n## Imuruk_Lake_BELA                   3.062381\n## Kuzitrin_Lake_BELA                 0.000000\nAK_lakes_clustered <- runMatrixAnalysis(\n    data = alaska_lake_data,\n    analysis = \"hclust\",\n    column_w_names_of_multiple_analytes = \"element\",\n    column_w_values_for_multiple_analytes = \"mg_per_L\",\n    columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n    columns_w_additional_analyte_info = \"element_type\",\n    columns_w_sample_ID_info = c(\"lake\", \"park\"),\n    na_replacement = \"mean\"\n)\n## Replacing NAs in your data with mean\nAK_lakes_clustered\n## # A tibble: 39 × 25\n##    sample_unique_ID   lake  park  parent  node branch.length\n##    <chr>              <chr> <chr>  <int> <int>         <dbl>\n##  1 Devil_Mountain_La… Devi… BELA      33     1         0.987\n##  2 Imuruk_Lake_BELA   Imur… BELA      39     2         0.820\n##  3 Kuzitrin_Lake_BELA Kuzi… BELA      38     3         0.703\n##  4 Lava_Lake_BELA     Lava… BELA      31     4         0.743\n##  5 North_Killeak_Lak… Nort… BELA      21     5         5.62 \n##  6 White_Fish_Lake_B… Whit… BELA      22     6         3.89 \n##  7 Iniakuk_Lake_GAAR  Inia… GAAR      28     7         1.25 \n##  8 Kurupa_Lake_GAAR   Kuru… GAAR      35     8         0.954\n##  9 Lake_Matcharak_GA… Lake… GAAR      35     9         0.954\n## 10 Lake_Selby_GAAR    Lake… GAAR      36    10         1.12 \n## # … with 29 more rows, and 19 more variables: label <chr>,\n## #   isTip <lgl>, x <dbl>, y <dbl>, branch <dbl>,\n## #   angle <dbl>, water_temp <dbl>, pH <dbl>, C <dbl>,\n## #   N <dbl>, P <dbl>, Cl <dbl>, S <dbl>, F <dbl>, Br <dbl>,\n## #   Na <dbl>, K <dbl>, Ca <dbl>, Mg <dbl>\nlibrary(ggtree)\nAK_lakes_clustered %>%\nggtree() +\n  geom_tiplab() +\n  geom_tippoint() +\n  theme_classic()\nAK_lakes_clustered %>%\nggtree() +\n    geom_tiplab(aes(label = lake), offset = 1, align = TRUE) +\n    geom_tippoint(shape = 21, aes(fill = park), size = 4) +\n    scale_x_continuous(limits = c(0,10)) +\n    scale_fill_brewer(palette = \"Set1\") +\n    # theme_classic() +\n    theme(\n      legend.position = c(0.2,0.8)\n    )"},{"path":"clustering.html","id":"further-reading-4","chapter":"clustering","heading":"further reading","text":"information plotting annotated trees, see: https://yulab-smu.top/treedata-book/chapter10.html.clustering, see: https://ryanwingate.com/intro--machine-learning/unsupervised/hierarchical--density-based-clustering/.","code":""},{"path":"clustering.html","id":"exercises-2","chapter":"clustering","heading":"exercises","text":"set exercises, please use runMatrixAnalysis() run visualize hierarchical cluster analysis main datasets worked far, except NY_trees. means: algae_data (algae strains similar ?), alaska_lake_data (lakes similar ?). solvents (solvents similar ?). also means use periodic table (elements similar ?), though please don’t use whole periodic table, rather, use periodic_table_subset. Please also conduct heirarchical clustering analysis dataset choice provided source() code. , create () tree diagram shows “samples” data set related based numerical data associated , (ii) caption diagram, (iii) describe, two sentences, interesting trend see diagram. can ignore columns contain categorical data, can list columns “additional_analyte_info”.assignment, may find colnames() function square bracket-subsetting useful. list subset column names dataset . example:","code":"\ncolnames(solvents)\n##  [1] \"solvent\"             \"formula\"            \n##  [3] \"boiling_point\"       \"melting_point\"      \n##  [5] \"density\"             \"miscible_with_water\"\n##  [7] \"solubility_in_water\" \"relative_polarity\"  \n##  [9] \"vapor_pressure\"      \"CAS_number\"         \n## [11] \"formula_weight\"      \"refractive_index\"   \n## [13] \"specific_gravity\"    \"category\"\n\ncolnames(solvents)[1:3]\n## [1] \"solvent\"       \"formula\"       \"boiling_point\"\n\ncolnames(solvents)[c(1,5,7)]\n## [1] \"solvent\"             \"density\"            \n## [3] \"solubility_in_water\""},{"path":"clustering.html","id":"k-means-and-dbscan","chapter":"clustering","heading":"k-means and dbscan","text":"“samples fall definable clusters?”","code":""},{"path":"clustering.html","id":"theory-2","chapter":"clustering","heading":"theory","text":"One questions ’ve asking “samples closely related?”. ’ve answering question using clustering. However, now know run principal components analyses, can use another approach. alternative approach called k-means, can help us decide assign data clusters. generally desirable small number clusters, however, must balanced variance within cluster big. strike balance point, elbow method used. , must first determine maximum within-group variance possible number clusters. illustration shown :One know within-group variances, find “elbow” point - point minimum angle theta - thus picking outcome good balance cluster number within-cluster variance (illustrated B C.)Let’s try k-means using runMatrixAnalysis. example, let’s run PCA projection alaska lakes data set. can set analysis = \"kmeans\". , application load show us threshold value number clusters want. set number clusters close app. context markdown document, simply provide number clusters parameters argument:can plot results color according group kmeans suggested. can also highlight groups using geom_mark_ellipse. Note recommended specify fill label geom_mark_ellipse:another method define clusters call dbscan. method, points necessarily assigned cluster, define clusters according set parameters, instead simply defining number clusteres, kmeans. interactive mode, runMatrixAnalysis() load interactive means selecting parameters defining dbscan clusters (“k”, “threshold”). context markdown document, simply provide “k” “threshold” parameters argument:can make plot way, please note get geom_mark_ellipse omit ellipse NAs need feed data without NAs:","code":"\nalaska_lake_data_pca <- runMatrixAnalysis(\n    data = alaska_lake_data,\n    analysis = c(\"pca\"),\n    column_w_names_of_multiple_analytes = \"element\",\n    column_w_values_for_multiple_analytes = \"mg_per_L\",\n    columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n    columns_w_additional_analyte_info = \"element_type\",\n    columns_w_sample_ID_info = c(\"lake\", \"park\")\n)\n## Replacing NAs in your data with mean\n\nalaska_lake_data_pca_clusters <- runMatrixAnalysis(\n    data = alaska_lake_data_pca,\n    analysis = c(\"kmeans\"),\n    parameters = c(5),\n    column_w_names_of_multiple_analytes = NULL,\n    column_w_values_for_multiple_analytes = NULL,\n    columns_w_values_for_single_analyte = c(\"Dim.1\", \"Dim.2\"),\n    columns_w_sample_ID_info = \"sample_unique_ID\"\n)\n## Using 5 as a value for cluster_number.\n\nalaska_lake_data_pca_clusters <- left_join(alaska_lake_data_pca_clusters, alaska_lake_data_pca) \nalaska_lake_data_pca_clusters$cluster <- factor(alaska_lake_data_pca_clusters$cluster)\nggplot() +\n  geom_point(\n    data = alaska_lake_data_pca_clusters,\n    aes(x = Dim.1, y = Dim.2, fill = cluster), shape = 21, size = 5, alpha = 0.6\n  ) +\n  geom_mark_ellipse(\n    data = alaska_lake_data_pca_clusters,\n    aes(x = Dim.1, y = Dim.2, label = cluster, fill = cluster), alpha = 0.2\n  ) +\n  theme_classic() +\n  coord_cartesian(xlim = c(-7,12), ylim = c(-4,5)) +\n  scale_fill_manual(values = discrete_palette) \nalaska_lake_data_pca <- runMatrixAnalysis(\n    data = alaska_lake_data,\n    analysis = c(\"pca\"),\n    column_w_names_of_multiple_analytes = \"element\",\n    column_w_values_for_multiple_analytes = \"mg_per_L\",\n    columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n    columns_w_additional_analyte_info = \"element_type\",\n    columns_w_sample_ID_info = c(\"lake\", \"park\")\n) \n## Replacing NAs in your data with mean\n\nalaska_lake_data_pca_clusters <- runMatrixAnalysis(\n    data = alaska_lake_data_pca,\n    analysis = c(\"dbscan\"),\n    parameters = c(4, 0.45),\n    column_w_names_of_multiple_analytes = NULL,\n    column_w_values_for_multiple_analytes = NULL,\n    columns_w_values_for_single_analyte = c(\"Dim.1\", \"Dim.2\"),\n    columns_w_sample_ID_info = \"sample_unique_ID\"\n)\n## Using 4 as a value for k.\n## Using 0.45 as a value for threshold.\n\nalaska_lake_data_pca_clusters <- left_join(alaska_lake_data_pca_clusters, alaska_lake_data_pca)\nalaska_lake_data_pca_clusters$cluster <- factor(alaska_lake_data_pca_clusters$cluster)\nggplot() +\n  geom_point(\n    data = alaska_lake_data_pca_clusters,\n    aes(x = Dim.1, y = Dim.2, fill = cluster), shape = 21, size = 5, alpha = 0.6\n  ) +\n  geom_mark_ellipse(\n    data = drop_na(alaska_lake_data_pca_clusters),\n    aes(x = Dim.1, y = Dim.2, label = cluster, fill = cluster), alpha = 0.2\n  ) +\n  theme_classic() +\n  coord_cartesian(xlim = c(-7,12), ylim = c(-4,5)) +\n  scale_fill_manual(values = discrete_palette) "},{"path":"clustering.html","id":"summarize-by-cluster","chapter":"clustering","heading":"summarize by cluster","text":"One important point: using kmeans dbscan, can use clusters groupings summary statistics. example, suppose want see differences abundances certain chemicals among clusters:","code":"\nalaska_lake_data_pca <- runMatrixAnalysis(\n  data = alaska_lake_data,\n  analysis = c(\"pca\"),\n  column_w_names_of_multiple_analytes = \"element\",\n  column_w_values_for_multiple_analytes = \"mg_per_L\",\n  columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n  columns_w_additional_analyte_info = \"element_type\",\n  columns_w_sample_ID_info = c(\"lake\", \"park\")\n)\n## Replacing NAs in your data with mean\n\nalaska_lake_data_pca_clusters <- runMatrixAnalysis(\n  data = alaska_lake_data_pca,\n  analysis = c(\"dbscan\"),\n  parameters = c(4, 0.45),\n  column_w_names_of_multiple_analytes = NULL,\n  column_w_values_for_multiple_analytes = NULL,\n  columns_w_values_for_single_analyte = c(\"Dim.1\", \"Dim.2\"),\n  columns_w_sample_ID_info = \"sample_unique_ID\",\n  columns_w_additional_analyte_info = colnames(alaska_lake_data_pca)[6:18]\n) \n## Using 4 as a value for k.\n## Using 0.45 as a value for threshold.\n\nalaska_lake_data_pca_clusters <- left_join(alaska_lake_data_pca_clusters, alaska_lake_data_pca)\n\nalaska_lake_data_pca_clusters %>%\n  select(cluster, S, Ca) %>%\n  pivot_longer(cols = c(2,3), names_to = \"analyte\", values_to = \"mg_per_L\") %>%\n  drop_na() %>%\n  group_by(cluster, analyte) -> alaska_lake_data_pca_clusters_clean\n\nplot_2 <- ggplot() + \n  geom_col(\n    data = summarize(\n      alaska_lake_data_pca_clusters_clean,\n      mean = mean(mg_per_L), sd = sd(mg_per_L)\n    ),\n    aes(x = cluster, y = mean, fill = cluster),\n    color = \"black\", alpha = 0.6\n  ) +\n  geom_errorbar(\n    data = summarize(\n      alaska_lake_data_pca_clusters_clean,\n      mean = mean(mg_per_L), sd = sd(mg_per_L)\n    ),\n    aes(x = cluster, ymin = mean-sd, ymax = mean+sd, fill = cluster),\n    color = \"black\", alpha = 0.6, width = 0.5, size = 1\n  ) +\n  facet_grid(.~analyte) + theme_bw() +\n  geom_jitter(\n    data = alaska_lake_data_pca_clusters_clean,\n    aes(x = cluster, y = mg_per_L, fill = cluster), width = 0.05,\n    shape = 21\n  ) +\n  scale_fill_manual(values = discrete_palette) \n\nplot_1<- ggplot() +\n  geom_point(\n    data = alaska_lake_data_pca_clusters,\n    aes(x = Dim.1, y = Dim.2, fill = cluster), shape = 21, size = 5, alpha = 0.6\n  ) +\n  geom_mark_ellipse(\n    data = drop_na(alaska_lake_data_pca_clusters),\n    aes(x = Dim.1, y = Dim.2, label = cluster, fill = cluster), alpha = 0.2\n  ) +\n  theme_classic() + coord_cartesian(xlim = c(-7,12), ylim = c(-4,5)) +\n  scale_fill_manual(values = discrete_palette)\n\nplot_1 + plot_2"},{"path":"clustering.html","id":"further-reading-5","chapter":"clustering","heading":"further reading","text":"http://www.sthda.com/english/wiki/wiki.php?id_contents=7940https://ryanwingate.com/intro--machine-learning/unsupervised/hierarchical--density-based-clustering/https://ryanwingate.com/intro--machine-learning/unsupervised/hierarchical--density-based-clustering/hierarchical-4.pnghttps://www.geeksforgeeks.org/dbscan-clustering--r-programming/","code":""},{"path":"clustering.html","id":"exercises-3","chapter":"clustering","heading":"exercises","text":"set exercises, please use dataset hawaii_aquifers, available run source() command. following:Run PCA analysis data set plot results.Run PCA analysis data set plot results.Create ordination plot identify one analyte varies Dim.1 one analyte varies Dim.2 (“variables interest”).Create ordination plot identify one analyte varies Dim.1 one analyte varies Dim.2 (“variables interest”).Run kmeans clustering PCA output. Create set clusters seems appropriately subdivide data set.Run kmeans clustering PCA output. Create set clusters seems appropriately subdivide data set.Use clusters defined kmeans groupings run summary statistics two variables interest.Use clusters defined kmeans groupings run summary statistics two variables interest.Create plot four subpanels shows: () PCA analysis (colored kmeans clusters), (ii) ordination analysis, (iii) summary statistics two variables interest within kmeans groups. Please note subpanel plots can created sending ggplots objects adding objects together. Please see subsection data visualization chapter subplots.Create plot four subpanels shows: () PCA analysis (colored kmeans clusters), (ii) ordination analysis, (iii) summary statistics two variables interest within kmeans groups. Please note subpanel plots can created sending ggplots objects adding objects together. Please see subsection data visualization chapter subplots.Run dbscan clustering PCA output. Create set clusters seems appropriately subdivide data set.Run dbscan clustering PCA output. Create set clusters seems appropriately subdivide data set.Use clusters defined dbscan groupings run summary statistics two variables interest.Use clusters defined dbscan groupings run summary statistics two variables interest.Create plot four subpanels shows: () PCA analysis (colored dbscan clusters), (ii) ordination analysis, (iii) summary statistics two variables interest within dbscan groups.Create plot four subpanels shows: () PCA analysis (colored dbscan clusters), (ii) ordination analysis, (iii) summary statistics two variables interest within dbscan groups.","code":""},{"path":"models.html","id":"models","chapter":"models","heading":"models","text":"","code":""},{"path":"models.html","id":"univariate","chapter":"models","heading":"univariate","text":"Next quest develop abilities analytical data exploration modeling. start simplest models - linear models. variety ways build linear models R, use function called buildLinearModel. use , simply give data, tell sets values want compare. tell want compare, give formula form Y = M x X + B, however, B term M implicit, need tell Y = X.Let’s look example. Suppose want know abundances ADP AMP related metabolomics dataset:looks like might relationship! Let’s build linear model relationship:model consists two thigs: metrics data. Let’s look metrics:shows us intercept (b), variable AMP (.e. slope, m), well things (talk second). thing model contains data (). includes input_x y values. raw values ADP AMP, residuals (see details), x y values generated model.Let’s plot model!good. Now let’s talk evaluating quality model. need means assessing well line fits data. use residuals - distance points line.can calculate sum squared residuals:15.39! Let’s call “residual sum squares”. . 15.39.. mean model good? don’t know. compare number something. Let’s compare super simple model just defined mean y value input data.pretty bad model, agree. much better linear model flat line model? Let’s create measure distance point point predicted x value model:40.32! Wow. Let’s call “total sum squares”, now can compare “residual sum squares”:0.68! Alright. R squared value. equal 1 minus ratio “residual sum squares” “total sum squares”. Now, let’s put together make pretty:","code":"\nggplot(metabolomics_data) +\n  geom_point(aes(x = AMP, y = ADP))\nmodel <- buildLinearModel(\n  data = metabolomics_data,\n  formula = \"ADP = AMP\"\n)\nstr(model, strict.width = \"cut\")\n## List of 2\n##  $ metrics:'data.frame': 6 obs. of  5 variables:\n##   ..$ variable: chr [1:6] \"(Intercept)\" \"AMP\" \"median_res\"..\n##   ..$ value   : num [1:6] 0.7842 0.9142 0.0415 40.3224 15...\n##   ..$ std_err : chr [1:6] \"1.0056\" \"0.0757\" NA NA ...\n##   ..$ type    : chr [1:6] \"coefficient\" \"coefficient\" \"st\"..\n##   ..$ p_value : chr [1:6] \"0.4375\" \"0\" NA NA ...\n##  $ data   :'data.frame': 92 obs. of  7 variables:\n##   ..$ input_x  : num [1:92] 13.2 13.5 14.3 13.3 12 ...\n##   ..$ input_y  : num [1:92] 12.8 13.1 13.3 13.2 11.9 ...\n##   ..$ ADP      : num [1:92] 12.8 13.1 13.3 13.2 11.9 ...\n##   ..$ AMP      : num [1:92] 13.2 13.5 14.3 13.3 12 ...\n##   ..$ residuals: num [1:92] 0.0312 -0.0217 -0.6014 0.2458 ..\n##   ..$ model_y  : num [1:92] 12.8 13.1 13.9 13 11.8 ...\n##   ..$ model_x  : num [1:92] 13.2 13.5 14.3 13.3 12 ...\nmodel$metrics\n##               variable   value std_err        type p_value\n## 1          (Intercept)  0.7842  1.0056 coefficient  0.4375\n## 2                  AMP  0.9142  0.0757 coefficient       0\n## 3      median_residual  0.0415    <NA>   statistic    <NA>\n## 4    total_sum_squares 40.3224    <NA>   statistic    <NA>\n## 5 residual_sum_squares 15.3901    <NA>   statistic    <NA>\n## 6            r_squared  0.6183    <NA>   statistic    <NA>\nhead(model$data)\n##    input_x  input_y      ADP      AMP   residuals  model_y\n## 1 13.15029 12.83791 12.83791 13.15029  0.03119000 12.80672\n## 2 13.48362 13.08980 13.08980 13.48362 -0.02165141 13.11146\n## 3 14.32515 13.27943 13.27943 14.32515 -0.60138528 13.88082\n## 4 13.31191 13.20029 13.20029 13.31191  0.24581244 12.95448\n## 5 11.99764 11.93350 11.93350 11.99764  0.18057517 11.75293\n## 6 12.95966 12.83649 12.83649 12.95966  0.20405638 12.63243\n##    model_x\n## 1 13.15029\n## 2 13.48362\n## 3 14.32515\n## 4 13.31191\n## 5 11.99764\n## 6 12.95966\nggplot(model$data) +\n  geom_point(aes(x = input_x, y = input_y)) +\n  geom_line(aes(x = model_x, y = model_y))\nggplot(model$data) +\n  geom_point(aes(x = input_x, y = input_y)) +\n  geom_line(aes(x = model_x, y = model_y)) +\n  geom_segment(aes(x = input_x, y = input_y, xend = input_x, yend = model_y))\nsum(\n  (model$data$input_y - model$data$model_y)^2\n, na.rm = TRUE)\n## [1] 15.39014\nggplot(metabolomics_data) +\n  geom_point(aes(x = AMP, y = ADP)) +\n  geom_hline(aes(yintercept = mean(ADP, na.rm = TRUE)))\nsum(\n  (metabolomics_data$ADP - mean(metabolomics_data$ADP, na.rm = TRUE))^2\n, na.rm = TRUE)\n## [1] 40.32239\n\nggplot(metabolomics_data) +\n  geom_point(aes(x = AMP, y = ADP)) +\n  geom_hline(aes(yintercept = mean(ADP, na.rm = TRUE))) +\n  geom_segment(aes(x = AMP, y = ADP, xend = AMP, yend = mean(ADP, na.rm = TRUE)))\n1-(15.39/40.32)\n## [1] 0.6183036\ntop <- ggplot(model$data) +\n  geom_point(aes(x = input_x, y = input_y)) +\n  geom_line(aes(x = model_x, y = model_y)) +\n  annotate(geom = \"table\",\n    x = 11.4,\n    y = 16,\n    label = list(model$metrics)\n  ) +\n  coord_cartesian(ylim = c(10,16)) +\n  theme_bw()\n\nbottom <- ggplot(model$data) +\n  geom_col(\n    aes(x = input_x, y = residuals),\n    width = 0.03, color = \"black\", position = \"dodge\", alpha = 0.5\n  ) +\n  theme_bw()\n\ncowplot::plot_grid(top, bottom, ncol = 1, labels = \"AUTO\", rel_heights = c(2,1))"},{"path":"models.html","id":"multivariate","chapter":"models","heading":"multivariate","text":"","code":"\n\nmodel1 <- buildLinearModel(metabolomics_data, formula = \"ADP = AMP\")\nmodel1[1]\n## $metrics\n##               variable   value std_err        type p_value\n## 1          (Intercept)  0.7842  1.0056 coefficient  0.4375\n## 2                  AMP  0.9142  0.0757 coefficient       0\n## 3      median_residual  0.0415    <NA>   statistic    <NA>\n## 4    total_sum_squares 40.3224    <NA>   statistic    <NA>\n## 5 residual_sum_squares 15.3901    <NA>   statistic    <NA>\n## 6            r_squared  0.6183    <NA>   statistic    <NA>\nmodel2 <- buildLinearModel(metabolomics_data, formula = \"ADP = AMP + IMP\")\nmodel2[1]\n## $metrics\n##               variable   value std_err        type p_value\n## 1          (Intercept)  2.0057  0.9222 coefficient  0.0323\n## 2                  AMP  0.6201  0.0907 coefficient       0\n## 3                  IMP  0.2303  0.0606 coefficient   3e-04\n## 4      median_residual  0.0462    <NA>   statistic    <NA>\n## 5    total_sum_squares 40.3224    <NA>   statistic    <NA>\n## 6 residual_sum_squares 11.6145    <NA>   statistic    <NA>\n## 7            r_squared  0.6494    <NA>   statistic    <NA>\n\nplot1 <- ggplot() + \n  geom_point(\n    data = metabolomics_data, \n    aes(x = (AMP*0.9142) + 0.7842, y = ADP),\n    fill = \"gold\", shape = 21, color = \"black\", size = 4\n  ) +\n  geom_segment(\n    aes(x = 10, y = 10, xend = 15, yend = 15),\n    color = \"black\"\n  ) +\n  annotate(\n    geom = \"table\",\n    x = 10,\n    y = 15,\n    label = list(model1$metrics)\n  ) +\n  theme_bw()\n\nplot2 <- ggplot() + \n  geom_point(\n    data = metabolomics_data, \n    aes(x = (AMP*0.6201) + (IMP*0.2303) + 2.0057, y = ADP), \n    fill = \"maroon\", shape = 21, color = \"black\", size = 4\n  ) +\n  annotate(\n    geom = \"table\",\n    x = 10,\n    y = 15,\n    label = list(model2$metrics)\n  ) +\n  geom_segment(\n    aes(x = 10, y = 10, xend = 15, yend = 15),\n    color = \"black\"\n  ) +\n  theme_bw()\n\nplot1/plot2"},{"path":"models.html","id":"exercises-4","chapter":"models","heading":"exercises","text":"practice creating linear models, try following:Choose one datasets used far, run principal components analysis . Note output analysis run “pca_ord” contains Dimension 1 coordinate “Dim.1” sample, well abundance analyte sample.Choose one datasets used far, run principal components analysis . Note output analysis run “pca_ord” contains Dimension 1 coordinate “Dim.1” sample, well abundance analyte sample.Using information ordination plot, identify two analytes: one variance strongly positively correlated first principal component (.e. dimension 1), one variance slightly less strongly, still positively correlated first principal component. Using buildLinearModel, create plot two linear models, one regresses analytes dimension 1. greater r-squared value? Based know PCA, make sense?Using information ordination plot, identify two analytes: one variance strongly positively correlated first principal component (.e. dimension 1), one variance slightly less strongly, still positively correlated first principal component. Using buildLinearModel, create plot two linear models, one regresses analytes dimension 1. greater r-squared value? Based know PCA, make sense?Choose two analytes: one one analytes question 2 , analyte , according PCA ordination analysis, negatively correlated first principal component. Using buildLinearModel create plots showing two analytes correlated dimension 1. One positively correlated, negatively correlated. Enhance plots including visual represetation residuals.Choose two analytes: one one analytes question 2 , analyte , according PCA ordination analysis, negatively correlated first principal component. Using buildLinearModel create plots showing two analytes correlated dimension 1. One positively correlated, negatively correlated. Enhance plots including visual represetation residuals.","code":""},{"path":"models.html","id":"further-reading-6","chapter":"models","heading":"further reading","text":"https://github.com/easystats/performance","code":""},{"path":"comparing-means.html","id":"comparing-means","chapter":"comparing means","heading":"comparing means","text":"“two things ?”Often, want know study subjects contain different amounts certain analytes. example, “lake contain potassium lake ?” , need statistical tests. , look comparing mean values analyte abundance situations two samples situations two samples.find many concepts discussed chapter easier think example mind. , suppose analytical chemist Hawaii studying chemistry island’s aquifers. data set hawaii_aquifers. can see output structure data set - 990 measurements 9 different analytes multiple wells draw set 10 aquifers.Importantly, many wells draw aquifer, shown graph .","code":"\nhawaii_aquifers\n## # A tibble: 954 × 6\n##    aquifer_code well_name         longitude latitude analyte\n##    <chr>        <chr>                 <dbl>    <dbl> <chr>  \n##  1 aquifer_1    Alewa_Heights_Sp…        NA       NA SiO2   \n##  2 aquifer_1    Alewa_Heights_Sp…        NA       NA Cl     \n##  3 aquifer_1    Alewa_Heights_Sp…        NA       NA Mg     \n##  4 aquifer_1    Alewa_Heights_Sp…        NA       NA Na     \n##  5 aquifer_1    Alewa_Heights_Sp…        NA       NA K      \n##  6 aquifer_1    Alewa_Heights_Sp…        NA       NA SO4    \n##  7 aquifer_1    Alewa_Heights_Sp…        NA       NA HCO3   \n##  8 aquifer_1    Alewa_Heights_Sp…        NA       NA dissol…\n##  9 aquifer_1    Alewa_Heights_Sp…        NA       NA Ca     \n## 10 aquifer_1    Beretania_High_S…        NA       NA SiO2   \n## # … with 944 more rows, and 1 more variable:\n## #   abundance <dbl>\nunique(hawaii_aquifers$aquifer_code)\n##  [1] \"aquifer_1\"  \"aquifer_2\"  \"aquifer_3\"  \"aquifer_4\" \n##  [5] \"aquifer_5\"  \"aquifer_6\"  \"aquifer_7\"  \"aquifer_8\" \n##  [9] \"aquifer_9\"  \"aquifer_10\"\nhawaii_aquifers %>%\n  select(aquifer_code, well_name) %>%\n  group_by(aquifer_code) %>%\n  summarize(n_wells = length(unique(well_name))) -> aquifers_summarized\n\naquifers_summarized\n## # A tibble: 10 × 2\n##    aquifer_code n_wells\n##    <chr>          <int>\n##  1 aquifer_1         12\n##  2 aquifer_10         7\n##  3 aquifer_2          5\n##  4 aquifer_3          3\n##  5 aquifer_4         16\n##  6 aquifer_5          4\n##  7 aquifer_6         12\n##  8 aquifer_7          9\n##  9 aquifer_8          3\n## 10 aquifer_9         30\n\nggplot(aquifers_summarized) + geom_col(aes(x = n_wells, y = aquifer_code))"},{"path":"comparing-means.html","id":"definitions","chapter":"comparing means","heading":"definitions","text":"populations independent measurements: comparing means, comparing two sets values. important consider values came first place. particular, usually useful think values representatives larger populations. example aquifer data set, can think measurements different wells drawing aquifer independent measurements “population” (.e. aquifer).populations independent measurements: comparing means, comparing two sets values. important consider values came first place. particular, usually useful think values representatives larger populations. example aquifer data set, can think measurements different wells drawing aquifer independent measurements “population” (.e. aquifer).null hypothesis: conduct statistical test, testing null hypothesis. null (think “default”) hypothesis difference bewteen means (hence name “null”). example aquifers, let’s say ’re interested whether two aquifers different abundances potassium - case null hypothesis differ, words, amount potassium.null hypothesis: conduct statistical test, testing null hypothesis. null (think “default”) hypothesis difference bewteen means (hence name “null”). example aquifers, let’s say ’re interested whether two aquifers different abundances potassium - case null hypothesis differ, words, amount potassium.p value: p value represents probability getting data extreme results null hypothesis true. words - p value probability observe differences , fact differences means . continue example: suppose measure potassium levels 10% wells access aquifer find aquifer_1 potassium levels 14 +/- 2 aquifer_2 potassium levels 12 +/- 1. Suppose conduct statistical test get p value 0.04. means , assuming aquifers magneisum levels (.e. assuming null hypothesis true), 4% chance get measured values . words, aquifers potassium abundance, pretty unlikely obtained measurements .p value: p value represents probability getting data extreme results null hypothesis true. words - p value probability observe differences , fact differences means . continue example: suppose measure potassium levels 10% wells access aquifer find aquifer_1 potassium levels 14 +/- 2 aquifer_2 potassium levels 12 +/- 1. Suppose conduct statistical test get p value 0.04. means , assuming aquifers magneisum levels (.e. assuming null hypothesis true), 4% chance get measured values . words, aquifers potassium abundance, pretty unlikely obtained measurements .Please note p value probability detected difference false positive. probability false positive requires additional information order calculated. discussion please see end chapter.","code":""},{"path":"comparing-means.html","id":"test-selection","chapter":"comparing means","heading":"test selection","text":"many different types statistical tests. flow chart illustrating recommended statistical tests used course. can see three regimes tests: variance normality tests (blue), parametric tests (green), non-parametric tests (orange):comparing means, need first determine kind statistical tests can use data. () data can reasonably modelled normal distribution (ii) variances two means similar, can use powerful “parametric” tests (.e. tests likely detect difference means, assuming one exists). one criteria met, need use less powerful “non-parametric” tests.can check data normality similar variances using Shapiro test Levene test. Let’s use hawaii_aquifers data example, let’s consider element potassium:work two means, let’s just look aquifers 1 6:data normally distributed? similar variance? Let’s get first approximation looking plot:Based graphic, ’s hard say! Let’s use statistical test help. want run Shaprio test, looking see group normally distributed (group “aquifer_code”, .e. aquifer_1 aquifer_6). means need group_by(aquifer_code) run test:p-values 0.05! means distributions significantly different normal distribution. variances two means? similar? need Levene test. test, looking within group, rather across groups - means need group_by(aquifer_code) specify y ~ x formula instead:p-value test 0.596! means variances significantly different. shape (normality) variances (equal variances), thing can different means. allows us set null hypothesis calculate probability obtaining different means two sets observations come identical source.","code":"\nK_data <- hawaii_aquifers %>%\n  filter(analyte == \"K\")\n  K_data\n## # A tibble: 106 × 6\n##    aquifer_code well_name         longitude latitude analyte\n##    <chr>        <chr>                 <dbl>    <dbl> <chr>  \n##  1 aquifer_1    Alewa_Heights_Sp…       NA      NA   K      \n##  2 aquifer_1    Beretania_High_S…       NA      NA   K      \n##  3 aquifer_1    Beretania_Low_Se…       NA      NA   K      \n##  4 aquifer_1    Kuliouou_Well         -158.     21.3 K      \n##  5 aquifer_1    Manoa_Well_II         -158.     21.3 K      \n##  6 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  7 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  8 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  9 aquifer_1    Nuuanu_Aerator_W…     -158.     21.4 K      \n## 10 aquifer_1    Palolo_Tunnel         -158.     21.3 K      \n## # … with 96 more rows, and 1 more variable: abundance <dbl>\nK_data_1_6 <- K_data %>%\n    filter(aquifer_code %in% c(\"aquifer_1\", \"aquifer_6\"))\n\nK_data_1_6\n## # A tibble: 24 × 6\n##    aquifer_code well_name         longitude latitude analyte\n##    <chr>        <chr>                 <dbl>    <dbl> <chr>  \n##  1 aquifer_1    Alewa_Heights_Sp…       NA      NA   K      \n##  2 aquifer_1    Beretania_High_S…       NA      NA   K      \n##  3 aquifer_1    Beretania_Low_Se…       NA      NA   K      \n##  4 aquifer_1    Kuliouou_Well         -158.     21.3 K      \n##  5 aquifer_1    Manoa_Well_II         -158.     21.3 K      \n##  6 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  7 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  8 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  9 aquifer_1    Nuuanu_Aerator_W…     -158.     21.4 K      \n## 10 aquifer_1    Palolo_Tunnel         -158.     21.3 K      \n## # … with 14 more rows, and 1 more variable: abundance <dbl>\n\nggplot(K_data_1_6, aes(x = aquifer_code, y = abundance)) +\n    geom_boxplot() +\n    geom_point()\nK_data_1_6 %>%\n  ggplot(aes(x = abundance)) + \n    geom_histogram(bins = 30) +\n    facet_wrap(~aquifer_code) +\n    geom_density(aes(y = ..density..*10), color = \"blue\")\nK_data_1_6 %>%\n  group_by(aquifer_code) %>% \n  shapiroTest(abundance)\n## # A tibble: 2 × 4\n##   aquifer_code variable  statistic     p\n##   <chr>        <chr>         <dbl> <dbl>\n## 1 aquifer_1    abundance     0.885 0.102\n## 2 aquifer_6    abundance     0.914 0.239\nK_data_1_6 %>%\n  leveneTest(abundance ~ aquifer_code)\n## # A tibble: 1 × 4\n##     df1   df2 statistic     p\n##   <int> <int>     <dbl> <dbl>\n## 1     1    22     0.289 0.596"},{"path":"comparing-means.html","id":"two-means","chapter":"comparing means","heading":"two means","text":"Now, since data passed test, means can use normal t-test. t-test parametric test. means relies modelling data using normal distribution order make comparisons. also powerful test. means likely detect difference means, assuming one present. Let’s try :p-value 0.012! 0.05, meaning 95% chance two means different. Suppose data passed Shapiro /Levene tests. need use Wilcox test. Wilcox test non-parametric test, means use normal distribution model data order make comparisons. means less powerful test t-test, means less likely detect difference means, assuming one. fun, let’s try one compare p-values two methods:p-value 0.028! higher value given t-test (0.012). Wilcox test less powerful test: less likely detect differences means, assuming exist.","code":"\nK_data_1_6 %>%\n  tTest(abundance ~ aquifer_code)\n## # A tibble: 1 × 8\n##   .y.       group1 group2    n1    n2 statistic    df      p\n## * <chr>     <chr>  <chr>  <int> <int>     <dbl> <dbl>  <dbl>\n## 1 abundance aquif… aquif…    12    12     -2.75  20.5 0.0121\nK_data_1_6 %>%\n  wilcoxTest(abundance ~ aquifer_code)\n## # A tibble: 1 × 7\n##   .y.       group1    group2       n1    n2 statistic      p\n## * <chr>     <chr>     <chr>     <int> <int>     <dbl>  <dbl>\n## 1 abundance aquifer_1 aquifer_6    12    12      33.5 0.0282"},{"path":"comparing-means.html","id":"more-than-two-means","chapter":"comparing means","heading":"more than two means","text":"previous section compared two means. want compare means two study subjects? first step determine tests use. Let’s consider hawaii aquifer data , though time let’s use aquifers, just two:Let’s check visually see group normally distributed see roughly equal variance:, somewhat hard tell visually data normally distributed. seems pretty likely different variances means, let’s check using Shapiro Levene tests. Don’t forget: Shaprio test, looking within group need group_by(), Levene test, looking across groups, need provide y~x formula:Based tests, looks like data aquifer 9 significantly different normal distribution (Shaprio test p = 0.000008), variances certainly different one another (Levene test p = 0.002).Let’s assume second data passed tests. means reasonably model data normal distributions use parametric test compare means. means can use ANOVA test differences means.","code":"\nK_data <- hawaii_aquifers %>%\n  filter(analyte == \"K\")\n\nK_data\n## # A tibble: 106 × 6\n##    aquifer_code well_name         longitude latitude analyte\n##    <chr>        <chr>                 <dbl>    <dbl> <chr>  \n##  1 aquifer_1    Alewa_Heights_Sp…       NA      NA   K      \n##  2 aquifer_1    Beretania_High_S…       NA      NA   K      \n##  3 aquifer_1    Beretania_Low_Se…       NA      NA   K      \n##  4 aquifer_1    Kuliouou_Well         -158.     21.3 K      \n##  5 aquifer_1    Manoa_Well_II         -158.     21.3 K      \n##  6 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  7 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  8 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  9 aquifer_1    Nuuanu_Aerator_W…     -158.     21.4 K      \n## 10 aquifer_1    Palolo_Tunnel         -158.     21.3 K      \n## # … with 96 more rows, and 1 more variable: abundance <dbl>\n\nggplot(data = K_data, aes(y = aquifer_code, x = abundance)) +\n  geom_boxplot() +\n  geom_point(color = \"maroon\", alpha = 0.6, size = 3)\nK_data %>%\n  group_by(aquifer_code) %>%\n  ggplot(aes(x = abundance)) + \n    geom_histogram(bins = 30) +\n    facet_wrap(~aquifer_code) +\n    geom_density(aes(y = ..density..*10), colour = \"blue\")\nK_data %>%\n  group_by(aquifer_code) %>% \n  shapiroTest(abundance)\n## # A tibble: 10 × 4\n##    aquifer_code variable  statistic         p\n##    <chr>        <chr>         <dbl>     <dbl>\n##  1 aquifer_1    abundance     0.885 0.102    \n##  2 aquifer_10   abundance     0.864 0.163    \n##  3 aquifer_2    abundance     0.913 0.459    \n##  4 aquifer_3    abundance     0.893 0.363    \n##  5 aquifer_4    abundance     0.948 0.421    \n##  6 aquifer_5    abundance     0.993 0.972    \n##  7 aquifer_6    abundance     0.914 0.239    \n##  8 aquifer_7    abundance     0.915 0.355    \n##  9 aquifer_8    abundance     0.842 0.220    \n## 10 aquifer_9    abundance     0.790 0.0000214\nK_data %>%\n  leveneTest(abundance ~ aquifer_code)\n## # A tibble: 1 × 4\n##     df1   df2 statistic       p\n##   <int> <int>     <dbl>   <dbl>\n## 1     9    96      2.95 0.00387"},{"path":"comparing-means.html","id":"anova-tukey-tests","chapter":"comparing means","heading":"ANOVA, Tukey tests","text":"use anovaTest function package rstatix. tell us means data statistically different one another. However, differences means, tell us different.p-value 7.7e-11! definitely significant differences among group. , different one another though? , need run Tukey’s Honest Significant Difference test (implemented using tukey_hsd). essentially run t-test pairs study subjects can derive data set (example, aquifer_1 vs. aquifer_2, aquifer_1 vs. aquifer_3, etc.). , correct p-values according number comparisons performed. controls rate type error can expect test. corrected values provided us p.adj column.Using output tukey test, can determine means similar. can using pGroups function:can use output pGroups annotate plot:Excellent! plot shows us, using letters line aquifer, means different. letter shared among labels line two aquifers, means means differ significantly. example, aquifer 2 aquifer 6 “b” labels, means different - aquifers 3 10.","code":"\nK_data %>%\n  anovaTest(abundance ~ aquifer_code)\n## Coefficient covariances computed by hccm()\n## ANOVA Table (type II tests)\n## \n##         Effect DFn DFd     F        p p<.05   ges\n## 1 aquifer_code   9  96 9.486 3.28e-10     * 0.471\nK_data %>%\n  tukey_hsd(abundance ~ aquifer_code)\n## # A tibble: 45 × 9\n##    term         group1   group2 null.value estimate conf.low\n##  * <chr>        <chr>    <chr>       <dbl>    <dbl>    <dbl>\n##  1 aquifer_code aquifer… aquif…          0  0.00357   -2.04 \n##  2 aquifer_code aquifer… aquif…          0  1.44      -0.708\n##  3 aquifer_code aquifer… aquif…          0  0.375     -2.40 \n##  4 aquifer_code aquifer… aquif…          0 -1.15      -2.78 \n##  5 aquifer_code aquifer… aquif…          0 -0.875     -3.36 \n##  6 aquifer_code aquifer… aquif…          0  1.98       0.228\n##  7 aquifer_code aquifer… aquif…          0  2.70       0.801\n##  8 aquifer_code aquifer… aquif…          0 -0.125     -2.90 \n##  9 aquifer_code aquifer… aquif…          0 -0.349     -1.80 \n## 10 aquifer_code aquifer… aquif…          0  1.44      -0.954\n## # … with 35 more rows, and 3 more variables:\n## #   conf.high <dbl>, p.adj <dbl>, p.adj.signif <chr>\n\n# K_data %>%\n#   tukeyHSD(abundance ~ aquifer_code)\ngroups_based_on_tukey <- K_data %>%\n  tukey_hsd(abundance ~ aquifer_code) %>%\n  pGroups()\ngroups_based_on_tukey\n##             treatment group spaced_group\n## aquifer_1   aquifer_1    ab         ab  \n## aquifer_10 aquifer_10   abc         abc \n## aquifer_2   aquifer_2   acd         a cd\n## aquifer_3   aquifer_3  abcd         abcd\n## aquifer_4   aquifer_4     b          b  \n## aquifer_5   aquifer_5    ab         ab  \n## aquifer_6   aquifer_6    cd           cd\n## aquifer_7   aquifer_7     d            d\n## aquifer_8   aquifer_8  abcd         abcd\n## aquifer_9   aquifer_9    ab         ab\nggplot(data = K_data, aes(y = aquifer_code, x = abundance)) +\n  geom_boxplot() +\n  geom_point(color = \"maroon\", alpha = 0.6, size = 3) +\n  geom_text(data = groups_based_on_tukey, aes(y = treatment, x = 9, label = group))"},{"path":"comparing-means.html","id":"kruskal-dunn-tests","chapter":"comparing means","heading":"Kruskal, Dunn tests","text":"ANOVA example great, remember - data pass Shapiro Levene tests. means data can modelled normal distribution taht need use non-parametric test. non-parametric alternative ANOVA called Kruskal test. Like Wilcox test, less powerful parametric relative, meaning less likely detected differences, exist. However, since data pass Shapiro/Levene tests, resort Kruskal test. Let’s try :p-value 3.9e-9! higher p-value running ANOVA data (remember, Kruskal test less powerful). Never less, value still well 0.05, meaning means different. , determine different one another? ran ANOVA follow-test (post hoc test) Tukey’s HSD. Kruskal test, post hoc test use Dunn test. Let’s try:gives us adjusted p-values pairwise comparisons. , can use pGroups() give us compact letter display group, can used annotate plot:Note groupings different generated ANOVA/Tukey.","code":"\nK_data %>%\n  kruskalTest(abundance ~ aquifer_code)\n## # A tibble: 1 × 6\n##   .y.           n statistic    df             p method      \n## * <chr>     <int>     <dbl> <int>         <dbl> <chr>       \n## 1 abundance   106      55.9     9 0.00000000807 Kruskal-Wal…\nK_data %>%\n  dunnTest(abundance ~ aquifer_code)\n## # A tibble: 45 × 9\n##    .y.     group1 group2    n1    n2 statistic       p p.adj\n##  * <chr>   <chr>  <chr>  <int> <int>     <dbl>   <dbl> <dbl>\n##  1 abunda… aquif… aquif…    12     7    -0.194 0.846   1    \n##  2 abunda… aquif… aquif…    12     6     2.24  0.0254  0.736\n##  3 abunda… aquif… aquif…    12     3     0.866 0.387   1    \n##  4 abunda… aquif… aquif…    12    17    -2.65  0.00806 0.266\n##  5 abunda… aquif… aquif…    12     4    -1.12  0.263   1    \n##  6 abunda… aquif… aquif…    12    12     2.51  0.0121  0.388\n##  7 abunda… aquif… aquif…    12     9     3.01  0.00257 0.100\n##  8 abunda… aquif… aquif…    12     3     0.143 0.886   1    \n##  9 abunda… aquif… aquif…    12    33    -0.470 0.639   1    \n## 10 abunda… aquif… aquif…     7     6     2.17  0.0296  0.830\n## # … with 35 more rows, and 1 more variable:\n## #   p.adj.signif <chr>\ngroups_based_on_dunn <- K_data %>%\n  dunnTest(abundance ~ aquifer_code) %>%\n  pGroups()\ngroups_based_on_dunn\n##             treatment group spaced_group\n## aquifer_1   aquifer_1  abcd         abcd\n## aquifer_10 aquifer_10  abcd         abcd\n## aquifer_2   aquifer_2   abc         abc \n## aquifer_3   aquifer_3  abcd         abcd\n## aquifer_4   aquifer_4     d            d\n## aquifer_5   aquifer_5   acd         a cd\n## aquifer_6   aquifer_6    ab         ab  \n## aquifer_7   aquifer_7     b          b  \n## aquifer_8   aquifer_8  abcd         abcd\n## aquifer_9   aquifer_9    cd           cd\n\nggplot(data = K_data, aes(y = aquifer_code, x = abundance)) +\n  geom_boxplot() +\n  geom_point(color = \"black\", alpha = 0.4, size = 2) +\n  scale_x_continuous(name = \"Potassium abundance\", breaks = seq(0,10,1)) +\n  scale_y_discrete(name = \"Aquifer code\") +\n  geom_text(data = groups_based_on_dunn, aes(y = treatment, x = 9, label = group)) +\n  theme_bw()"},{"path":"comparing-means.html","id":"pairs-of-means","chapter":"comparing means","heading":"pairs of means","text":"Oftentimes two means compare, rather wanting compare means , want compare pairwise fashion. example, suppose want know aquifers contain different amounts Na Cl. interested testing differences among values Na Cl, rather, want test pairs Na Cl values arising aquifer. say, want compare means facet plot :Fortunately, can use approach similar ’ve learned earlier portions chapter, just minor modifications. Let’s look! start Shapiro Levene tests, usual (note group using two variables using Shapiro test analyte within aquifer considered individual distribution):Looks like distributions significantly different normal! Let’s run levene test anyway. Note particular case Levene test, interested testing whether pair distributions similar variances. need feed Levene test data grouped aquifer_code (tests pair group), need specify y ~ x formula (case abundance ~ analyte):looks like variances pair aquifer 1 significantly different variances. - sure need using non-parametric testing. simple case two means use wilcox_test, may pairs, use pairwise_wilcox_test (note test options various styles controlling multiple comparisons, see: ?pairwise_wilcox_test):Excellent! looks like statistically significant difference means abundances Cl Na aquifer_2 (surprisingly?) aquifer_9 (perhaps due large number observations?).done Shaprio Levene tests revealed significant differences? Well, pairwise_tTest course!Excellent, now see run parametric non-parametric pairwise comparisons. annotate plots output tests? example:","code":"\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  ggplot(aes(x = analyte, y = abundance)) + geom_violin() + geom_point() + facet_grid(.~aquifer_code)\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  group_by(analyte, aquifer_code) %>%\n  shapiroTest(abundance)\n## # A tibble: 20 × 5\n##    aquifer_code analyte variable  statistic        p\n##    <chr>        <chr>   <chr>         <dbl>    <dbl>\n##  1 aquifer_1    Cl      abundance     0.900 1.59e- 1\n##  2 aquifer_10   Cl      abundance     0.486 1.09e- 5\n##  3 aquifer_2    Cl      abundance     0.869 2.24e- 1\n##  4 aquifer_3    Cl      abundance     0.75  0       \n##  5 aquifer_4    Cl      abundance     0.903 7.49e- 2\n##  6 aquifer_5    Cl      abundance     0.849 2.24e- 1\n##  7 aquifer_6    Cl      abundance     0.741 2.15e- 3\n##  8 aquifer_7    Cl      abundance     0.893 2.12e- 1\n##  9 aquifer_8    Cl      abundance     0.878 3.17e- 1\n## 10 aquifer_9    Cl      abundance     0.420 2.68e-10\n## 11 aquifer_1    Na      abundance     0.886 1.06e- 1\n## 12 aquifer_10   Na      abundance     0.593 2.26e- 4\n## 13 aquifer_2    Na      abundance     0.884 2.88e- 1\n## 14 aquifer_3    Na      abundance     0.822 1.69e- 1\n## 15 aquifer_4    Na      abundance     0.933 2.41e- 1\n## 16 aquifer_5    Na      abundance     0.827 1.61e- 1\n## 17 aquifer_6    Na      abundance     0.764 3.80e- 3\n## 18 aquifer_7    Na      abundance     0.915 3.51e- 1\n## 19 aquifer_8    Na      abundance     0.855 2.53e- 1\n## 20 aquifer_9    Na      abundance     0.531 3.97e- 9\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  group_by(aquifer_code) %>%\n  leveneTest(abundance ~ analyte)\n## # A tibble: 10 × 5\n##    aquifer_code   df1   df2 statistic       p\n##    <chr>        <int> <int>     <dbl>   <dbl>\n##  1 aquifer_1        1    22   10.5    0.00375\n##  2 aquifer_10       1    12    0.0535 0.821  \n##  3 aquifer_2        1    10    0.0243 0.879  \n##  4 aquifer_3        1     4    0.320  0.602  \n##  5 aquifer_4        1    32    1.57   0.219  \n##  6 aquifer_5        1     6    2      0.207  \n##  7 aquifer_6        1    22    1.03   0.322  \n##  8 aquifer_7        1    16    1.54   0.232  \n##  9 aquifer_8        1     4    0.515  0.512  \n## 10 aquifer_9        1    64    1.10   0.298\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  group_by(aquifer_code) %>%\n  pairwiseWilcoxTest(abundance~analyte)\n## # A tibble: 10 × 10\n##    aquifer_code .y.      group1 group2    n1    n2 statistic\n##  * <chr>        <chr>    <chr>  <chr>  <int> <int>     <dbl>\n##  1 aquifer_1    abundan… Cl     Na        12    12      99.5\n##  2 aquifer_10   abundan… Cl     Na         7     7      14  \n##  3 aquifer_2    abundan… Cl     Na         6     6      36  \n##  4 aquifer_3    abundan… Cl     Na         3     3       3  \n##  5 aquifer_4    abundan… Cl     Na        17    17     189  \n##  6 aquifer_5    abundan… Cl     Na         4     4      13  \n##  7 aquifer_6    abundan… Cl     Na        12    12      53  \n##  8 aquifer_7    abundan… Cl     Na         9     9      42  \n##  9 aquifer_8    abundan… Cl     Na         3     3       6  \n## 10 aquifer_9    abundan… Cl     Na        33    33     195  \n## # … with 3 more variables: p <dbl>, p.adj <dbl>,\n## #   p.adj.signif <chr>\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  group_by(aquifer_code) %>%\n  pairwiseTTest(abundance~analyte) -> test_output\n  test_output\n## # A tibble: 10 × 10\n##    aquifer_code .y.       group1 group2    n1    n2        p\n##  * <chr>        <chr>     <chr>  <chr>  <int> <int>    <dbl>\n##  1 aquifer_1    abundance Cl     Na        12    12  4.69e-2\n##  2 aquifer_10   abundance Cl     Na         7     7  8.82e-1\n##  3 aquifer_2    abundance Cl     Na         6     6  3.75e-5\n##  4 aquifer_3    abundance Cl     Na         3     3  6.83e-1\n##  5 aquifer_4    abundance Cl     Na        17    17  1.03e-1\n##  6 aquifer_5    abundance Cl     Na         4     4  9.75e-2\n##  7 aquifer_6    abundance Cl     Na        12    12  5.66e-1\n##  8 aquifer_7    abundance Cl     Na         9     9  5.21e-1\n##  9 aquifer_8    abundance Cl     Na         3     3  4.28e-1\n## 10 aquifer_9    abundance Cl     Na        33    33  8.96e-1\n## # … with 3 more variables: p.signif <chr>, p.adj <dbl>,\n## #   p.adj.signif <chr>\n\nanno <- data.frame(\n  xmin = test_output$group1,\n  xmax = test_output$group2,\n  y_position = c(150, 150, 150, 175, 80, 50, 300, 150, 50, 125),\n  text = test_output$p.signif,\n  text_size = 10,\n  text_vert_offset = 10,\n  text_horiz_offset = 1.5,\n  tip_length_xmin = 5,\n  tip_length_xmax = 5,\n  aquifer_code = test_output$aquifer_code,\n  hjust = 0.5,\n  vjust = 0.5\n)\n\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  ggplot(aes(x = analyte, y = abundance)) +\n  geom_violin(fill = \"gold\", color = \"black\") +\n  geom_point(shape = 21, fill = \"maroon\", color = \"black\") +\n  facet_grid(.~aquifer_code) +\n  geomSignif(data = anno, orientation = \"horizontal\") +\n  scale_x_discrete(name = \"Analyte\") +\n  scale_y_continuous(name = \"Abundance\") +\n  theme_bw() +\n  theme(\n    text = element_text(size = 16)\n    )"},{"path":"comparing-means.html","id":"further-reading-7","chapter":"comparing means","heading":"further reading","text":"comparing multiple means R: www.datanovia.comFor parametric versus non-parametric tests: Statistics JimFor interpreting p values: [p value wars () Ulrich Dirnagl]","code":""},{"path":"comparing-means.html","id":"exercises-5","chapter":"comparing means","heading":"exercises","text":"Using hawaii_aquifers data set, please complete following:Choose one analyte filter data rows analyte shown.Choose one analyte filter data rows analyte shown.Choose two aquifers. mean abundances chosen analyte different two aquifers? Don’t forget test data normality homogeneity variance selecting statistical test. Use plot illustrate whether means similar different.Choose two aquifers. mean abundances chosen analyte different two aquifers? Don’t forget test data normality homogeneity variance selecting statistical test. Use plot illustrate whether means similar different.Choose second analyte, different first one chose. Considering aquifers dataset, abundance analyte? , don’t forget normality homogeneity variance tests. Use plot illustrate answer.Choose second analyte, different first one chose. Considering aquifers dataset, abundance analyte? , don’t forget normality homogeneity variance tests. Use plot illustrate answer.Repeat #3 , switch type test used (.e. use non-parametric used parametric #3 vice-versa). Compare p values p groups obtained two methods. Use graphic illustrate . different?Repeat #3 , switch type test used (.e. use non-parametric used parametric #3 vice-versa). Compare p values p groups obtained two methods. Use graphic illustrate . different?","code":""},{"path":"map-data.html","id":"map-data","chapter":"map data","heading":"map data","text":"","code":""},{"path":"map-data.html","id":"plotting-boundaries","chapter":"map data","heading":"plotting boundaries","text":"simple way plot maps ggplot. map data comes ggplot2! Let’s look. See data sets included. Options included ggplot : world, world2, usa, state (US), county (US), nz, italy, france. geom_polygon() useful plotting , (least ) seems intuitive geom_map().Cool! can see lat, lon, group, order, region, subregion included. makes plotting easy. Note coord_map() can help preserve aspect ratios:Note can use coord_map() pretty cool things!can use filtering produce maps specific regions.","code":"\nhead(map_data(\"world\"))\n##        long      lat group order region subregion\n## 1 -69.89912 12.45200     1     1  Aruba      <NA>\n## 2 -69.89571 12.42300     1     2  Aruba      <NA>\n## 3 -69.94219 12.43853     1     3  Aruba      <NA>\n## 4 -70.00415 12.50049     1     4  Aruba      <NA>\n## 5 -70.06612 12.54697     1     5  Aruba      <NA>\n## 6 -70.05088 12.59707     1     6  Aruba      <NA>\nhead(map_data(\"state\"))\n##        long      lat group order  region subregion\n## 1 -87.46201 30.38968     1     1 alabama      <NA>\n## 2 -87.48493 30.37249     1     2 alabama      <NA>\n## 3 -87.52503 30.37249     1     3 alabama      <NA>\n## 4 -87.53076 30.33239     1     4 alabama      <NA>\n## 5 -87.57087 30.32665     1     5 alabama      <NA>\n## 6 -87.58806 30.32665     1     6 alabama      <NA>\nhead(map_data(\"county\"))\n##        long      lat group order  region subregion\n## 1 -86.50517 32.34920     1     1 alabama   autauga\n## 2 -86.53382 32.35493     1     2 alabama   autauga\n## 3 -86.54527 32.36639     1     3 alabama   autauga\n## 4 -86.55673 32.37785     1     4 alabama   autauga\n## 5 -86.57966 32.38357     1     5 alabama   autauga\n## 6 -86.59111 32.37785     1     6 alabama   autauga\nhead(map_data(\"france\"))\n##       long      lat group order region subregion\n## 1 2.557093 51.09752     1     1   Nord      <NA>\n## 2 2.579995 51.00298     1     2   Nord      <NA>\n## 3 2.609101 50.98545     1     3   Nord      <NA>\n## 4 2.630782 50.95073     1     4   Nord      <NA>\n## 5 2.625894 50.94116     1     5   Nord      <NA>\n## 6 2.597699 50.91967     1     6   Nord      <NA>\nggplot(map_data(\"world\")) +\n  geom_point(aes(x = long, y = lat, color = group), size = 0.5) +\n  theme_void() +\n  coord_map()\nggplot(map_data(\"world\")) +\n  geom_point(aes(x = long, y = lat, color = group), size = 0.5) +\n  theme_void() +\n  coord_map(projection = \"albers\", lat0 = 39, lat1 = 45)\nggplot() +\n  geom_polygon(\n    data = filter(map_data(\"county\"), region == \"minnesota\"),\n    aes(x = long, y = lat, group = subregion, fill = subregion),\n    color = \"black\"\n  ) +\n  theme_void() +\n  coord_map()"},{"path":"map-data.html","id":"further-reading-8","chapter":"map data","heading":"further reading","text":"plotting maps R: datavizplyrFor advanced map plotting: R Spatial","code":""},{"path":"mass-spectrometric-analysis.html","id":"mass-spectrometric-analysis","chapter":"mass spectrometric analysis","heading":"mass spectrometric analysis","text":"","code":""},{"path":"mass-spectrometric-analysis.html","id":"loading-analyzegcmsdata-basic","chapter":"mass spectrometric analysis","heading":"loading analyzeGCMSdata (basic)","text":"phylochemistry provides simple application integrating analyzing GC-MS data. , can analyze .CDF files, contain essentially data GC-MS run, can exported GC-MS systems using software provided manufacturer. Instructions provided end chapter. run lite version integration app, use following guidelines:Create new folder hard drive place CDF file(s) folder. doesn’t matter name folder , must contain special characters (including space  name). example, CDF file called “sorghum_bicolor.CDF”, might create folder called gc_data hard drive, place “sorghum_bicolor.CDF” file folder.Create new folder hard drive place CDF file(s) folder. doesn’t matter name folder , must contain special characters (including space  name). example, CDF file called “sorghum_bicolor.CDF”, might create folder called gc_data hard drive, place “sorghum_bicolor.CDF” file folder.RStudio, run source command load phylochemistry:RStudio, run source command load phylochemistry:RStudio, run analyzeGCMSdata command folder contains CDF file.Mac, use single forward slashes. example:PC, use double back slashes. example:first time open datafile, may take load. new RShiny window opens, press shit+q load chromatogram(s).","code":"\nsource(\"https://thebustalab.github.io/phylochemistry/phylochemistry.R\")\nanalyzeGCMSdata(\"/Volumes/My_Drive/gc_data\")\nanalyzeGCMSdata(\"C:\\\\Users\\\\My_Profile\\\\gc_data\")"},{"path":"mass-spectrometric-analysis.html","id":"loading-analyzegcmsdata-advanced","chapter":"mass spectrometric analysis","heading":"loading analyzeGCMSdata (advanced)","text":"can ask analyzeGCMSdata extract single ion chromatograms wish. Just specify list ions argument. Note specifying “0” corresponds total ion chromatogram. example:return interface shows chromatograms total ion count ion 218.point, note new set files data-containing folder. one *.CDF.csv file CDF file folder. contains matrix mass measurements entire sample - abundance m/z value scan. also chromatograms.csv file. list chromatograms (total ion + whatever single ions specified). can useful creating plots chromatograms via ggplot.","code":"\nanalyzeGCMSdata(\"/Volumes/My_Drive/gc_data\", ions = c(\"0\", \"218\"))"},{"path":"mass-spectrometric-analysis.html","id":"using-analyzegcmsdata","chapter":"mass spectrometric analysis","heading":"1.1 using analyzeGCMSdata","text":"reference, key commands used operate integration app. information covered overview video.control chromatogram window:shift + q = updateshift + = add selected peakshift + r = remove selected peakshift + g = add global peak\nshift + z = save tableTo control mass spectrum window:shift+1 = extract mass spectra highlighted chromatogram region, plot average mass spectrum panel 1.shift+2 = refresh mass spectrum panel 1. used zooming region mass spectrum highlighted. spectrum needs first extracted possible.shift+3 = extract mass spectra highlighted chromatogram region, subtract average mass spectrum panel 1.shift+4 = search current spectrum panel 1 library mass spectra.shift+5 = save current spectrum panel 1 csv file.","code":""},{"path":"mass-spectrometric-analysis.html","id":"cdf-export","chapter":"mass spectrometric analysis","heading":"1.2 CDF export","text":"GC-MS computer, open Enhanced Data AnalysisFile > Export Data .AIA Format, Create New Directory (“OK”) > Desktop (create folder name remember)Select datafiles wish analyze process , saving output folder just createdCopy .D files samples wish analyze folderMove folder personal computerCreate one folder sample, put corresponding .CDF file folder.\n","code":""},{"path":"data-acquisition.html","id":"data-acquisition","chapter":"data acquisition","heading":"data acquisition","text":"Updating MinKNOW GridIonsudo apt update\nsudo apt install ont-gridion-release\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/3bf863cc.pub","code":""},{"path":"data-transfer.html","id":"data-transfer","chapter":"data transfer","heading":"data transfer","text":"’ve completed sequencing run, data can transferred external hard drive, can plugged storage computer. next steps :Identify files interest/system. Useful commands:Display currently mounted filesystems (& usage, storage space, mounting point):df -hAlso:lsblk -fDisplay data pertaining identification disks. Can also change partitioning hard disks:sudo fdisk -l-Hard drives labeled sd’s. Organization follows /dev/sd_ underscore replaced letter (first hard drive starting ‘’ continuing alphabetically). partitions present, letter followed number (starting ‘1’ first partition continuing numerically). Ex) /dev/sdb2Mounting-Use command:\nsudo mount <\/dev/sd_> <\/file_path>\n-Replace <\/sd_> actual hard drive label /file_path pathway location want mount drive.\n-Make sure location (<\/file_path>) preexisting location. Use mkdir command make new directory necessary.Copy data-Just use cp command make sure right filenames locations transfer data hard drive internal disk.","code":""},{"path":"sequence-assessment.html","id":"sequence-assessment","chapter":"sequence assessment","heading":"sequence assessment","text":"nanopore reads stored suitable machine, can analyze several phylochemistry functions. quick overview:Additional Informationbootable USB: https://rufus.ie/en/#","code":"\nqc_data <- fastxQC(\n    paths_to_fastxs = c(\n        \"/Users/bust0037/Documents/Science/Websites/thebustalab.github.io/data/example.fastq\",\n        \"/Users/bust0037/Documents/Science/Websites/thebustalab.github.io/data/example2.fastq\"\n    ),\n    type = \"fasta\",\n    mode = \"slow\",\n    max_n_seqs = 1000\n)\n\nhead(qc_data)\n\nqc_data %>%\n  mutate(category = case_when(\n    length > mean(qc_data$length)*5 ~ \"chromosome\",\n    length <= mean(qc_data$length)*5 ~ \"leftover_bit\"\n  )) %>%\n  ggplot() +\n    geom_treemap(aes(area = length, fill = category), color = \"black\", size = 1) +\n    scale_fill_manual(values = c(\"gold\", \"maroon\"))"},{"path":"illumina-read-assessment.html","id":"illumina-read-assessment","chapter":"illumina read assessment","heading":"illumina read assessment","text":"Check : fastqcr: R Package Facilitating Quality Controls Sequencing Data Large Numbers Samples","code":""},{"path":"setup.html","id":"setup","chapter":"setup","heading":"setup","text":"Get docker.https://hub.docker.com/Connecting remote host:Make sure remote host openSSH installed:sudo apt install openssh-serverOn client computer (usually laptop something), first create key:ssh-keygen -t rsaThen copy key host (usually computer want connect remotely ):ssh-copy-id -~/.ssh/id_rsa.pub {username}@host.addressDone! Log ssh {username}@host.address","code":""},{"path":"genome-assembly.html","id":"genome-assembly","chapter":"genome assembly","heading":"genome assembly","text":"degree, refer : https://github.com/dithiii/ant-pipeline/blob/main/README.md.","code":""},{"path":"genome-assembly.html","id":"assembly","chapter":"genome assembly","heading":"1.3 assembly","text":"","code":""},{"path":"genome-assembly.html","id":"equipment","chapter":"genome assembly","heading":"1.3.1 equipment","text":"Genome assembly requires computing resources - since genomes equal size, computing resources required different assemblies may differ. run genome assembly, start determining computing resources available. helpful commands investigating resources Linux machines:Assessing RAM (recommended assign 75% available RAM assembly process):grep MeMTotal /proc/meminfoAssessing CPU resources (note “threads per CPU” can denote availability hyperthreading):lscpuAssessing disk/storage space (Make sure running assembly disk lots open space. Ideally > 2TB):df -h","code":""},{"path":"genome-assembly.html","id":"assembly-software","chapter":"genome assembly","heading":"1.3.2 assembly software","text":"","code":""},{"path":"genome-assembly.html","id":"canu","chapter":"genome assembly","heading":"1.3.2.1 canu","text":"docker pull staphb/canu-raconFor assembly BustaLab storage box, navigate directory contains reads. Merge reads one file using:cat *.fastq > all_reads.fastqThen use Canu assemble, suggest creating file contains Canu call. can create file using nano. , try something like:Notes Canu options:Defaults:minReadLength=1000minOverlapLength=500bpcorrectedErrorRate=0.114stopOnLowCoverage <integer=10>Essentially speed optimization:30X coverage:Nanopore flip-flop R9.4 R10.3: try: corMhapOptions=--threshold 0.8 –ordered-sketch-size 1000 –ordered-kmer-size 14’ correctedErrorRate=0.105For 60X coverage: 2 recommendations made, one said decrease slightly (~1%). Another suggested using 12%\ncorrectedErrorRate=0.12Increasing minReadLength increases run time, increasing minOverlapLength improves assembly quality increasing much quickly degrades assemblies.","code":"sudo docker run -u $(id -u) -v /data/ben_diatom2/basecalled_reads/:/canu-racon_wd staphb/canu-racon canu -p n_frust2assembly -d /canu-racon_wd/ -genomeSize=150m -nanopore /canu-racon_wd/all_reads2.fastq -minReadLength=1000 -correctedErrorRate=0.12 -minOverlapLength=500 -useGrid=false -minInputCoverage=0.5 -maxInputCoverage=100 -stopOnLowCoverage=0.5 -corMemory=48 -corThreads=4 -hapMemory=48 -hapThreads=4 -merylMemory=48 -merylthreads=4 -batMemory=48 -batThreads=4"},{"path":"genome-assembly.html","id":"flye","chapter":"genome assembly","heading":"1.3.2.2 flye","text":"docker pull staphb/flye","code":""},{"path":"genome-assembly.html","id":"kmer-based-metrics","chapter":"genome assembly","heading":"1.3.3 kmer-based metrics","text":"Canu take time run. goes along, can check progress learn genome assembling intermediate results. Take k-mer data found .histogram files (.e. correction/0-mercounts/x.histogram, trimming/0-mercounts/x.histogram, unitigging/0-mercounts/x.histogram) process canuHistogramToKmerTable(), shown . can upload output : http://qb.cshl.edu/genomescope/genomescope2.0/. give approximate genome size, ploidy, heterozygosity, repeat content, read error rate. good stuff know!Also check tutorial:genomics tutorial","code":"\ncanuHistogramToKmerTable(\n  file_in_path = \"/Users/bust0037/Desktop/n_frust3assemblyB.ms22.histogram\",\n  file_out_path = \"/Users/bust0037/Desktop/n_frust3assemblyB.ms22.histogram_table\"\n)"},{"path":"genome-assembly.html","id":"merqury","chapter":"genome assembly","heading":"1.3.3.1 merqury","text":"docker pull quay.io/chai/merqurysudo docker run -u $(id -u) -v /home/bust0037/data1/Kalanchoe_DNASeq/round2_pass_reads_assembly/:/merqury/ quay.io/chai/merqury:latest quast.py -hReferences:\nhttps://www.biorxiv.org/content/10.1101/2020.03.15.992941v1.abstract\nMerqury: reference-free quality, completeness, phasing assessment genome assemblies","code":""},{"path":"genome-assembly.html","id":"evaluating-contigs","chapter":"genome assembly","heading":"1.4 evaluating contigs","text":"Can merged single wrapper can run step assembly/polishing/scaffolding etc?","code":""},{"path":"genome-assembly.html","id":"busco","chapter":"genome assembly","heading":"1.4.1 BUSCO","text":"Real BUSCO input /home/bust0037/data1/comparative_genomics/Kfedtschenkoi_382_v1.0.faNote BUSCO uses current working directory input outputdocker pull ezlabgva/busco:v5.3.2_cv1sudo docker run -u $(id -u) -v /home/bust0037/data1/comparative_genomics/:/busco_wd ezlabgva/busco:v5.3.2_cv1 busco -k_fed.contigs.fa -o busco_our_kfed/ -m genome -l eudicots_odb10","code":""},{"path":"genome-assembly.html","id":"quast","chapter":"genome assembly","heading":"1.4.2 quast","text":"Quast provides score called ALE: alignment liklihood estimate.docker pull longas/quastsudo docker run -u $(id -u) -v /home/bust0037/:/tmp/work/quast_results longas/quast:latest quast.py -hsudo docker run -u $(id -u) -v /home/bust0037/ben_test/_ben_genomes/:/tmp/work/quast_results longas/quast:latest quast.py --fragmented /tmp/work/quast_results/ben_pre_n_frust.contigs.fasta --nanopore /tmp/work/quast_results/all_pass_reads.fastq --space-efficient --memory-efficient --fast","code":""},{"path":"genome-assembly.html","id":"polishing-contigs","chapter":"genome assembly","heading":"1.5 polishing contigs","text":"","code":""},{"path":"genome-assembly.html","id":"medaka","chapter":"genome assembly","heading":"1.5.1 medaka","text":"Pull docker image:docker pull ontresearch/medakaRun medaka:sudo docker run -u $(id -u) -v /home/bust0037/data1/Kalanchoe_DNASeq/round2_pass_reads_assembly/:/medaka/ ontresearch/medaka:latest medaka_consensus -medaka/all_reads.fastq -d medaka/k_fed.contigs.fasta -b 50Good documentation : https://labs.epi2me.io/notebooks/Introduction_to_how_ONT's_medaka_works.htmlMedaka :\n* Map raw reads. Look feedback like: [M::worker_pipeline::2924.325*0.25] mapped 75823 sequences.\n* something else, updates form : 21.7% Done (88.2/406.1 Mbases) 6815.1s.","code":""},{"path":"genome-assembly.html","id":"methylation-with-remora","chapter":"genome assembly","heading":"1.6 methylation with remora","text":"can call methylation status Kalanchoe genomes? -> yes, can use Remora -> watch new guppy release, MinKNOW integration -> currently bonito","code":"bonito basecaller dna_r10.4_e8.1_sup@v3.4 /data/reads --modified-bases 5mC --reference ref.mmi > basecalls_with_mods.bam\nbonito basecaller dna_r10.4_e8.1_sup@v3.4 --reference consensus.fasta --modified-bases 5mC"},{"path":"genome-assembly.html","id":"scaffolding-assembly","chapter":"genome assembly","heading":"1.7 scaffolding assembly","text":"","code":""},{"path":"genome-assembly.html","id":"ragtag","chapter":"genome assembly","heading":"1.7.1 RagTag","text":"INSTALL PYTHON (upgrade python) <- can done using docker?INSTALL BIOCONDA\n1. install miniconda:\ncurl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nsh …","code":""},{"path":"genome-assembly.html","id":"annotation","chapter":"genome assembly","heading":"1.8 annotation","text":"","code":""},{"path":"genome-assembly.html","id":"augustus","chapter":"genome assembly","heading":"1.8.1 augustus","text":"see: https://hub.docker.com/r/pegi3s/autoaugustus/","code":"docker pull pegi3s/autoaugustussudo docker run --rm -v $(pwd):$(pwd) pegi3s/autoaugustus augustus --species=help\nsudo docker run --rm -v $(pwd):/augustus/ pegi3s/autoaugustus augustus --species=tomato /augustus/consensus.fasta > consensus-preductions.gff --progress=TRUE"},{"path":"genome-assembly.html","id":"final-assessment","chapter":"genome assembly","heading":"1.9 final assessment","text":"https://www.molecularecologist.com/2017/03/29/whats-n50/","code":""},{"path":"genome-assembly.html","id":"mosdepth","chapter":"genome assembly","heading":"1.9.1 mosdepth","text":"sudo docker pull quay.io/biocontainers/mosdepth:0.2.4--he527e40_0sudo docker run -u $(id -u) -v /home/bust0037/data1/Kalanchoe_DNASeq/rounds_1and2_pass_assembly/:/mosdepth_wd quay.io/biocontainers/mosdepth:0.2.4--he527e40_0 mosdepth -hsudo docker run -u $(id -u) -v /home/bust0037/data1/Kalanchoe_DNASeq/rounds_1and2_pass_assembly/:/mosdepth_wd quay.io/biocontainers/mosdepth:0.2.4--he527e40_0 mosdepth -n --fast-mode --1000 mosdepth_wd/mosdepth_out /mosdepth_wd/calls_to_draft.bamsudo docker run -u $(id -u) -v /home/bust0037/data1/Kalanchoe_DNASeq/rounds_1and2_pass_assembly/:/mosdepth_wd gfanz/mosdepth -n --fast-mode --1000 mosdepth_wd/mosdepth_out /mosdepth_wd/calls_to_draft.bamsudo docker run -u $(id -u) -v /home/bust0037/data1/Kalanchoe_DNASeq/rounds_1and2_pass_assembly/:/mosdepth_wd quay.io/biocontainers/mosdepth:0.2.4--he527e40_0 mosdepth --quantize 0:1:4:100:200: --fast-mode --1000 mosdepth_wd/mosdepth_out /mosdepth_wd/calls_to_draft.bamset channels/home/bust0037/miniconda3/bin/conda config –add channels defaults\n/home/bust0037/miniconda3/bin/conda config –add channels bioconda\n/home/bust0037/miniconda3/bin/conda config –add channels conda-forgeinstall packages/home/bust0037/miniconda3/bin/conda install sibeliaz\n/home/bust0037/miniconda3/bin/conda install -c bioconda ragtagrun stuff/home/bust0037/miniconda3/bin/conda run sibeliaz -n k_fed.contigs.scaffolded.fasta KlaxifloraFTBG2000359A_699_v3.0.fa/home/bust0037/miniconda3/bin/conda run ragtag/home/bust0037/miniconda3/bin/conda run ragtagragtag.py/home/bust0037/meryl-1.3/bin/meryl\n/home/bust0037/merqury-1.3/merqury.shsh $MERQURY/best_k.sh Let’s look examples. example, use fasta files stored Google Drive folder:","code":"\n# reads <- readFasta(\"https://drive.google.com/file/d/1r6E0U5LyYwjWenxy9yqh5QQ2mq1umWOW/view?usp=sharing\")\n\n# # post <- readFasta(\"/Users/bust0037/Desktop/ragtag.scaffold.fasta\")\n# n_chroms <- 18\n\n# pb <- progress::progress_bar$new(total = n_chroms)\n\n# out <- list()\n\n# for (i in 1:n_chroms) {\n\n#   pb$tick()\n\n#   dat <- strsplit(substr(as.character(post[i]), 1, 50000000), \"\")[[1]]\n  \n#   b <- rle(dat)\n\n#   # Create a data frame\n#   dt <- data.frame(number = b$values, lengths = b$lengths, scaff = i)\n#   # Get the end\n#   dt$end <- cumsum(dt$lengths)\n#   # Get the start\n#   dt$start <- dt$end - dt$lengths + 1\n\n#   # Select columns\n#   dt <- dt[, c(\"number\", \"start\", \"end\", \"scaff\")]\n#   # Sort rows\n#   dt <- dt[order(dt$number), ]\n\n#   dt %>%\n#     filter(number == \"N\") -> N_dat\n\n#   out[[i]] <- N_dat\n\n# }\n\n# out <- do.call(rbind, out)\n\n\n# chroms <- data.frame(\n#   lengths = post@ranges@width[1:n_chroms],\n#   scaff = seq(1,n_chroms,1)\n# )\n\n# ggplot() +\n#   statebins:::geom_rrect(data = chroms, aes(xmin = 0, xmax = lengths, ymin = -1, ymax = 1, fill = scaff), color = \"black\") +\n#   geom_rect(data = out, aes(xmin = start, xmax = end, ymin = -0.95, ymax = 0.95), color = \"white\", fill = \"white\", size = 0.08) +\n#   facet_grid(scaff~.) +\n#   scale_fill_viridis(end = 0.8) +\n#   theme_classic()\n\n# ggplot() +\n#   geom_rect(data = filter(chroms, scaff == 1 | scaff == 2), aes(xmin = 0, xmax = lengths, ymin = -1, ymax = 1, fill = scaff), color = \"black\") +\n#   geom_rect(data = filter(out, scaff == 1 | scaff == 2), aes(xmin = start, xmax = end, ymin = -0.95, ymax = 0.95), color = \"white\", fill = \"white\", size = 0.08) +\n#   facet_grid(scaff~.) +\n#   scale_y_continuous(limits = c(-2,2)) +\n#   scale_fill_viridis(end = 0.8) +\n#   theme_classic() +\n#   coord_polar()"},{"path":"annotation-1.html","id":"annotation-1","chapter":"annotation","heading":"annotation","text":"docker pull nanozoo/braker2","code":""},{"path":"comparative-genomics.html","id":"comparative-genomics","chapter":"comparative genomics","heading":"comparative genomics","text":"GENESPACE: syntenic pan-genome annotations eukaryotes","code":""},{"path":"comparative-genomics.html","id":"loading-gff-files","chapter":"comparative genomics","heading":"1.10 loading GFF files","text":"","code":""},{"path":"blast.html","id":"blast","chapter":"blast","heading":"blast","text":"","code":""},{"path":"blast.html","id":"polyblast","chapter":"blast","heading":"1.11 polyBlast","text":"","code":""},{"path":"blast.html","id":"setup-1","chapter":"blast","heading":"1.11.1 setup","text":"NCBI, can search various sequence collections one queries. However, often want search custom library, multiple libraries. example, maybe downloaded genomes interest want run blast searches . polyBlast() designed . polyBlast() relies BLAST+ program available NCBI BLAST+. Download program point function executable via blast_module_directory_path argument. can search multiple sequence libraries using multiple queries, usual blast configurations (blastp, blastn, tblastn, etc.) available. Please note searches protein sequences translated DNA sequences 5–10-fold sensitive DNA:DNA sequence comparison.Let’s check polyBlast() looking example. example, need set things:“named_subjects_list”: named list sequence collections (often transcriptomes) search (one fasta collection, often one collection species accession).“query_in_path”: One queries, listed single fasta file.“sequences_of_interest_directory_path”: path directory BLAST hits written individual files (useful later ).“blast_module_directory_path”: path folder BLAST+ executable.“blast_mode”: format XYblastZ X subject type (transcriptome proteome, use “n” nucleotide, “p” amino acids). Y whether subjects translated (“t” translate, “n” translation, choose “t” subjects searched ORFs, every three base pairs just translated verbatim). Z format query/queries (“n” nucleotide, “p” amino acids). Allowed formats: nnblastn, ntblastp, pnblastp.“e_value_cutoff”: Hits e-value cutoff returned. Default = 1.“queries_in_outout”: TRUE/FALSE, queries included output? want build tree BLAST hits want queries tree, set TRUE.“monolist_out_path”: path want summary file BLAST hits written.things, can set search (see ). two main outputs search: list hits (“monolist_out”, written “monolist_out_path”), hits , written individual files “sequences_of_interest_directory_path”. two things can used downstream analyses, alignments. function return object.","code":"\nthe_transcriptomes <- c(\n  \"/path_to/the_transcriptomes_or_proteomes/Nicotiana_glauca.fa\",\n  \"/path_to/the_transcriptomes_or_proteomes/Nicotiana_tabacum.fa\",\n  \"/path_to/the_transcriptomes_or_proteomes/Nicotiana_benthamiana.fa\"\n)\n\nnames(the_transcriptomes) <- c(\n  \"Nicotiana_glauca.fa\",\n  \"Nicotiana_tabacum.fa\",\n  \"Nicotiana_benthamiana.fa\"\n)\n\npolyBlast(\n  named_subjects_list = the_transcriptomes,\n  query_in_path = \"/path_to/sequences_you_want_to_find_in_the_transcriptomes.fa\",\n  sequences_of_interest_directory_path = \"/path_to/a_folder_for_hit_sequences/\",\n  blast_module_directory_path = \"/path_to/the_blast_module/\",\n  blast_mode = c(\"nnblastn\", \"ntblastp\", \"pnblastp\", \"dc-megablast\"), \n  e_value_cutoff = 1,\n  queries_in_output = TRUE,\n  monolist_out_path = \"/path_to/a_csv_file_that_will_list_all_blast_hits.csv\"\n)"},{"path":"blast.html","id":"interpretation","chapter":"blast","heading":"1.11.2 interpretation","text":"“30% identity rule--thumb” conservative. Statistically significant (E < 10−6 – 10−3) protein homologs can share less 20% identity. E-values bit scores (bits > 50) far sensitive reliable percent identity inferring homology.expect value (E-value) can changed order limit number hits significant ones. lower E-value, better hit. E-value dependent length query sequence size database. example, alignment obtaining E-value 0.05 means 5 100 chance occurring chance alone. E-values dependent query sequence length database size. Short identical sequence may high E-value may regarded “false positive” hits. often seen one searches short primer regions, small domain regions etc. default threshold E-value BLAST web page 10, default polyBlast 1. Increasing value likely generate hits. rules thumb can used loose guidelines:E-value < 10e-100 Identical sequences. get long alignments across entire query hit sequence.10e-100 < E-value < 10e-50 Almost identical sequences. long stretch query protein matched database.10e-50 < E-value < 10e-10 Closely related sequences, domain match similar.10e-10 < E-value < 1 true homologue gray area.E-value > 1 Proteins likely relatedE-value > 10 Hits likely junk unless query sequence short.reference: https://resources.qiagenbioinformatics.com/manuals/clcgenomicsworkbench/650/_E_value.htmlreference: Pearson W. R. (2013). introduction sequence similarity (“homology”) searching. Current protocols bioinformatics, Chapter 3, Unit3.1. https://doi.org/10.1002/0471250953.bi0301s42.","code":""},{"path":"alignments.html","id":"alignments","chapter":"alignments","heading":"alignments","text":"","code":""},{"path":"alignments.html","id":"alignsequences","chapter":"alignments","heading":"1.12 alignSequences","text":", course, many tools aligning sequences. alignSequences(), alignment tool phylochemistry, designed versatile (can nucleotide, amino acid, codon alignments, ), able quily align different subsets collections sequences. three steps make work, bit work, worth end. list ingredients. used polyBlast(), polyBlast() created ingredients . Following list example. function return object, output fasta containing alignment alignment_directory_path.“monolist”: data.frame contains list sequences aligned. first column accession number refers fasta file “sequences_of_interest_directory_path”.“monolist”: data.frame contains list sequences aligned. first column accession number refers fasta file “sequences_of_interest_directory_path”.“subset”: monolist .csv also needs contain least one “subset_*” column. simple implementation column called “subset_all” contains TRUE entry row. means accessions aligned. possible create additonal logical/boolean columns specify argument, cause subset collection sequences aligned.“subset”: monolist .csv also needs contain least one “subset_*” column. simple implementation column called “subset_all” contains TRUE entry row. means accessions aligned. possible create additonal logical/boolean columns specify argument, cause subset collection sequences aligned.“alignment_directory_path”: path directory contain output alignment.“alignment_directory_path”: path directory contain output alignment.“sequences_of_interest_directory_path”: path directory contains one fasta file accessions monolist.“sequences_of_interest_directory_path”: path directory contains one fasta file accessions monolist.“input_sequence_type”: options “nucl” “amin” specifying type sequence aligned.“input_sequence_type”: options “nucl” “amin” specifying type sequence aligned.“mode”: options “nucl_align”, basic nucleotide alignment, “amin_align”, basic amino acid alignment, “codon_align”, codon alignment, “fragment_align”, align sequences base fragment.“mode”: options “nucl_align”, basic nucleotide alignment, “amin_align”, basic amino acid alignment, “codon_align”, codon alignment, “fragment_align”, align sequences base fragment.“base_fragment”: path fasta file containing base fragment subjects aligned.“base_fragment”: path fasta file containing base fragment subjects aligned.","code":"\nalignSequences(\n  monolist = readMonolist(\"/path_to/a_csv_file_that_will_list_all_blast_hits.csv\"), \n  subset = \"subset_all\", \n  alignment_directory_path = \"/path_to/a_folder_for_alignments/\", \n  sequences_of_interest_directory_path = \"/path_to/a_folder_for_hit_sequences/\",\n  input_sequence_type = \"amin\", \n  mode = \"amin_alignment\",\n  base_fragment = NULL\n)"},{"path":"alignments.html","id":"analyzealignment","chapter":"alignments","heading":"1.13 analyzeAlignment","text":"","code":""},{"path":"phylogenies.html","id":"phylogenies","chapter":"phylogenies","heading":"phylogenies","text":"","code":""},{"path":"phylogenies.html","id":"buildtree","chapter":"phylogenies","heading":"1.14 buildTree","text":"function swiss army knife tree building. takes input alignments existing phylogenies derive phylogeny interest, can use neighbor-joining maximum liklihood methods (model optimization), can run bootstrap replicates, can calculate ancestral sequence states. illustrate, let’s look examples:","code":""},{"path":"phylogenies.html","id":"newick-input","chapter":"phylogenies","heading":"1.14.1 newick input","text":"Let’s use Busta lab’s plant phylogeny [derived Qian et al., 2016] build phylogeny five species .Cool! got phylogeny. happens want build phylogeny species isn’t scaffold? example, want build phylogeny includes Arabidopsis neglecta? can include name list members:Note buildTree informs us: “Scaffold newick tip Arabidopsis_thaliana substituted Arabidopsis_neglecta”. means Arabidopsis neglecta grafted onto tip originally occupied Arabidopsis thaliana. behaviour useful operating large phylogenetic scale (.e. exact phylogeny topology critical family level). However, person interested using existing newick tree scaffold phylogeny genus-level topology critical, beware! scaffold may appropriate see message. operating genus level, probably want use sequence data build phylogeny anyway. let’s look :","code":"\ntree <- buildTree(\n  scaffold_type = \"newick\",\n  scaffold = \"https://thebustalab.github.io/data/plant_phylogeny.newick\",\n  members = c(\"Sorghum_bicolor\", \"Zea_mays\", \"Setaria_viridis\", \"Arabidopsis_thaliana\", \"Amborella_trichopoda\")\n)\n## Pro tip: most tree read/write functions reset node numbers.\n## Fortify your tree and save it as a csv file to preserve node numbering.\n## Do not save your tree as a newick or nexus file.\n\ntree\n## \n## Phylogenetic tree with 5 tips and 4 internal nodes.\n## \n## Tip labels:\n##   Amborella_trichopoda, Zea_mays, Sorghum_bicolor, Setaria_viridis, Arabidopsis_thaliana\n## Node labels:\n##   , , , \n## \n## Rooted; includes branch lengths.\n\nplot(tree)\ntree <- buildTree(\n  scaffold_type = \"newick\",\n  scaffold_in_path = \"https://thebustalab.github.io/data/plant_phylogeny.newick\",\n  members = c(\"Sorghum_bicolor\", \"Zea_mays\", \"Setaria_viridis\", \"Arabidopsis_neglecta\", \"Amborella_trichopoda\")\n)\n## Scaffold newick tip Arabidopsis_thaliana substituted with Arabidopsis_neglecta \n## Pro tip: most tree read/write functions reset node numbers.\n## Fortify your tree and save it as a csv file to preserve node numbering.\n## Do not save your tree as a newick or nexus file.\n\ntree\n## \n## Phylogenetic tree with 5 tips and 4 internal nodes.\n## \n## Tip labels:\n##   Amborella_trichopoda, Zea_mays, Sorghum_bicolor, Setaria_viridis, Arabidopsis_neglecta\n## Node labels:\n##   , , , \n## \n## Rooted; includes branch lengths.\n\nplot(tree)"},{"path":"phylogenies.html","id":"alignment-input","chapter":"phylogenies","heading":"1.14.2 alignment input","text":"Arguments case :“scaffold_type”: “amin_alignment” “nucl_alignment” amino acids nucleotides.“scaffold_in_path”: path fasta file contains alignment want build tree.“ml”: Logical, TRUE want use maximum liklihood, FALSE , case neighbor joining ne used.“model_test”: say TRUE “ml”, buildTree test different maximum liklihood models use “best” one?“bootstrap”: TRUE FALSE, whether want bootstrap values nodes.“ancestral_states”: TRUE FALSE, buildTree() compute ancestral sequence node?“root”: NULL, name accession form root tree.","code":"\nbuildTree(\n  scaffold_type = \"amin_alignment\",\n  scaffold_in_path = \"/path_to/a_folder_for_alignments/all_amin_seqs.fa\",\n  ml = FALSE, \n  model_test = FALSE,\n  bootstrap = FALSE,\n  ancestral_states = FALSE,\n  root = NULL\n)"},{"path":"phylogenies.html","id":"plotting-trees","chapter":"phylogenies","heading":"1.15 plotting trees","text":"several approaches plotting trees. simple one using base plot function:Though can get messy lots tip labels:One solution use ggtree, default doesn’t show tip labels. plot can , ggtree bunch useful things, recommend :Another convenient fucntion ggplot’s fortify. convert phylo object data frame:ggtree can still plot dataframe, allows metadata stored human readable format using mutating joins (explained ). metadata can plotted standard ggplot geoms, dataframes can also conveniently saved .csv files:","code":"\ntest_tree_small <- buildTree(\n  scaffold_type = \"newick\",\n  scaffold_in_path = \"https://thebustalab.github.io/data/plant_phylogeny.newick\",\n  members = c(\"Sorghum_bicolor\", \"Zea_mays\", \"Setaria_viridis\")\n)\n## Pro tip: most tree read/write functions reset node numbers.\n## Fortify your tree and save it as a csv file to preserve node numbering.\n## Do not save your tree as a newick or nexus file.\n\nplot(test_tree_small)\nset.seed(122)\ntest_tree_big <- buildTree(\n  scaffold_type = \"newick\",\n  scaffold_in_path = \"https://thebustalab.github.io/data/plant_phylogeny.newick\",\n  members = plant_species$Genus_species[abs(floor(rnorm(60)*100000))]\n)\n## The following species belong to a genus not found in the newick scaffold and were removed: \n## Steirodiscus_schlechteri\n## Phyllagathis_marumiaetricha\n## Jungia_sordida\n## Carpacoce_heteromorpha\n## Huttonaea_woodii\n## Ferulago_macrocarpa\n## Echinospartum_lusitanicum\n## Scurrula_lepidota\n## Astronidium_sudestense\n## \n## Scaffold newick tip Peperomia_fraseri substituted with Peperomia_kimachii \n## Scaffold newick tip Telipogon_pulcher substituted with Telipogon_alberti \n## Scaffold newick tip Elaeocarpus_angustifolius substituted with Elaeocarpus_miriensis \n## Scaffold newick tip Angelica_sinensis substituted with Angelica_anomala \n## Scaffold newick tip Senecio_pterophorus substituted with Senecio_isatideus \n## Scaffold newick tip Macroscepis_hirsuta substituted with Macroscepis_pleistantha \n## Scaffold newick tip Tithonia_diversifolia substituted with Tithonia_fruticosa \n## Scaffold newick tip Spermacoce_princeae substituted with Spermacoce_latituba \n## Scaffold newick tip Bothriocline_laxa substituted with Bothriocline_amphicoma \n## Scaffold newick tip Siler_montanum substituted with Siler_zernyi \n## Scaffold newick tip Teucrium_betchei substituted with Teucrium_rotundifolium \n## Scaffold newick tip Calathea_pluriplicata substituted with Calathea_mediopicta \n## Scaffold newick tip Phyllanthus_maderaspatensis substituted with Phyllanthus_roeperianus \n## Scaffold newick tip Entada_abyssinica substituted with Entada_dolichorrhachis \n## Scaffold newick tip Pimpinella_rhodantha substituted with Pimpinella_cypria \n## Scaffold newick tip Baccharis_neglecta substituted with Baccharis_grisebachii \n## Scaffold newick tip Mikania_micrantha substituted with Mikania_longipes \n## Scaffold newick tip Raphionacme_flanaganii substituted with Raphionacme_hirsuta \n## Scaffold newick tip Senecio_polyanthemoides substituted with Senecio_conferruminatus \n## Scaffold newick tip Heracleum_austriacum substituted with Heracleum_bailletianum \n## Scaffold newick tip Bulbophyllum_hainanense substituted with Bulbophyllum_kaniense \n## Scaffold newick tip Madhuca_microphylla substituted with Madhuca_elmeri \n## Scaffold newick tip Capparis_spinosa substituted with Capparis_cantoniensis \n## Scaffold newick tip Albizia_lebbekoides substituted with Albizia_tulearensis \n## Scaffold newick tip Cephalaria_syriaca substituted with Cephalaria_dirmilensis \n## Scaffold newick tip Adesmia_exilis substituted with Adesmia_uspallatensis \n## Scaffold newick tip Artemisia_biennis substituted with Artemisia_stricta \n## Scaffold newick tip Osteospermum_ilicifolium substituted with Osteospermum_polycephalum \n## Scaffold newick tip Atriplex_californica substituted with Atriplex_lanfrancoi \n## Scaffold newick tip Oberonia_ensiformis substituted with Oberonia_anguina \n## Scaffold newick tip Ceropegia_linearis_subsp._woodii substituted with Ceropegia_andamanica \n## Scaffold newick tip Cousinia_severtzovii substituted with Cousinia_butkovii \n## Scaffold newick tip Hoya_lanceolata substituted with Hoya_loyceandrewsiana \n## Scaffold newick tip Cousinia_microcarpa substituted with Cousinia_trachylepis \n## Scaffold newick tip Bossiaea_cordigera substituted with Bossiaea_oligosperma \n## Scaffold newick tip Cayaponia_tubulosa substituted with Cayaponia_jenmanii \n## Scaffold newick tip Pomatocalpa_kunstleri substituted with Pomatocalpa_linearipetalum \n## Scaffold newick tip Endlicheria_verticillata substituted with Endlicheria_xerampela \n## Scaffold newick tip Eugenia_moschata substituted with Eugenia_azurensis \n## Scaffold newick tip Gastrolobium_punctatum substituted with Gastrolobium_spinosum \n## Scaffold newick tip Dioscorea_mexicana substituted with Dioscorea_pennellii \n## Scaffold newick tip Mitrella_kentii substituted with Mitrella_ledermannii \n## Scaffold newick tip Ageratina_adenophora substituted with Ageratina_ayerscottiana \n## Scaffold newick tip Astragalus_vogelii substituted with Astragalus_jolderensis \n## Scaffold newick tip Eremocharis_fruticosa substituted with Eremocharis_longiramea \n## Scaffold newick tip Spathiphyllum_floribundum substituted with Spathiphyllum_monachinoi \n## Scaffold newick tip Balanops_vieillardii substituted with Balanops_microstachya \n## Pro tip: most tree read/write functions reset node numbers.\n## Fortify your tree and save it as a csv file to preserve node numbering.\n## Do not save your tree as a newick or nexus file.\n\nplot(test_tree_big)\nggtree(test_tree_big)\ntest_tree_big_fortified <- fortify(test_tree_big)\ntest_tree_big_fortified\n## # A tibble: 101 × 9\n##    parent  node branch.length label isTip     x     y branch\n##     <int> <int>         <dbl> <chr> <lgl> <dbl> <dbl>  <dbl>\n##  1     54     1          83.0 Wolf… TRUE   188.     1   147.\n##  2     54     2          83.0 Spat… TRUE   188.     2   147.\n##  3     55     3         138.  Dios… TRUE   188.     3   120.\n##  4     58     4          42.7 Bulb… TRUE   188.     5   167.\n##  5     58     5          42.7 Ober… TRUE   188.     6   167.\n##  6     59     6          32.0 Poma… TRUE   188.     7   172.\n##  7     59     7          32.0 Teli… TRUE   188.     8   172.\n##  8     56     8         135.  Cala… TRUE   188.     4   121.\n##  9     61     9         147.  Pepe… TRUE   188.     9   115.\n## 10     62    10         121.  Endl… TRUE   188.    10   128.\n## # … with 91 more rows, and 1 more variable: angle <dbl>\n\n## Note that \"plant_species\" comes with the phylochemistry source.\n\ntest_tree_big_fortified_w_data <- left_join(test_tree_big_fortified, plant_species, by = c(\"label\" = \"Genus_species\"))\n\ntest_tree_big_fortified_w_data\n## # A tibble: 101 × 14\n##    parent  node branch.length label isTip     x     y branch\n##     <int> <int>         <dbl> <chr> <lgl> <dbl> <dbl>  <dbl>\n##  1     54     1          83.0 Wolf… TRUE   188.     1   147.\n##  2     54     2          83.0 Spat… TRUE   188.     2   147.\n##  3     55     3         138.  Dios… TRUE   188.     3   120.\n##  4     58     4          42.7 Bulb… TRUE   188.     5   167.\n##  5     58     5          42.7 Ober… TRUE   188.     6   167.\n##  6     59     6          32.0 Poma… TRUE   188.     7   172.\n##  7     59     7          32.0 Teli… TRUE   188.     8   172.\n##  8     56     8         135.  Cala… TRUE   188.     4   121.\n##  9     61     9         147.  Pepe… TRUE   188.     9   115.\n## 10     62    10         121.  Endl… TRUE   188.    10   128.\n## # … with 91 more rows, and 6 more variables: angle <dbl>,\n## #   Phylum <chr>, Order <chr>, Family <chr>, Genus <chr>,\n## #   species <chr>\n\nggtree(test_tree_big_fortified_w_data) + \n  geom_point(\n    data = filter(test_tree_big_fortified_w_data, isTip == TRUE),\n    aes(x = x, y = y, fill = Order), size = 3, shape = 21, color = \"black\") +\n  geom_text(\n    data = filter(test_tree_big_fortified_w_data, isTip == TRUE),\n    aes(x = x, y = y, label = y), size = 2, color = \"white\") +\n  geom_tiplab(aes(label = label), offset = 10, size = 2) +\n  theme_void() +\n  scale_fill_manual(values = discrete_palette) +\n  coord_cartesian(xlim = c(0,280)) +\n  theme(\n    legend.position = c(0.15, 0.75)\n  )"},{"path":"phylogenies.html","id":"collapsetree","chapter":"phylogenies","heading":"1.16 collapseTree","text":"Sometimes want view tree higher level taxonomical organization, higher level. can done easily using collapseTree function. takes two arguments: un-fortified tree (tree), two-column data frame (associations). first column data frame tip labels tree, second column higher level organization tip belongs. function prune tree one member higher level organization included output. example, let’s look tree previous section family level:","code":"\ncollapseTree(\n  tree = test_tree_big,\n  associations = data.frame(\n    tip.label = test_tree_big$tip.label,\n    family = plant_species$Family[match(test_tree_big$tip.label, plant_species$Genus_species)]\n  )\n) -> test_tree_big_families\n\nggtree(test_tree_big_families) + geom_tiplab() + coord_cartesian(xlim = c(0,300))"},{"path":"phylogenetic-analyses.html","id":"phylogenetic-analyses","chapter":"phylogenetic analyses","heading":"phylogenetic analyses","text":"","code":""},{"path":"phylogenetic-analyses.html","id":"ancestraltraits","chapter":"phylogenetic analyses","heading":"1.17 ancestralTraits","text":"Note different buildTree’s “ancestral_states”, estimates ancestral sequence states phylogeny nodes. Instead, ancestralTraits estimate traits ancestor, given traits extant species present leaves phylogeny.ancestral states: https://www.phytools.org/eqg2015/asr.html","code":""},{"path":"phylogenetic-analyses.html","id":"phylogenetic-regression","chapter":"phylogenetic analyses","heading":"1.18 phylogenetic regression","text":"","code":""},{"path":"overview-1.html","id":"overview-1","chapter":"overview","heading":"overview","text":"final project course use techniques learned class analyze large dataset, prepare high quality figures, write miniature manuscript describing results:Find data set: Large! >10ish variables, >5ish categoriesSources: research supervisor, CHEM5725 database spreadsheet, google searches!Relevant research interests (ideally).Requires approval Dr. Busta.Ask least three scientific questions.drive data analyses.Requires approval Dr. Busta.Analyze data using learned class.Refer book.Ask Dr. Busta assistance.Create written overview analysis. mini-manuscript R Markdown:Content similar articles looked class, though shorter.Layout similar example (pdf, rmd).","code":""},{"path":"overview-1.html","id":"scope","chapter":"overview","heading":"scope","text":"conducting project type, common mismatches scope project conducted written report presented (see image ). often spend LOTS time exploring data running dead ends, conclusions mundane, questions can’t answer. write report project, often focus report specific discovery made vast avenues exploration, rather boring reader mundane details.","code":""},{"path":"overview-1.html","id":"order","chapter":"overview","heading":"order","text":"manuscript comprised title, abstract, introduction, results discussion section, figures captions, conclusions section, least five references. Please note following preparing manuscript: orders presentation preparation (see images )! instances scientist may choose write components manuscript order appear page, always case. order preparation suggsted designed minimize amount revision / re-writing needs performed manuscript preparation process. Note suggested order composition line class schedule rest semester.","code":""},{"path":"overview-1.html","id":"scientific-questions","chapter":"overview","heading":"scientific questions","text":"DESCRIPTIVE questions (often addressed summary statistics):many white pines Duluth area?many white pines Duluth area?wolf pack’s distribution range?wolf pack’s distribution range?frequently blizzards occurr?frequently blizzards occurr?CORRELATIVE questions (often addressed regression modeling):relationship leaf color soil nitrogen content oak seedlings?relationship leaf color soil nitrogen content oak seedlings?spider’s reproduction rate change change season?spider’s reproduction rate change change season?COMPARATIVE questions (often addressed dimensionality reduction, clustering, /comparisons means):rivers streams along North Shore, similar terms chemistry?rivers streams along North Shore, similar terms chemistry?factors drive differences chemistry Lake Superior inland lakes?factors drive differences chemistry Lake Superior inland lakes?difference diversity cyanobacteria live St. Louis estuary Twin Ports Harbor area?difference diversity cyanobacteria live St. Louis estuary Twin Ports Harbor area?","code":""},{"path":"figures-captions.html","id":"figures-captions","chapter":"figures & captions","heading":"figures & captions","text":"high quality figure one , example, axes tick labels overlap also fill space available , colors used, raw data plotted (possible), axes labels customized, appropriate theme chosen, geoms chosen carefully. plots visually attractive professional.","code":""},{"path":"figures-captions.html","id":"zoomed-figures","chapter":"figures & captions","heading":"zoomed figures","text":"Zoom certain plot regions","code":"\np <- ggplot(mpg, aes(displ, hwy, colour = factor(cyl))) +\n  geom_point() \n\ndata.tb <- \n  tibble(x = 7, y = 44, \n         plot = list(p + \n                       coord_cartesian(xlim = c(4.9, 6.2), \n                                       ylim = c(13, 21)) +\n                       labs(x = NULL, y = NULL) +\n                       theme_bw(8) +\n                       scale_colour_discrete(guide = \"none\")))\n\nggplot(mpg, aes(displ, hwy, colour = factor(cyl))) +\n  geom_plot(data = data.tb, aes(x, y, label = plot)) +\n  annotate(geom = \"rect\", \n           xmin = 4.9, xmax = 6.2, ymin = 13, ymax = 21,\n           linetype = \"dotted\", fill = NA, colour = \"black\") +\n  geom_point() "},{"path":"figures-captions.html","id":"inset-figures","chapter":"figures & captions","heading":"inset figures","text":"","code":""},{"path":"figures-captions.html","id":"plot-insets","chapter":"figures & captions","heading":"plot insets","text":"","code":"\np <- ggplot(mpg, aes(factor(cyl), hwy, fill = factor(cyl))) +\n  stat_summary(geom = \"col\", fun = mean, width = 2/3) +\n  labs(x = \"Number of cylinders\", y = NULL, title = \"Means\") +\n  scale_fill_discrete(guide = \"none\")\n\ndata.tb <- tibble(x = 7, y = 44, \n                  plot = list(p +\n                                theme_bw(8)))\n\nggplot(mpg, aes(displ, hwy, colour = factor(cyl))) +\n  geom_plot(data = data.tb, aes(x, y, label = plot)) +\n  geom_point() +\n  labs(x = \"Engine displacement (l)\", y = \"Fuel use efficiency (MPG)\",\n       colour = \"Engine cylinders\\n(number)\") +\n  theme_bw()"},{"path":"figures-captions.html","id":"image-insets","chapter":"figures & captions","heading":"image insets","text":"","code":"\nIsoquercitin_synthase <- magick::image_read(\"https://thebustalab.github.io/integrated_bioanalytics/images/homology.png\")\ngrobs.tb <- tibble(x = c(0, 10, 20, 40), y = c(4, 5, 6, 9),\n                   width = c(0.05, 0.05, 0.01, 1),\n                   height =  c(0.05, 0.05, 0.01, 0.3),\n                   grob = list(grid::circleGrob(), \n                               grid::rectGrob(), \n                               grid::textGrob(\"I am a Grob\"),\n                               grid::rasterGrob(image = Isoquercitin_synthase)))\n\nggplot() +\n  geom_grob(data = grobs.tb, \n            aes(x, y, label = grob, vp.width = width, vp.height = height),\n            hjust = 0.7, vjust = 0.55) +\n  scale_y_continuous(expand = expansion(mult = 0.3, add = 0)) +\n  scale_x_continuous(expand = expansion(mult = 0.2, add = 0)) +\n  theme_bw(12)\n\nggplot() +\n  annotate(\"grob\", x = 1, y = 3, vp.width = 0.5,\n           label = grid::rasterGrob(image = Isoquercitin_synthase, width = 1)) +\n  theme_bw(12)"},{"path":"figures-captions.html","id":"composite-figures","chapter":"figures & captions","heading":"composite figures","text":"Many high quality figures composite figures one panel. simple way make figures R. First, make component composite figure send plot new object:Now, add together lay . plot_annotation() allows quick numbering lettering subpanels. Note & used add ggplot elements entire plot, opposed last plot list. Let’s look various ways lay :","code":"\ncolor_palette <- RColorBrewer::brewer.pal(11, \"Paired\")\nnames(color_palette) <- unique(alaska_lake_data$element)\n\nplot1 <- ggplot(\n  data = filter(alaska_lake_data, element_type == \"bound\"),\n  aes(y = lake, x = mg_per_L)\n) +\n  geom_col(\n    aes(fill = element), size = 0.5, position = \"dodge\",\n    color = \"black\"\n  ) +\n  facet_grid(park~., scales = \"free\", space = \"free\") +\n  theme_bw() + \n  scale_fill_manual(values = color_palette) +\n  scale_y_discrete(name = \"Lake Name\") +\n  scale_x_continuous(name = \"Abundance mg/L)\") +\n  theme(\n    text = element_text(size = 14)\n  )\n\nplot2 <- ggplot(\n  data = filter(alaska_lake_data, element_type == \"free\"),\n  aes(y = lake, x = mg_per_L)\n) +\n  geom_col(\n    aes(fill = element), size = 0.5, position = \"dodge\",\n    color = \"black\"\n  ) +\n  facet_grid(park~., scales = \"free\", space = \"free\") +\n  theme_bw() + \n  scale_fill_manual(values = color_palette) +\n  scale_y_discrete(name = \"Lake Name\") +\n  scale_x_continuous(name = \"Abundance mg/L)\") +\n  theme(\n    text = element_text(size = 14)\n  )\nplot1 + plot2 + plot_annotation(tag_levels = 'A')\nplot1 / plot2 + plot_annotation(tag_levels = 'A')\n(plot1 + plot2) / plot1 + plot_annotation(tag_levels = 'A')\n(plot1 + plot2) + plot_annotation(tag_levels = 'A') + \n  plot_layout(widths = c(1.1, 3), guides = 'collect') &\n  theme(legend.position = 'right')"},{"path":"figures-captions.html","id":"exporting-graphics","chapter":"figures & captions","heading":"exporting graphics","text":"export graphics R, consider code .  something like: “C:\\Desktop\\the_file.png” (.e. path specific file .png suffix. file yet exist - already exist, overwritten. adjust height width get image look want, dialed , crank resolution 1200 2400 export final version.","code":"plot <- ggplot(data, aes(x = x, y = y)) + geom_point()\n\npng(filename = <path_to_file_you_want_to_create>, width = 8, height = 8, res = 600, units = \"in\")\n\nplot\n\ndev.off()"},{"path":"figures-captions.html","id":"captions","chapter":"figures & captions","heading":"captions","text":"Title - overall description shownFor subplot:type plot (line plot, bar chart, etc.)Describe plotted y vs x words.Describe bar, point, error bar represents.applicable, describe number independent samples measurements (sometimes called “replicates”) underlie given geometric feature summary statistic.Describe data .Avoid abbreviations, use , specify mean.example:","code":"\n(plot1 + plot2 + labs(caption = str_wrap(\"Figure 1: Carbon, nitrogen, and phosphorous in Alaskan lakes. A) A bar chart showing the abundance (in mg per L, x-axis) of the bound elements (C, N, and P) in various Alaskan lakes (lake names on y-axis) that are located in one of three parks in Alaska (park names on right y groupings). B) A bar chart showing the abundance (in mg per L, x-axis) of the free elements (Cl, S, F, Br, Na, K, Ca, and Mg) in various Alaskan lakes (lake names on y-axis) that are located in one of three parks in Alaska (park names on right y groupings). The data are from a public chemistry data repository. Each bar represents the result of a single measurement of a single analyte, the identity of which is coded using color as shown in the color legend. Abbreviations: BELA - Bering Land Bridge National Preserve, GAAR - Gates Of The Arctic National Park & Preserve, NOAT - Noatak National Preserve.\", 90))) + plot_annotation(tag_levels = 'A') + \n  plot_layout(widths = c(1.1, 3), guides = 'collect') &\n  theme(legend.position = 'right')"},{"path":"figures-captions.html","id":"further-reading-9","chapter":"figures & captions","heading":"further reading","text":"","code":""},{"path":"figures-captions.html","id":"insets","chapter":"figures & captions","heading":"insets","text":"https://docs.r4photobiology.info/ggpp/articles/grammar-extensions.html#geom_plot","code":""},{"path":"figures-captions.html","id":"plot-layout","chapter":"figures & captions","heading":"plot layout","text":"One option plot layout, patchwork. one quick simple.\npatchwork, plot layoutAnother option plot layout cowplot. Cowplot bit complicated, versatile.\ncowplot Github","code":""},{"path":"results-and-discussion.html","id":"results-and-discussion","chapter":"results and discussion","heading":"results and discussion","text":"Objective: Walk reader results, drawing conclusions making interpretations go.go: make notes go introduction.","code":""},{"path":"results-and-discussion.html","id":"structure","chapter":"results and discussion","heading":"structure","text":"(key: number suggested sentences: purpose: “example”)Introductory paragraph:\n1: Review aim paper: “order understand…”\n3-4: Combine methods summary (generalized summary results?) call subsections: “used method X quantify property Y study subject (section 2.1)”\n\n\n1: Review aim paper: “order understand…”3-4: Combine methods summary (generalized summary results?) call subsections: “used method X quantify property Y study subject (section 2.1)”\n\nsubsection paragraph:\n\n1: Purpose work described paragraph: “order determine…”\n1: Review methods experimental design specific subsection (necessary)\n4-5: Results method experiment (.e. data features)\n1-2: Comparison new results literature (possible)\n1-2: Conclusion combined results concluding remark “Thus, analysis X revealed …”\n1: Interpretation conclusion larger context (possible / reasonable)\n1: Purpose work described paragraph: “order determine…”1: Review methods experimental design specific subsection (necessary)4-5: Results method experiment (.e. data features)1-2: Comparison new results literature (possible)1-2: Conclusion combined results concluding remark “Thus, analysis X revealed …”1: Interpretation conclusion larger context (possible / reasonable)Let’s look example:2. Results Discussion.order better understand pollution state Minnesota, study focused detailed analyses chemical measurements soil samples 300 sites around state. analyses consisted principal components analysis determine sites similar one another (Section 2.1) followed statistical tests see whether differences detected sites’ chemistry (Section 2.2).2.1 Principal Components AnalysisTo understand relationships sites soil chemistry sampled, principal components analysis used. 20 different analytes, contained halogen atoms, included analysis. scatter plot showing position 300 samples space defined dimesions 1 2 (explain 54% 35% total variance dataset, respectively), revealed two major clusters present, small number outliers (Fig. 1). color coding two clusters according whether samples collected rural versus urban areas, possible see first cluster made almost exclusively samples urban areas, second cluster made almost entirely samples rural areas. suggested variance pollutant chemistry among samples collected assocaited urban versus rural environments.2.2 Statistical AnalysesUsing groupings identified via principal components analysis, statistical tests conducted determine chemical abundances differed groups. Tests normality homogeneity variance (Shapiro Levene tests) revealed data assessed using ANOVA instead required use non-parametric test. Accordingly, Kruskall-Wallis test followed post-hoc Dunn tests applied, showed abundances halogenated pollutants significantly higher urban versus rural areas (p = 0.0035, Fig. 2A). direct observations consistent conclusions drawn others recent literature reviews focused hydrocarbon compounds (Petrucci et al., 2018; Hendrix et al., 2019). Thus, new chemical analyses presented demonstrate discrepancy urban versus rural pollution true hydrocarbon compounds (found previously), also halogenated compounds. Together, findings strongly suggest either cities source pollution mechanism concentrates pollution cities.","code":""},{"path":"results-and-discussion.html","id":"suggestions","chapter":"results and discussion","heading":"suggestions","text":"efficient way write results discussion section format outlined ? Yes. Follow step--step instructions :","code":""},{"path":"results-and-discussion.html","id":"outline-then-draft-paragraphs","chapter":"results and discussion","heading":"outline then draft paragraphs","text":"Identify “data features” -> “conclusion” combinations. Using figures, make list potentially interesting features data, pair feature possible conclusiona lead . Example:“GC-MS data presented indicates cities higher levels pollution rural areas (Fig. 1),” (data feature)“suggesting either cities source pollution mechanism concentrates pollution cities.” (conclusion)Perform targeted literature searches. Expand “data feature” -> “conclusion” combinations “supplementary information” “literature information”. Example:“GC-MS data presented indicates cities higher levels pollution rural areas.” (data feature)“direct observations consistent conclusions drawn others recent literature reviews (Petrucci., 2018; Hendrix et al., 2019)” (literature information)“Overall, suggests either cities source pollution mechanism concentrates pollution cities.” (conclusion)Group “data feature” -> “supp/lit info” -> “conclusion” combinations paragraphs. Edit conclusion highlights new contribution data makes situation. Also consider whether parargaphs now suggest existence mechanisms. Example (note conclusion sentence italics highlights new findings):“GC-MS data presented indicates cities higher levels pollution rural areas (Fig. 1). direct observations consistent meta-analyses previously published observations (Supplemental Figure 1), well conclusions drawn others recent literature reviews (et al., 2018; person et al., 2019). new chemical analyses presented thus confirm true hydrocarbon compounds, extend observation halogenated compounds atmosphere. Together findings strongly suggest either cities source pollution mechanism concentrates pollution cities.","code":""},{"path":"results-and-discussion.html","id":"order-then-edit-paragraphs","chapter":"results and discussion","heading":"order then edit paragraphs","text":"Identify paragraph characteristics groupConsider whether paragraphs prerequisites others whether paragraphs can grouped according topic.Group paragraphs according topic prerequisite dependencies (putting prereq dependencies close eachother possible.)Rearrange paragraph groups Create natural flow. Consider:Starting group paragraphs relevant overall pitch/goal paperEnding group paragraphs future perspectiveEnding strong suit (.e. something speculative)Consider putting orphaned paragraphs (shortened version ) conclusion section.Edit transitions groups. Edit paragraph, particularly first last sentences, connect paragraphs flowing document. Specifically, means several things:implicit cross-paragraph references (.e. new paragraph begin “compound described exhibited interesting properties”, rather, “3-hydroxycinnamic acid exhibited interesting properties.”).abrupt jumps subject paragraphs, consider breaking discussion subsections help reader identify logical resting points.discussion require reader go back read first half order understand second half.","code":""},{"path":"conclusion-and-introduction.html","id":"conclusion-and-introduction","chapter":"conclusion and introduction","heading":"conclusion and introduction","text":"Objective (conclusion): convey short statement take-home messages study. important things want reader remember study?Objective (conclusion): convey short statement take-home messages study. important things want reader remember study?Objective (introduciton): prepare reader giving reader sufficient background understand study whole. therefore contain information pertinent understanding study broader significance.Objective (introduciton): prepare reader giving reader sufficient background understand study whole. therefore contain information pertinent understanding study broader significance.Make sure scope introduction -line scope conclusion. way, reader underwhelmed, work undersold.Make sure scope introduction -line scope conclusion. way, reader underwhelmed, work undersold.","code":""},{"path":"conclusion-and-introduction.html","id":"structure-1","chapter":"conclusion and introduction","heading":"structure","text":"Conclusion:One paragraph\n\n2-3: Summarize -arching conclusions section paper (omit details described results discussion)\n2-3: Based general description findings, use pros cons argue , possible, alternative hypotheses.\n1-2: Suggest experiments test hypotheses.\n1-2: Describe future directions.\n\n2-3: Summarize -arching conclusions section paper (omit details described results discussion)2-3: Based general description findings, use pros cons argue , possible, alternative hypotheses.1-2: Suggest experiments test hypotheses.1-2: Describe future directions.\nIntroduction:Paragraph 1: Introduce topic\n1: Introduce topic , ideally, application research describe. Grab reader’s attention.\n1: State topic important.\n1: Describe known topic (least, pertains work hand).\n1: Identify gap knowledge: “despite research area, don’t know topic.”\n1: List negative things happen don’t fill gap knowledge.\n1: Introduce topic , ideally, application research describe. Grab reader’s attention.1: State topic important.1: Describe known topic (least, pertains work hand).1: Identify gap knowledge: “despite research area, don’t know topic.”1: List negative things happen don’t fill gap knowledge.Paragraph 2: Provide background information\n3-5: Describe, moderate detail, background information (concepts, literature) relevant study.\n1: End saying details just described relate application/topic described first paragraph.\n3-5: Describe, moderate detail, background information (concepts, literature) relevant study.1: End saying details just described relate application/topic described first paragraph.Paragraph 3: Objectives study\n1: State objective study.\n1: Briefly describe done techniques instruments used.\n1-2: project, briefly describe got data, cleaned , merged multiple datasets, etc.\n1: (optional) State major conclusion work means application described paragraph 1.\n1: State objective study.1: Briefly describe done techniques instruments used.1-2: project, briefly describe got data, cleaned , merged multiple datasets, etc.1: (optional) State major conclusion work means application described paragraph 1.","code":""},{"path":"conclusion-and-introduction.html","id":"suggestions-1","chapter":"conclusion and introduction","heading":"suggestions","text":"something well-established, say .clear speculation.Last paragraph can mention objectives list form.Last sentence can briefly mention methods (specific techniques instruments) used.","code":""},{"path":"abstract-and-title.html","id":"abstract-and-title","chapter":"abstract and title","heading":"abstract and title","text":"","code":""},{"path":"abstract-and-title.html","id":"abstract","chapter":"abstract and title","heading":"1.19 abstract","text":"Structure One paragraph Use 200 - 500 words (ideally 400 words)\n1-2 sentences: Introduction: Describe topic, motivation, overall purpose research (research interesting important? gap knowledge fill?)\n1-2 sentences: Objective: Specific research objective, potentially hypotheses/predictions, .\n1-2 sentences: Methods: concise overview methods used address research questions.\n2-3 sentences: Results/Discussion: Describe major results (found) interpretation results (results mean).\n1-2 sentences: Conclusions: Synthesizes major contributions study context larger field study belongs. learn bigger picture field general study?\n1-2 sentences: Introduction: Describe topic, motivation, overall purpose research (research interesting important? gap knowledge fill?)1-2 sentences: Objective: Specific research objective, potentially hypotheses/predictions, .1-2 sentences: Methods: concise overview methods used address research questions.2-3 sentences: Results/Discussion: Describe major results (found) interpretation results (results mean).1-2 sentences: Conclusions: Synthesizes major contributions study context larger field study belongs. learn bigger picture field general study?Function: abstract proves short summary entire study. abstract include motivation reason conducting study, research question hypothesis , experiments conducted, results , results interpreted light research question hypothesis, concluding sentence general contribution importance study. good abstract :\nInform readers article’s content\nSummarize complex information clear, concise manner\nHelp readers decide whether read article\nUsed conferences summarize speaker say /presentation\nInform readers article’s contentSummarize complex information clear, concise mannerHelp readers decide whether read articleUsed conferences summarize speaker say /presentation","code":""},{"path":"abstract-and-title.html","id":"title","chapter":"abstract and title","heading":"1.20 title","text":"Structure One sentence Use 75-140 characters (ideally 125 characters). essentially two types titles: descriptive titles mechanistic titles.\nmanuscript exploratory research, consider using descriptive title. example:\n“Comparative analysis carbon, sulfur, phoshorous chemistry six Alaskan lakes.”\n\nmanuscript hypothesis-driven research, consider using mechanistic title. example:\n“Dissolved organic carbon Alaskan lakes heavily influenced water pH temperature.”\n\nmanuscript exploratory research, consider using descriptive title. example:\n“Comparative analysis carbon, sulfur, phoshorous chemistry six Alaskan lakes.”\n“Comparative analysis carbon, sulfur, phoshorous chemistry six Alaskan lakes.”manuscript hypothesis-driven research, consider using mechanistic title. example:\n“Dissolved organic carbon Alaskan lakes heavily influenced water pH temperature.”\n“Dissolved organic carbon Alaskan lakes heavily influenced water pH temperature.”Function: title captures attention highlight research question(s). good title :\nindicative content paper\nAttract interest potential readers\nReflect whether article deascriptive mechanistic\nInclude important keywords\nindicative content paperAttract interest potential readersReflect whether article deascriptive mechanisticInclude important keywords","code":""},{"path":"abstract-and-title.html","id":"further-reading-10","chapter":"abstract and title","heading":"1.21 further reading","text":"Titles GuideTitles Guide[Abstract Guide] (https://www.cbs.umn.edu/sites/default/files/public/downloads/Annotated_Nature_abstract.pdf)[Abstract Guide] (https://www.cbs.umn.edu/sites/default/files/public/downloads/Annotated_Nature_abstract.pdf)","code":""},{"path":"image-color-analysis.html","id":"image-color-analysis","chapter":"image color analysis","heading":"image color analysis","text":"analyze color images use interactive app called analyzeImage(). takes two arguments: share_link, monolist_out_path. share_link Google Drive share link photo wish analyze. share_link can also share link Google Drive folder, case app allow cycle photos folder one--one. monolist_out_path path new existing .csv file local sytem results saved work. example. Remember, Mac use path single slashes, example: /Users/bust0037/Desktop/output.csv. PC use path double slashes, example: C://Users//Busta_Lab//Desktop//output.csv.","code":"\nanalyzeImage(\n  share_link = \"https://drive.google.com/file/d/1rvfh9_DqEWlpaegGwfLZLdjjYEDlM0ZL/view?usp=sharing\",\n  monolist_out_path = \"/Users/bust0037/Desktop/output.csv\"\n)"},{"path":"images-of-mass-spectra.html","id":"images-of-mass-spectra","chapter":"images of mass spectra","heading":"images of mass spectra","text":"","code":"\nanalyzeMassSpectralImages()"},{"path":"links.html","id":"links","chapter":"links","heading":"links","text":"","code":""},{"path":"links.html","id":"geoms","chapter":"links","heading":"geoms","text":"geoms ggplot2 cheatsheet","code":""},{"path":"links.html","id":"colors","chapter":"links","heading":"colors","text":"ColorBrewer2","code":""},{"path":"r-faq.html","id":"r-faq","chapter":"r faq","heading":"r faq","text":"","code":""},{"path":"r-faq.html","id":"filtering","chapter":"r faq","heading":"filtering","text":"filter(<data>, <variable> < 18) ## less 18filter(<data>, <variable> <= 18) ## less equal 18filter(<data>, <variable> > 18) ## greater 18filter(<data>, <variable> >= 18) ## greater equal 18filter(<data>, <variable> == 18) ## equals 18filter(<data>, <variable> != 18) ## equal 18filter(<data>, <variable> == 18 | <variable> == 19) ## equal 18 19filter(<data>, <variable> %% c(18, 19, 20) ## equal 18 19 20","code":""},{"path":"r-faq.html","id":"ordering-1","chapter":"r faq","heading":"ordering","text":"list numeric element inherent order : -inf -> +inf. list character element also inherent order : -> Z, ’s mixed number letter list (interpreted R character list): 0 -> 9 -> -> Z.However, cases want list character elements order -> Z. cases, want convert list character elements list factor elements. Factors lists character elements inherent order -> Z. example, plot , y axis , perhaps, “correct” order:fix ? need convert column group_number list factors correct order (see ). , use command factor, accept argument called levels can define order characters :Notice now look type data contained column group_number says “”. great! means converted column list factors, instead characters. Now happens make plot?VICTORY!","code":"\nggplot(periodic_table) +\n  geom_point(aes(y = group_number, x = atomic_mass_rounded))\nperiodic_table$group_number <- factor(\n  periodic_table$group_number,\n  levels = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"lanthanides\", \"actinides\")\n)\n\nperiodic_table\n## # A tibble: 118 × 41\n##    atomic_number element_name atomic_symbol group_number\n##            <dbl> <chr>        <chr>         <fct>       \n##  1             1 hydrogen     H             1           \n##  2             2 helium       He            18          \n##  3             3 lithium      Li            1           \n##  4             4 beryllium    Be            2           \n##  5             5 boron        B             13          \n##  6             6 carbon       C             14          \n##  7             7 nitrogen     N             15          \n##  8             8 oxygen       O             16          \n##  9             9 fluorine     F             17          \n## 10            10 neon         Ne            18          \n## # … with 108 more rows, and 37 more variables:\n## #   period <dbl>, atomic_mass_rounded <dbl>,\n## #   melting_point_C <dbl>, boiling_point_C <dbl>,\n## #   state_at_RT <chr>, density_g_per_mL <dbl>,\n## #   electronegativity_pauling <dbl>,\n## #   first_ionization_poten_eV <dbl>,\n## #   second_ionization_poten_eV <dbl>, …\nggplot(periodic_table) +\n  geom_point(aes(y = group_number, x = atomic_mass_rounded))"},{"path":"r-faq.html","id":"column-manipulation","chapter":"r faq","heading":"column manipulation","text":"select specific columns:remove certain columns:","code":"\nalaska_lake_data %>%\n  select(water_temp, pH)\n## # A tibble: 220 × 2\n##    water_temp    pH\n##         <dbl> <dbl>\n##  1       6.46  7.69\n##  2       6.46  7.69\n##  3       6.46  7.69\n##  4       6.46  7.69\n##  5       6.46  7.69\n##  6       6.46  7.69\n##  7       6.46  7.69\n##  8       6.46  7.69\n##  9       6.46  7.69\n## 10       6.46  7.69\n## # … with 210 more rows\nalaska_lake_data %>%\n  select(!water_temp)\n## # A tibble: 220 × 6\n##    lake            park     pH element mg_per_L element_type\n##    <chr>           <chr> <dbl> <chr>      <dbl> <chr>       \n##  1 Devil_Mountain… BELA   7.69 C          3.4   bound       \n##  2 Devil_Mountain… BELA   7.69 N          0.028 bound       \n##  3 Devil_Mountain… BELA   7.69 P          0     bound       \n##  4 Devil_Mountain… BELA   7.69 Cl        10.4   free        \n##  5 Devil_Mountain… BELA   7.69 S          0.62  free        \n##  6 Devil_Mountain… BELA   7.69 F          0.04  free        \n##  7 Devil_Mountain… BELA   7.69 Br         0.02  free        \n##  8 Devil_Mountain… BELA   7.69 Na         8.92  free        \n##  9 Devil_Mountain… BELA   7.69 K          1.2   free        \n## 10 Devil_Mountain… BELA   7.69 Ca         5.73  free        \n## # … with 210 more rows"},{"path":"r-faq.html","id":"user-color-palettes","chapter":"r faq","heading":"user color palettes","text":"Suppose want create specific color palette pack alaska_lake_data. three unique parks:First define colors want:name vector according park want color:Now feed object values argument scale_color_manual (scale_fill_manual, want fill):","code":"\nunique(alaska_lake_data$park)\n## [1] \"BELA\" \"GAAR\" \"NOAT\"\ncustom_colors_for_lakes <- c(\"#1a9850\", \"#ffffbf\", \"#d73027\")\ncustom_colors_for_lakes\n## [1] \"#1a9850\" \"#ffffbf\" \"#d73027\"\nnames(custom_colors_for_lakes) <- c(\"GAAR\", \"NOAT\", \"BELA\")\ncustom_colors_for_lakes\n##      GAAR      NOAT      BELA \n## \"#1a9850\" \"#ffffbf\" \"#d73027\"\nggplot(alaska_lake_data) + \n  geom_point(aes(x = pH, y = water_temp, fill = park), size = 5, shape = 21, color = \"black\") +\n  scale_fill_manual(values = custom_colors_for_lakes) +\n  theme_classic()"},{"path":"templates.html","id":"templates","chapter":"templates","heading":"templates","text":"","code":""},{"path":"templates.html","id":"matrix-analyses","chapter":"templates","heading":"1.22 matrix analyses","text":"","code":""},{"path":"templates.html","id":"basic-runmatrixanalysis-template","chapter":"templates","heading":"1.22.1 basic runMatrixAnalysis() template","text":"","code":"\n\nrunMatrixAnalysis(\n                \n  data = NULL,\n\n  analysis = c(\"hclust\", \"pca\", \"pca_ord\", \"pca_dim\"),\n\n  column_w_names_of_multiple_analytes = NULL,\n  column_w_values_for_multiple_analytes = NULL,\n    \n  columns_w_values_for_single_analyte = NULL,\n\n  columns_w_sample_ID_info = NULL\n\n)"},{"path":"templates.html","id":"advanced-runmatrixanalysis-template","chapter":"templates","heading":"1.22.2 advanced runMatrixAnalysis() template","text":"","code":"\n\nrunMatrixAnalysis(\n  data = NULL, # the data set to work on\n  analysis = c(\"hclust\", \"pca\", \"pca_ord\", \"pca_dim\"), # the analysis to conduct\n  column_w_names_of_multiple_analytes = NULL, # a column with names of multiple analytes\n  column_w_values_for_multiple_analytes = NULL, # a column with quantities measured for multiple analytes\n  columns_w_values_for_single_analyte = NULL, # a column with quantities measured for a single analyte\n  columns_w_additional_analyte_info = NULL, # a column with character or numeric information about analytes that was not \"measured\" as part of the experiment.\n  columns_w_sample_ID_info = NULL, # a column with information about the sample (i.e. contents from the test tube's label)\n  transpose = FALSE,\n  kmeans = c(\"none\", \"auto\", \"elbow\", \"1\", \"2\", \"3\", \"etc.\"),\n  na_replacement = c(\"none\", \"mean\", \"zero\", \"drop\")\n)"}]
