[{"path":"index.html","id":"section","chapter":"","heading":"","text":"","code":""},{"path":"phylochemistry.html","id":"phylochemistry","chapter":"phylochemistry","heading":"phylochemistry","text":"Analytical chemists separate, identify, quantify matter. connect data world around us answer scientific questions, multiple chemical entities must separated, quantified, identified. Challenge 1: ability collect analytical data expands, must ability effectively analyze data - whether ’s 10 data points 10,000.Analytical chemists separate, identify, quantify matter. connect data world around us answer scientific questions, multiple chemical entities must separated, quantified, identified. Challenge 1: ability collect analytical data expands, must ability effectively analyze data - whether ’s 10 data points 10,000.One largest obstacles facing scientists communicating work non-scientists. Challenge 2: must practice oral written science communication technical non-technical formats.One largest obstacles facing scientists communicating work non-scientists. Challenge 2: must practice oral written science communication technical non-technical formats.course set first steps toward meeting challenges outlined . first half, ’ll explore, critique, practice methods handling communicating data generated large analytical chemistry projects. second half, ’ll apply methods large datasets hone writing skills developing mini manuscripts incorporate large datasets.","code":""},{"path":"section-1.html","id":"section-1","chapter":"","heading":"","text":"","code":""},{"path":"getting-started.html","id":"getting-started","chapter":"GETTING STARTED","heading":"GETTING STARTED","text":"","code":""},{"path":"installation.html","id":"installation","chapter":"1 installation","heading":"1 installation","text":"","code":""},{"path":"installation.html","id":"r","chapter":"1 installation","heading":"1.1 R","text":"R computing language use run chemometric analyses produce high quality plots. already R installed (need least version 4.1.1), can go straight installing RStudio. , follow steps install R:Go https://cran.r-project.org/Go https://cran.r-project.org/Click “Download R <operating system>” (see footnote), depending operating system select “Download R Linux,” “Download R (Mac) OS X,” “Download R Windows.”Click “Download R <operating system>” (see footnote), depending operating system select “Download R Linux,” “Download R (Mac) OS X,” “Download R Windows.”use <notation> quite bit. indicates place insert information, data, something similar corresponds particular situation. example means insert “operating system,” .e. Linux, (Mac) OS X, Windows.Mac: download .pkg file latest release. PC: click “install R first time,” click “Download R <version> Windows.”Mac: download .pkg file latest release. PC: click “install R first time,” click “Download R <version> Windows.”executable finishes downloading (Windows, file .exe extension; Mac, .dmg file .dmg inside .pkg file), open file administrator, follow installation instructions. R install without problems. can click OK windows pop-installation, choose “regular” installation (given choice).executable finishes downloading (Windows, file .exe extension; Mac, .dmg file .dmg inside .pkg file), open file administrator, follow installation instructions. R install without problems. can click OK windows pop-installation, choose “regular” installation (given choice).trouble installing R please google “Install R Mac” “Install R PC” follow one many video tutorials . tried still trouble, please contact .","code":""},{"path":"installation.html","id":"rstudio","chapter":"1 installation","heading":"1.2 RStudio","text":"install R, can install RStudio, essentially convenient way interacting R. people like RStudio prefer interact R directly. fine, many beginning R users find RStudio helpful, recommend . Follow steps install RStudio:Go https://rstudio.com/Go https://rstudio.com/Click “DOWNLOAD” top page.Click “DOWNLOAD” top page.Click “DOWNLOAD” button corresponds RStudio Desktop free Open Source License.Click “DOWNLOAD” button corresponds RStudio Desktop free Open Source License.page may automatically detect operating system using recommend version . , download file (.exe PC .dmg Mac). , scroll “Installers” section download file right . Open file administrator, follow installation instructions. RStudio install without problems. can click OK windows pop-installation, choose “regular” installation (given choice).page may automatically detect operating system using recommend version . , download file (.exe PC .dmg Mac). , scroll “Installers” section download file right . Open file administrator, follow installation instructions. RStudio install without problems. can click OK windows pop-installation, choose “regular” installation (given choice).trouble installing RStudio please google “Install RStudio Mac” “Install RStudio PC” following one many video tutorials . tried still trouble, please contact .","code":""},{"path":"installation.html","id":"verification","chapter":"1 installation","heading":"1.3 Verification","text":"Open RStudio clicking appropriate file applications folder, wherever saved computer. see several windows. One Code Editor, one R Console, one Workspace History, one Plots Files window.R Console window > . Type head(Indometh). display first six lines data set describing pharmacokinets indomethacin. one built datasets R - need additional files run test.Next, type plot(Indometh) R Console. plot indomethacin dataset basic way.commands (head(Indometh) plot(Indometh)) worked error messages installation, ready proceed.","code":"\nhead(Indometh)\n##   Subject time conc\n## 1       1 0.25 1.50\n## 2       1 0.50 0.94\n## 3       1 0.75 0.78\n## 4       1 1.00 0.48\n## 5       1 1.25 0.37\n## 6       1 2.00 0.19\nplot(Indometh)"},{"path":"installation.html","id":"tidyverse","chapter":"1 installation","heading":"1.4 tidyverse","text":"us run analyses, need install set add-functions expand R’s capabilities. functions collected something called tidyverse, well-known widely-used R package. need manually download anything complete installation - R . R Console, type install.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\") install tidyverse. Let’s try :RSudio might ask : “want install sources packages need compilation? (Yes//cancel),” now, type press enter.Let’s make sure version tidyverse installed correctly. , load tidyverse library/package inside R session. can using library(tidyverse). Let’s try :library load correctly - set go! , try updating R / RStudio installations, re installing tidyverse. still fails, please contact .","code":"\ninstall.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\nlibrary(tidyverse)"},{"path":"installation.html","id":"tex","chapter":"1 installation","heading":"1.5 TeX","text":"class generate high quality reports suitable submission supervisors, academic journals, etc. , need typesetting engine TeX. ways . easiest way using following commands:Mac, may get error “able write path” something like . case probably need open terminal run following two commands:sudo chown -R `whoami`:admin /usr/local/binand ~/Library/TinyTeX/bin/*/tlmgr path addThen, Mac PC, need :options : Windows, download install MikTeX. OSX, can download install MacTeX.","code":"\ninstall.packages(c('tinytex', 'rmarkdown'))\ntinytex::install_tinytex()"},{"path":"installation.html","id":"phylochemistry-1","chapter":"1 installation","heading":"1.6 phylochemistry","text":"addition tidyverse, variety packages need, well datasets custom functions. call loaded following.First, attempt load phylochemistry:first time try , likely say: “need install following packages proceeding […] Run: installPhylochemistry() automatically install required packages.”means prerequisite packages phylochemistry needs installed. happens, run following:Sometimes run installPhylochemistry() get message:Update //none? [/s/n]:case, generally advisable enter console press enter, indicating R wish update anything everything can updated.times may get message:want install sources packages need compilation? (Yes//cancel)can reply yes wish, simplicity’s sake okay say . usually start saying , reverting yes things don’t work line.complete, assuming errors displayed, attempt load phylochemistry :","code":"\nsource(\"http://thebustalab.github.io/phylochemistry/phylochemistry.R\")\ninstallPhylochemistry()\nsource(\"http://thebustalab.github.io/phylochemistry/phylochemistry.R\")"},{"path":"installation.html","id":"xcms","chapter":"1 installation","heading":"1.7 xcms","text":"wish run GC-MS integration app comes phylochemistry, please also install XCMS running following RStudio console:","code":"\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"xcms\")"},{"path":"installation.html","id":"updating-r-and-r-packages","chapter":"1 installation","heading":"1.8 Updating R and R Packages","text":"update R:","code":"\n\ninstall.packages('devtools') #assuming it is not already installed\n\nlibrary(devtools)\n\ninstall_github('andreacirilloac/updateR')\n\nlibrary(updateR)\n\nupdateR()"},{"path":"section-2.html","id":"section-2","chapter":"","heading":"","text":"","code":""},{"path":"data-visualization.html","id":"data-visualization","chapter":"DATA VISUALIZATION","heading":"DATA VISUALIZATION","text":"","code":""},{"path":"R_Markdown.html","id":"R_Markdown","chapter":"2 ggplot and markdown","heading":"2 ggplot and markdown","text":"","code":""},{"path":"R_Markdown.html","id":"objects","chapter":"2 ggplot and markdown","heading":"2.1 Objects","text":"Ok, ’ve got installation way. Let’s get working data generating reports! R, data stored objects. can think objects “files” inside R session. phylochemistry provides variety objects us work .Let’s look create object. , can use arrow: <- . arrow take something store inside object. example:Now ’ve got new object called new_object, inside number 1. look ’s inside object, can simply type name object console:Easy! Let’s look one objects comes class code base. dimensions “algae_data” data set?","code":"\nnew_object <- 1\nnew_object\n## [1] 1\nalgae_data\n## # A tibble: 180 × 5\n##    replicate algae_strain harvesting_regime chemical_species\n##        <dbl> <chr>        <chr>             <chr>           \n##  1         1 Tsv1         Heavy             FAs             \n##  2         1 Tsv1         Heavy             saturated_Fas   \n##  3         1 Tsv1         Heavy             omega_3_polyuns…\n##  4         1 Tsv1         Heavy             monounsaturated…\n##  5         1 Tsv1         Heavy             polyunsaturated…\n##  6         1 Tsv1         Heavy             omega_6_polyuns…\n##  7         1 Tsv1         Heavy             lysine          \n##  8         1 Tsv1         Heavy             methionine      \n##  9         1 Tsv1         Heavy             essential_Aas   \n## 10         1 Tsv1         Heavy             non_essential_A…\n## # … with 170 more rows, and 1 more variable:\n## #   abundance <dbl>"},{"path":"R_Markdown.html","id":"functions","chapter":"2 ggplot and markdown","heading":"2.2 Functions","text":"Excellent - ’ve got data. Now need manipulate . need functions:function command tells R perform action!function begins ends parentheses: this_is_a_function()stuff inside parentheses details want function perform action: run_this_analysis(on_this_data)Let’s illustrate example. algae_data pretty big object. next chapter visualization, nice smaller dataset object work . Let’s use another tidyverse command called filter filter algae_data object. need tell filter command filter using “logical predicates” (things like equal : ==, less : <, greater : >, greater---equal-: <=, etc.). Let’s filter algae_data rows chemical_species equal FAs (fatty acids) preserved. look like chemical_species == \"FAs\". go:Cool! Now ’s just showing us 18 rows chemical_species fatty acids (FAs). Let’s write new, smaller dataset new object. use <-, remember?","code":"\nfilter(algae_data, chemical_species == \"FAs\")\n## # A tibble: 18 × 5\n##    replicate algae_strain harvesting_regime chemical_species\n##        <dbl> <chr>        <chr>             <chr>           \n##  1         1 Tsv1         Heavy             FAs             \n##  2         2 Tsv1         Heavy             FAs             \n##  3         3 Tsv1         Heavy             FAs             \n##  4         1 Tsv1         Light             FAs             \n##  5         2 Tsv1         Light             FAs             \n##  6         3 Tsv1         Light             FAs             \n##  7         1 Tsv2         Heavy             FAs             \n##  8         2 Tsv2         Heavy             FAs             \n##  9         3 Tsv2         Heavy             FAs             \n## 10         1 Tsv2         Light             FAs             \n## 11         2 Tsv2         Light             FAs             \n## 12         3 Tsv2         Light             FAs             \n## 13         1 Tsv11        Heavy             FAs             \n## 14         2 Tsv11        Heavy             FAs             \n## 15         3 Tsv11        Heavy             FAs             \n## 16         1 Tsv11        Light             FAs             \n## 17         2 Tsv11        Light             FAs             \n## 18         3 Tsv11        Light             FAs             \n## # … with 1 more variable: abundance <dbl>\nalgae_data_small <- filter(algae_data, chemical_species == \"FAs\")\nalgae_data_small\n## # A tibble: 18 × 5\n##    replicate algae_strain harvesting_regime chemical_species\n##        <dbl> <chr>        <chr>             <chr>           \n##  1         1 Tsv1         Heavy             FAs             \n##  2         2 Tsv1         Heavy             FAs             \n##  3         3 Tsv1         Heavy             FAs             \n##  4         1 Tsv1         Light             FAs             \n##  5         2 Tsv1         Light             FAs             \n##  6         3 Tsv1         Light             FAs             \n##  7         1 Tsv2         Heavy             FAs             \n##  8         2 Tsv2         Heavy             FAs             \n##  9         3 Tsv2         Heavy             FAs             \n## 10         1 Tsv2         Light             FAs             \n## 11         2 Tsv2         Light             FAs             \n## 12         3 Tsv2         Light             FAs             \n## 13         1 Tsv11        Heavy             FAs             \n## 14         2 Tsv11        Heavy             FAs             \n## 15         3 Tsv11        Heavy             FAs             \n## 16         1 Tsv11        Light             FAs             \n## 17         2 Tsv11        Light             FAs             \n## 18         3 Tsv11        Light             FAs             \n## # … with 1 more variable: abundance <dbl>"},{"path":"R_Markdown.html","id":"ggplot","chapter":"2 ggplot and markdown","heading":"2.3 ggplot","text":"Now nice, small table can use practice data visualization. visualization, ’re going use ggplot2 - powerful set commands plot generation.three steps setting ggplot:Define data want use.using ggplot function’s data argument. run line, just shows grey plot space. ? ’s ’ve done told ggplot () want make plot (ii) data used. haven’t explained represent features data using ink.Define variables map onto axes.called aesthetic mapping done aes() function. aes() placed inside ggplot command. Now run , get axes!Use geometric shapes represent variables data.Map variables onto geometric features shapes. define shape used, use geom_* command. options , example, geom_point(), geom_boxplot(), geom_violin(). functions added plot using + sign. can use new line keep code getting wide, just make sure + sign end fo top line. Let’s try :way mapped variables dataset plot axes, can map variables dataset geometric features shapes using represent data. , , use aes() map variables onto geometric features shapes:","code":"\nggplot(data = algae_data_small)\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance))\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) +\n  geom_point()\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) + \n  geom_point(aes(color = harvesting_regime))"},{"path":"R_Markdown.html","id":"modifying-geoms","chapter":"2 ggplot and markdown","heading":"2.3.1 modifying geoms","text":"last plot previous section, points bit small, fix ? can modify features shapes adding additional arguments geom_*() functions. change size points created geom_point() function, means need add size = argument. ’s example:One powerful aspect ggplot ability quickly change mappings see alternative plots effective bringing trends data. example, modify plot switching harvesting_regime mapped:** Important note: Inside aes() function, map aesthetics (features geom’s shape) variable. Outside aes() function, map aesthetics constants. can see two plots - first one, color inside aes() mapped variable called harvesting_regime, size outside aes() call set constant 5. second plot, situation reversed, size inside aes() function mapped variable harvesting_regime, color outside aes() call mapped constant “black.”","code":"\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) + \n  geom_point(aes(color = harvesting_regime), size = 5)\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) +\n  geom_point(aes(size = harvesting_regime), color = \"black\")"},{"path":"R_Markdown.html","id":"multiple-geoms","chapter":"2 ggplot and markdown","heading":"2.3.2 multiple geoms","text":"can also stack geoms top one another using multiple + signs. also don’t assign mappings geom.can probably guess right now, lots mappings can done, lots different ways look data!","code":"\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) + \n  geom_violin() +\n  geom_point(aes(color = harvesting_regime), size = 5)\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) +\n  geom_violin(aes(fill = algae_strain)) +\n  geom_point(aes(color = harvesting_regime, size = replicate))\nggplot(data = algae_data_small, aes(x = algae_strain, y = abundance)) +\n  geom_boxplot()"},{"path":"R_Markdown.html","id":"markdown","chapter":"2 ggplot and markdown","heading":"2.4 markdown","text":"Now able filter data make plots, ready make reports show others data processing visualization . , use R Markdown. can open new markdown document RStudio clicking: File -> New File -> R Markdown. get template document compiles press “knit.”Customize document modifying title, add author: \"your_name\" header. Delete content header, compile . get page blank except title author name.can think markdown document stand-alone R Session. means need load class code base new markdown doument create. can adding “chunk” R code. looks like :notice things compile document:Headings: compile code, “# first analysis” creates header. can create headers various levels increasing number hashtags use front header. example, “## Part 1” create subheading, “### Part 1.1” create sub-subheading, .Headings: compile code, “# first analysis” creates header. can create headers various levels increasing number hashtags use front header. example, “## Part 1” create subheading, “### Part 1.1” create sub-subheading, .Plain text: Plain text R Markdown document creates plan text entry compiled document. can use explain analyses figures, etc.Plain text: Plain text R Markdown document creates plan text entry compiled document. can use explain analyses figures, etc.can also run R chunks right markdown create figures. Dr. Busta show class.","code":""},{"path":"R_Markdown.html","id":"exercises","chapter":"2 ggplot and markdown","heading":"2.5 exercises","text":"set exercises ’re going practice filtering plotting data R Markdown. ’re going work two datasets: () algae_data (ii) alaska_lake_data. exercises, write code answers questions R Markdown report, compile pdf, submit Canvas. questions please let knowSome pointers:code goes page, don’t afraid wrap across multiple lines, shown examples.code goes page, don’t afraid wrap across multiple lines, shown examples.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.","code":""},{"path":"R_Markdown.html","id":"algae-chemistry-dataset","chapter":"2 ggplot and markdown","heading":"2.5.1 Algae Chemistry Dataset","text":"Filtering 1You algae_data stored object called algae_data soon run source(\"http://thebustalab.github.io/phylochemistry/phylochemistry.R\"). question, filter data entries shown chemical_species “FAs” (remember quotes needed around FAs !). dimensions (.e. number rows columns) resulting dataset?Filtering 2Now filter dataset entries algae_strain “Tsv1” shown. dimensions resulting dataset?Filtering 3Now filter dataset entries abundance greater 250 shown. Note > can used filter command instead ==, numbers inside filter command require quotes around . dimensions resulting dataset?PlottingMake ggplot algae_strain x axis abundance y axis. Remember aes(). Use points (geom_point()) represent compound. don’t need color points.algae strain abundant compound compounds dataset?PlottingMake ggplot abundance x axis chemical_species y axis. Use points represent compound. don’t need color points.Generally speaking, two abundant classes chemical species algae strains? (FAs/Fas stand fatty acids, AAs/Aas stand amino acids.)Filtering plottingI going show example can filter plot time. , nest filter command inside ggplot’s data argument:Using template, make plot shows just omega_3_polyunsaturated_Fas, algae_strain x axis, abundance y axis. Color points correspond harvesting_regime. Remember mapping feature shape onto variable must done inside aes(). Change plot points size = 5. Remember mapping features shape constant needs done outside aes(). harvesting regime leads higher levels omega_3_polyunsaturated_Fas?Filtering plottingUse combination filtering plotting show abundance different chemical species just algae_strain called “Tsv1.” Use x y axis, well points represent measurements. Make point size correspond replicate, color points according harvesting regime.Open-ended plottingMake plot checks see chemical_species abundant light opposed heavy harvesting_regime three replicates. Use filtered data just one algae_strain shown, x y axis, points represent measurements. Make points size = 5 also set point’s alpha = 0.6. points colored according harvesting_regime. Make 3 plots, one strain algae.peek ’s come…Take code made Question 9. Remove filtering. Add following line end plot: facet_grid(.~algae_strain). Remember adding things plots done + sign, code look something like:Also try, instead facet_grid(.~algae_strain), facet_grid(algae_strain~.) end plot command. (note swap position .~ relative algae_strain). means code look something like:advantages one extra line (.e. facet_grid) provide question 8?","code":"\nggplot(\n  data = filter(algae_data, chemical_species == \"essential_Aas\"),\n  aes(x = algae_strain, y = abundance)) +\ngeom_point()ggplot(data = algae_data, aes(x = <something>, y = <something else>)) +\n  geom_point(aes(<some things>), <some here too>) +\n  facet_grid(.~algae_strain)ggplot(data = algae_data, aes(x = <something>, y = <something else>)) +\n  geom_point(aes(<some things>), <some here too>) +\n  facet_grid(algae_strain~.)"},{"path":"R_Markdown.html","id":"alaska-lakes-dataset","chapter":"2 ggplot and markdown","heading":"2.6 Alaska Lakes Dataset","text":"Viewing DataUse R view first lines alaska_lake_data dataset. best describe, written format, kind data data set.ObjectsHow many variables Alaska lakes dataset?FilteringFilter data set meausurements free elements (.e. element_type “free”) shown. Remember, ’s ==, =. dimensions resulting dataset?PlottingMake plot shows water temperatures lake. Don’t worry get warning message R “missing values.” hottest lake? coolest?PlottingMake plot shows water temperature lake. x axis park, y axis water temp. Add geom_violin() plot first, geom_point(). Make points size = 5. Color points according water_temp. park four lakes similar temperatures?Filtering PlottingFrom plot made question 5, apparent one lake NOAT much warmer others. Filter data entries park == \"NOAT\" shown (note double equals sign quotes around NOAT…). Combine filtering plotting use geom_point() make plot shows specific lake .Filtering PlottingMake plot shows lake highest abundance sulfur.Open-ended PlottingMake plot uses geom_point(). Set “shape” aesthetic points 21, .e. geom_point(aes(...), shape = 21). gives access new aesthetics: fill. also changes behaviour color aesthetic slightly, now controls border color, internal color. example (though doesn’t make nice plot):Now lots aesthetics can map : x, y, size, color, fill (leave shape set 21 now). Make plot design. include filtering, aesthetics listed , though whether map variable constant .done plot, take screen shot . Go GOOGLE SHEET, make slide (don’t include name), paste screen shot . Add small caption explains variables mapped.\n","code":"\nggplot(\n  data = filter(alaska_lake_data, lake == \"Lake_Narvakrak\"),\n  aes(x = lake, y = mg_per_L)\n) +\n  geom_point(\n    shape = 21, size = 10,\n    color = \"black\", fill = \"green\"\n  )"},{"path":"data-visualization-1.html","id":"data-visualization-1","chapter":"data visualization","heading":"data visualization","text":"Stuff deseption graphics, tufte, etc.","code":""},{"path":"geoms_facets_scales_themes.html","id":"geoms_facets_scales_themes","chapter":"3 geoms, facets, scales, themes","heading":"3 geoms, facets, scales, themes","text":"’ve looked filter data map variables data geometric shapes make plots. Let’s look things. examples, ’re going use data set called solvents.","code":""},{"path":"geoms_facets_scales_themes.html","id":"geoms","chapter":"3 geoms, facets, scales, themes","heading":"3.1 geoms","text":"’d like introduce two new geoms. first geom_smooth() used two continuous variables. particularly nice geom_point() stacked top .Also, please aware geom_tile(), nice situations two discrete variables one continuous variable. geom_tile() makes often referred heat maps. Note geom_tile() somewhat similar geom_point(shape = 21), fill color aesthetics control fill color border color, respectively.examples illustrate , degree, correspondence type data interested plotting (number discrete continuous variables) types geoms can effectively used represent data.handy cheat sheet can help identify right geom situation. Please keep cheat sheet mind future plotting needs…","code":"\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth() +\n  geom_point()\n## `geom_smooth()` using method = 'loess' and formula 'y ~ x'\nggplot(\n  data = filter(algae_data, harvesting_regime == \"Heavy\"),\n  aes(x = algae_strain, y = chemical_species)\n) + \n  geom_tile(aes(fill = abundance), color = \"black\", size = 1)"},{"path":"geoms_facets_scales_themes.html","id":"facets","chapter":"3 geoms, facets, scales, themes","heading":"3.2 facets","text":"alluded Exercises 1, possible map variables dataset geometric features shapes (.e. geoms). One common way facets. Faceting creates small multiples plot, shows different subset data based categorical variable choice. Let’s check ., can facet horizontal direction:can facet vertical direction:can time:Faceting great way describe variation plot without make geoms complicated. situations need generate lots lots facets, consider facet_wrap instead facet_grid.","code":"\nggplot(data = algae_data, aes(x = algae_strain, y = chemical_species)) + \n  geom_tile(aes(fill = abundance), color = \"black\") + \n  facet_grid(.~replicate)\nggplot(data = algae_data, aes(x = algae_strain, y = chemical_species)) + \n  geom_tile(aes(fill = abundance), color = \"black\") + \n  facet_grid(replicate~.)\nggplot(data = algae_data, aes(x = algae_strain, y = chemical_species)) + \n  geom_tile(aes(fill = abundance), color = \"black\") + \n  facet_grid(harvesting_regime~replicate)"},{"path":"geoms_facets_scales_themes.html","id":"scales","chapter":"3 geoms, facets, scales, themes","heading":"3.3 scales","text":"Every time define aesthetic mapping (e.g. aes(x = algae_strain)), defining new scale added plot. can control scales using scale_* family commands. Consider faceting example . , use geom_tile(aes(fill = abundance)) map abundance variable fill aesthetic tiles. creates scale called fill can adjust using scale_fill_*. case, fill mapped continuous variable fill scale color gradient. Therefore, scale_fill_gradient() command need change . Remember always type ?scale_fill_ console help find relevant help topics provide detail. Another option google: “modify color scale ggplot geom_tile,” undoubtedly turn wealth help.","code":"\nggplot(data = algae_data, aes(x = algae_strain, y = chemical_species)) + \n  geom_tile(aes(fill = abundance), color = \"black\") + \n  facet_grid(harvesting_regime~replicate) +\n  scale_fill_gradient(low = \"white\", high = \"black\") +\n  theme_classic()"},{"path":"geoms_facets_scales_themes.html","id":"rcolorbrewer","chapter":"3 geoms, facets, scales, themes","heading":"3.3.1 RColorBrewer","text":"One particularly useful type scale provided RColorBrewer:","code":"\ndisplay.brewer.all()\nggplot(mtcars) +\n  geom_point(\n    aes(x = mpg, y = factor(cyl), fill = factor(carb)), \n    shape = 21, size = 6\n  ) +\n  scale_fill_brewer(palette = \"Set1\")"},{"path":"geoms_facets_scales_themes.html","id":"themes","chapter":"3 geoms, facets, scales, themes","heading":"3.4 themes","text":"far ’ve just looked control means data represented plot. also components plot , strictly speaking, data per se, rather non-data ink. controlled using theme() family commands. two ways go .","code":""},{"path":"geoms_facets_scales_themes.html","id":"complete-themes","chapter":"3 geoms, facets, scales, themes","heading":"3.4.1 Complete themes","text":"ggplot comes handful built “complete themes.” change appearance plots respect non-data ink. Compare following plots:","code":"\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth() +\n  geom_point() +\n  theme_classic()\n## `geom_smooth()` using method = 'loess' and formula 'y ~ x'\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth() +\n  geom_point() +\n  theme_dark()\n## `geom_smooth()` using method = 'loess' and formula 'y ~ x'\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth() +\n  geom_point() +\n  theme_void()\n## `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"geoms_facets_scales_themes.html","id":"theme-components","chapter":"3 geoms, facets, scales, themes","heading":"3.4.2 Theme components","text":"can also change individual components themes. can bit tricky, ’s explained run ?theme(). Hare example (google provide many, many ).Last, example combining scale_* theme* previous commands really get plot looking sharp.","code":"\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth() +\n  geom_point() +\n  theme(\n    text = element_text(size = 20, color = \"black\")\n  )\n## `geom_smooth()` using method = 'loess' and formula 'y ~ x'\nggplot(data = solvents, aes(x = boiling_point, y = vapor_pressure)) + \n  geom_smooth(color = \"#4daf4a\") +\n  scale_x_continuous(\n    name = \"Boiling Point\", breaks = seq(0,200,25), limits = c(30,210)\n  ) +\n  scale_y_continuous(\n    name = \"Vapor Pressure\", breaks = seq(0,600,50)\n  ) +\n  geom_point(color = \"#377eb8\", size = 4, alpha = 0.6) +\n  theme_bw() +\n  theme(\n    axis.text = element_text(color = \"black\"),\n    text = element_text(size = 20, color = \"black\")\n  )\n## `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"geoms_facets_scales_themes.html","id":"exercises-1","chapter":"3 geoms, facets, scales, themes","heading":"3.5 exercises","text":"set exercises ’re going practice making plots using dataset solvents. Since now familiar filtering plotting data, prompts assignment going relatively open ended - care variables map x, y, fill, color, etc. Rather, expect submission demonstrate explored new topics covered previous chapter. includes geoms beyond geom_point() geom_violin(), facets, scale modifications, theme adjustments. creative! Explore solvents dataset. Find something interesting! Show mastered material. Don’t forget ggplot cheat sheet (see “Links” section book)., exercises, write code answers questions Script Editor window RStudio R Markdown document. compile file pdf submit Canvas. questions please let know.pointers:code goes page, don’t afraid wrap across multiple lines, shown examples previous set exercises.code goes page, don’t afraid wrap across multiple lines, shown examples previous set exercises.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.Create two plots identical except one uses scales = \"free\" feature facet_grid (.e. one use facet_grid(<things>), whiel uses facet_grid(<things>, scales = \"free\")). Write single caption describes plots, highlighting advantages provided plot . additional tips writing captions, please see “Writing” chapter book.Create two plots identical except one uses scales = \"free\" feature facet_grid (.e. one use facet_grid(<things>), whiel uses facet_grid(<things>, scales = \"free\")). Write single caption describes plots, highlighting advantages provided plot . additional tips writing captions, please see “Writing” chapter book.Create two plots identical except one uses geom_point(), uses geom_jitter(). Write single caption describes plots. caption highlight differences bewteen two plots describe case(s) think appropriate use geom_jitter() geom_point().Create two plots identical except one uses geom_point(), uses geom_jitter(). Write single caption describes plots. caption highlight differences bewteen two plots describe case(s) think appropriate use geom_jitter() geom_point().Make plot four aesthetic mappings (x y mappings count). Use scales_* family commands modify aspect scale create four mappings. Hint: scales somewhat tricky modify (alpha, linetype, …), scales easier modify (x, y, color, fill, shape).Make plot four aesthetic mappings (x y mappings count). Use scales_* family commands modify aspect scale create four mappings. Hint: scales somewhat tricky modify (alpha, linetype, …), scales easier modify (x, y, color, fill, shape).Make plot manually modify least three aspects theme (.e. use one build complete themes theme_classic(), rather, manually modify components theme using theme()). means inside theme() command, three arguments separated commas.Make plot manually modify least three aspects theme (.e. use one build complete themes theme_classic(), rather, manually modify components theme using theme()). means inside theme() command, three arguments separated commas.Identify relationship two variables dataset. Create plot optimized (see note) highlight features relationship. Write short caption describes plot trend ’ve identified highlighted. Note: realize word “optimize” clearly defined . ’s ok! judge optimized . Use caption make case plot optimized. Defend ideas argument!Identify relationship two variables dataset. Create plot optimized (see note) highlight features relationship. Write short caption describes plot trend ’ve identified highlighted. Note: realize word “optimize” clearly defined . ’s ok! judge optimized . Use caption make case plot optimized. Defend ideas argument!","code":""},{"path":"import-and-tidying.html","id":"import-and-tidying","chapter":"4 import and tidying","heading":"4 import and tidying","text":"","code":""},{"path":"import-and-tidying.html","id":"data-import","chapter":"4 import and tidying","heading":"4.1 data import","text":"analyze data stored computer can indeed import RStudio.easiest way use interactive command readCSV(), function comes phylochemistry source command. run readCSV() console, navigate data hard drive.Another option read data path. , need know “path” data file. essentially street address data computer’s hard drive. Paths look different Mac PC.Mac: /Users/lucasbusta/Documents/sample_data_set.csv (note forward slashes!)PC: C:\\\\Computer\\\\Documents\\\\sample_data_set.csv (note double backward slashes!)can quickly find paths files via following:Mac: Locate file Finder. Right-click file, hold Option key, click “Copy  Pathname”PC: Locate file Windows Explorer. Hold Shift key right-click file. Click “Copy Path”paths, can read data using read_csv command. ’ll run read_csv(\"<path_to_your_data>\"). Note use QUOTES \"\"! necessary. Also make sure path uses appropriate direction slashes operating system.","code":""},{"path":"import-and-tidying.html","id":"tidy-data","chapter":"4 import and tidying","heading":"4.2 tidy data","text":"https://tidydatatutor.com/vis.htmlWhen make data tables hand, ’s often easy make wide-style table like following. , abundances 7 different fatty acids 10 different species tabulated. fatty acid gets row, species, column.format nice filling hand (lab notebook similar), groove ggplot tidyverse functions well. need convert long-style table. done using pivot_longer(). can think function transforming data’s column names (column names) data matrix’s values (case, measurements) variables (.e. columns). can fatty acid dataset using command . , specify data want transform (data = fadb_sample), need tell columns want transform (cols = 2:11), want new variable contains column names called (names_to = \"plant_species\") want new variable contains matrix values called (values_to = \"relative_abundance\"). together now:Brilliant! Now tidy, long-style table can used ggplot.","code":"\nfadb_sample\n## # A tibble: 7 × 11\n##   fatty_acid         Agonandra_brasiliensis Agonandra_silva…\n##   <chr>                               <dbl>            <dbl>\n## 1 Hexadecanoic acid                     3.4              1  \n## 2 Octadecanoic acid                     6.2              0.1\n## 3 Eicosanoic acid                       4.7              3.5\n## 4 Docosanoic acid                      77.4              0.4\n## 5 Tetracosanoic acid                    1.4              1  \n## 6 Hexacosanoic acid                     1.9             12.6\n## 7 Octacosanoic acid                     5               81.4\n## # … with 8 more variables: Agonandra_excelsa <dbl>,\n## #   Heisteria_silvianii <dbl>, Malania_oleifera <dbl>,\n## #   Ximenia_americana <dbl>, Ongokea_gore <dbl>,\n## #   Comandra_pallida <dbl>, Buckleya_distichophylla <dbl>,\n## #   Nuytsia_floribunda <dbl>\npivot_longer(data = fadb_sample, cols = 2:11, names_to = \"plant_species\", values_to = \"relative_abundance\")\n## # A tibble: 70 × 3\n##    fatty_acid        plant_species           relative_abunda…\n##    <chr>             <chr>                              <dbl>\n##  1 Hexadecanoic acid Agonandra_brasiliensis               3.4\n##  2 Hexadecanoic acid Agonandra_silvatica                  1  \n##  3 Hexadecanoic acid Agonandra_excelsa                    1.2\n##  4 Hexadecanoic acid Heisteria_silvianii                  2.9\n##  5 Hexadecanoic acid Malania_oleifera                     0.7\n##  6 Hexadecanoic acid Ximenia_americana                    3.3\n##  7 Hexadecanoic acid Ongokea_gore                         1  \n##  8 Hexadecanoic acid Comandra_pallida                     2.3\n##  9 Hexadecanoic acid Buckleya_distichophylla              1.6\n## 10 Hexadecanoic acid Nuytsia_floribunda                   3.8\n## # … with 60 more rows"},{"path":"summary_statistics.html","id":"summary_statistics","chapter":"5 the pipe and summaries","heading":"5 the pipe and summaries","text":"","code":""},{"path":"summary_statistics.html","id":"the-pipe","chapter":"5 the pipe and summaries","heading":"5.1 the pipe (%>%)","text":"seen create new objects using <-, filtering plotting data using, example:However, analyses get complex, code can get long hard read. ’re going use pipe %>% help us . Check :Neat! Another way think pipe:pipe become important analyses become sophisticated, happens quickly start working summary statistics, shall now see…","code":"\nggplot(filter(alaska_lake_data, park == \"BELA\"), aes(x = pH, y = lake)) + geom_col()\nalaska_lake_data %>%\n  filter(park == \"BELA\") %>%\n  ggplot(aes(x = pH, y = lake)) + geom_col()"},{"path":"summary_statistics.html","id":"summary-statistics","chapter":"5 the pipe and summaries","heading":"5.2 summary statistics","text":"far, plotting raw data. well good, always suitable. Often scientific questions answered looking raw data alone, sometimes much raw data plot. , need summary statistics - things like averages, standard deviations, . metrics can computed Excel, programming can time consuming, especially group statistics. Consider example , uses ny_trees dataset. NY Trees dataset contains information nearly half million trees New York City (considerable filtering simplification):300,000 observations 14 variables! ’s 4.2M data points! Now, average standard deviation height diameter tree species within NY borough? values change trees parks versus sidewalk pits?? don’t even know one begin approach questions using traditional spreadsheets. , answer questions ease using two new commands: group_by() summarize(). Let’s get .Say want know (course, visualize) mean standard deviation heights tree species NYC. can see data first columns NY trees dataset , calculate statistics? R, mean can computed mean() standard deviation can calculated sd(). use function summarize() calculate summary statistics. , can calculate average standard deviation trees data set follows:Great! species? need subdivide data species, compute mean standard deviation, recombine results new table. First, use group_by(). Note ny_trees, species indicated column called spc_latin. data grouped, can use summarize() compute statistics.Bam. Mean height tree species. summarize() powerful though, can many summary statistics :Now can use data plotting. , use new geom, geom_pointrange, takes x y aesthetics, usual, also requires two additional y-ish aesthetics ymin ymax (xmin xmax want vary along x). Also, note aesthetic mappings xmin xmax, can use mathematical expression: mean-stdev mean+stdev, respectivey. case, mean_height - stdev_height mean_height + stdev_height. Let’s see action:Cool! Just like , ’ve found (visualized) average standard deviation tree heights, species, NYC. doesn’t stop . can use group_by() summarize() multiple variables (.e. groups). can examine properties tree species NYC borough. Let’s check :Now summary statistics tree species within borough. different previous plot now additional variable (boroname) summarized dataset. additional variable needs encoded plot. Let’s map boroname x facet tree species, used x. ’ll also manually modify theme element strip.text.y get species names readable position.Excellent! really want go something pretty:Now getting somewhere. looks like really big maple trees (Acer) Queens.","code":"\nny_trees\n## # A tibble: 378,762 × 14\n##    tree_height tree_diameter address      tree_loc pit_type \n##          <dbl>         <dbl> <chr>        <chr>    <chr>    \n##  1        21.1             6 1139 57 STR… Front    Sidewalk…\n##  2        59.0             6 2220 BERGEN… Across   Sidewalk…\n##  3        92.4            13 2254 BERGEN… Across   Sidewalk…\n##  4        50.2            15 2332 BERGEN… Across   Sidewalk…\n##  5        95.0            21 2361 EAST  … Front    Sidewalk…\n##  6        67.5            19 2409 EAST  … Front    Continuo…\n##  7        75.3            11 1481 EAST  … Front    Lawn     \n##  8        27.9             7 1129 57 STR… Front    Sidewalk…\n##  9       111.             26 2076 EAST  … Across   Sidewalk…\n## 10        83.9            20 2025 EAST  … Front    Sidewalk…\n## # … with 378,752 more rows, and 9 more variables:\n## #   soil_lvl <chr>, status <chr>, spc_latin <chr>,\n## #   spc_common <chr>, trunk_dmg <chr>, zipcode <dbl>,\n## #   boroname <chr>, latitude <dbl>, longitude <dbl>\nny_trees %>%\n  summarize(mean_height = mean(tree_height))\n## # A tibble: 1 × 1\n##   mean_height\n##         <dbl>\n## 1        72.6\n\nny_trees %>%\n  summarize(stdev_height = sd(tree_height))\n## # A tibble: 1 × 1\n##   stdev_height\n##          <dbl>\n## 1         28.7\nny_trees %>%\n  group_by(spc_latin) %>%\n  summarize(mean_height = mean(tree_height))\n## # A tibble: 12 × 2\n##    spc_latin              mean_height\n##    <chr>                        <dbl>\n##  1 ACER PLATANOIDES              82.6\n##  2 ACER RUBRUM                  106. \n##  3 ACER SACCHARINUM              65.6\n##  4 FRAXINUS PENNSYLVANICA        60.6\n##  5 GINKGO BILOBA                 90.4\n##  6 GLEDITSIA TRIACANTHOS         53.0\n##  7 PLATANUS ACERIFOLIA           82.0\n##  8 PYRUS CALLERYANA              21.0\n##  9 QUERCUS PALUSTRIS             65.5\n## 10 QUERCUS RUBRA                111. \n## 11 TILIA CORDATA                 98.8\n## 12 ZELKOVA SERRATA              101.\nny_trees %>%\n  group_by(spc_latin) %>%\n  summarize(\n    mean_height = mean(tree_height),\n    stdev_height = sd(tree_height)\n  ) -> ny_trees_by_spc_summ\nny_trees_by_spc_summ\n## # A tibble: 12 × 3\n##    spc_latin              mean_height stdev_height\n##    <chr>                        <dbl>        <dbl>\n##  1 ACER PLATANOIDES              82.6        17.6 \n##  2 ACER RUBRUM                  106.         15.7 \n##  3 ACER SACCHARINUM              65.6        16.6 \n##  4 FRAXINUS PENNSYLVANICA        60.6        21.3 \n##  5 GINKGO BILOBA                 90.4        24.5 \n##  6 GLEDITSIA TRIACANTHOS         53.0        13.0 \n##  7 PLATANUS ACERIFOLIA           82.0        16.0 \n##  8 PYRUS CALLERYANA              21.0         5.00\n##  9 QUERCUS PALUSTRIS             65.5         6.48\n## 10 QUERCUS RUBRA                111.         20.7 \n## 11 TILIA CORDATA                 98.8        32.6 \n## 12 ZELKOVA SERRATA              101.         10.7\nny_trees_by_spc_summ %>%\nggplot() +\n  geom_pointrange(\n      aes(\n        y = spc_latin,\n        x = mean_height,\n        xmin = mean_height - stdev_height,\n        xmax = mean_height + stdev_height\n      )\n    )\nny_trees %>%\n  group_by(spc_latin, boroname) %>%\n  summarize(\n    mean_diam = mean(tree_diameter),\n    stdev_diam = sd(tree_diameter)\n  ) -> ny_trees_by_spc_boro_summ\n## `summarise()` has grouped output by 'spc_latin'. You can override using the `.groups` argument.\nny_trees_by_spc_boro_summ\n## # A tibble: 48 × 4\n## # Groups:   spc_latin [12]\n##    spc_latin        boroname  mean_diam stdev_diam\n##    <chr>            <chr>         <dbl>      <dbl>\n##  1 ACER PLATANOIDES Bronx         13.9        6.74\n##  2 ACER PLATANOIDES Brooklyn      15.4       14.9 \n##  3 ACER PLATANOIDES Manhattan     11.6        8.45\n##  4 ACER PLATANOIDES Queens        15.1       12.9 \n##  5 ACER RUBRUM      Bronx         11.4        7.88\n##  6 ACER RUBRUM      Brooklyn      10.5        7.41\n##  7 ACER RUBRUM      Manhattan      6.63       4.23\n##  8 ACER RUBRUM      Queens        14.1        8.36\n##  9 ACER SACCHARINUM Bronx         19.7       10.5 \n## 10 ACER SACCHARINUM Brooklyn      22.2       10.1 \n## # … with 38 more rows\nny_trees_by_spc_boro_summ %>%\nggplot() +\n  geom_pointrange(\n    aes(\n      y = boroname,\n      x = mean_diam,\n      xmin = mean_diam-stdev_diam,\n      xmax = mean_diam+stdev_diam\n    )\n  ) +\n  facet_grid(spc_latin~.) +\n  theme(\n    strip.text.y = element_text(angle = 0)\n  )\nny_trees_by_spc_boro_summ %>%\nggplot() +\n  geom_pointrange(\n    aes(\n      y = boroname,\n      x = mean_diam,\n      xmin = mean_diam-stdev_diam,\n      xmax = mean_diam+stdev_diam,\n      fill = spc_latin\n    ), color = \"black\", shape = 21\n  ) +\n  labs(\n    y = \"Borough\", \n    x = \"Trunk diameter\",\n    caption = str_wrap(\"Figure 1: Diameters of trees in New York City. Points correspond to average diameters of each tree species in each borough. Horizontal lines indicate the standard deviation of tree diameters. Points are colored according to tree species.\", width = 80)\n  ) +\n  facet_grid(spc_latin~.) +\n  guides(fill = \"none\") +\n  scale_fill_brewer(palette = \"Paired\") +\n  theme_bw() +\n  theme(\n    strip.text.y = element_text(angle = 0),\n    plot.caption = element_text(hjust = 0.5)\n  )"},{"path":"summary_statistics.html","id":"exercises-2","chapter":"5 the pipe and summaries","heading":"5.3 exercises","text":"Isn’t seven powerfully magical number? Isn’t seven powerfully magical number? Yes… think idea seven-part assignment greatly appeal alchemist.set exercises going use periodic table. run source() can load dataset using periodic_table. Please use dataset run analyses answer following quetions/prompts. Compile answers R Markdown document, compile pdf, upload Canvas assignment. Please let know questions. Good luck, fun!pointers:code goes page, don’t afraid wrap across multiple lines, shown examples previous set exercises.code goes page, don’t afraid wrap across multiple lines, shown examples previous set exercises.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.Don’t afraid put variable long elements / long text y-axis continuous variable x-axis.Make plot using geom_point() shows average atomic weight elements discovered year spanned dataset (.e. average weight elements discovered 1900? 1901? 1902? etc.). see trend, particularly 1950. think caused trend?Make plot using geom_point() shows average atomic weight elements discovered year spanned dataset (.e. average weight elements discovered 1900? 1901? 1902? etc.). see trend, particularly 1950. think caused trend?column state_at_RT indicates state element room temperate. Make plot shows average first ionization potential elements belonging state group indicated state_at_RT (.e. average 1st ionization potential elements solid room temp? liquid? etc.). highest?column state_at_RT indicates state element room temperate. Make plot shows average first ionization potential elements belonging state group indicated state_at_RT (.e. average 1st ionization potential elements solid room temp? liquid? etc.). highest?Filter dataset elements atomic number less 85 included. Considering elements, average standard deviation boiling points type crystal_structure? Make plot using geom_pointrange() shows mean standard deviation groups. ’s elements cubic crystal structure?Filter dataset elements atomic number less 85 included. Considering elements, average standard deviation boiling points type crystal_structure? Make plot using geom_pointrange() shows mean standard deviation groups. ’s elements cubic crystal structure?Now filter original dataset elements atomic number less 37 considered. elements dataset belong first four periods. average abundance four periods seawater? .e. average abundance elements period 1? period 2? etc. period abundant? context “CHON” mean? (rock band, though also excellent, especially song features GoYama)Now filter original dataset elements atomic number less 37 considered. elements dataset belong first four periods. average abundance four periods seawater? .e. average abundance elements period 1? period 2? etc. period abundant? context “CHON” mean? (rock band, though also excellent, especially song features GoYama)Now filter original dataset elements atomic number less 103 considered. Filter elements group number 18 excluded. Using twice-filtered dataset, compute average, minimum, maximum values electronegativiy group_number. Use geom_point() geom_errorbar() illustrate average, minimum, maximum values group number.Now filter original dataset elements atomic number less 103 considered. Filter elements group number 18 excluded. Using twice-filtered dataset, compute average, minimum, maximum values electronegativiy group_number. Use geom_point() geom_errorbar() illustrate average, minimum, maximum values group number.Filter dataset elements atomic number less 85 considered. Group color. Now filter color == \"colorless\". remaining elements, widest range specific heats? Use geom_point() geom_errorbar() illustrate mean standard deviation color’s specific heats.Filter dataset elements atomic number less 85 considered. Group color. Now filter color == \"colorless\". remaining elements, widest range specific heats? Use geom_point() geom_errorbar() illustrate mean standard deviation color’s specific heats.learned many things course far. filter(), ggplot(), now group_by() summarize(). Using commands, create graphic illustrate consider interesting periodic trend. Use theme elements scales enhance plot: impress !\nlearned many things course far. filter(), ggplot(), now group_by() summarize(). Using commands, create graphic illustrate consider interesting periodic trend. Use theme elements scales enhance plot: impress !\n","code":""},{"path":"chemometrics.html","id":"chemometrics","chapter":"chemometrics","heading":"chemometrics","text":"","code":""},{"path":"clustering.html","id":"clustering","chapter":"6 clustering","heading":"6 clustering","text":"","code":""},{"path":"clustering.html","id":"theory","chapter":"6 clustering","heading":"6.1 theory","text":"“samples closely related?”far looking plot raw data, well data summarize across samples. important stuff useful. However, often questions samples datasets relate one another. example: Alaska lakes dataset, lake similar, chemically speaking, Lake Narvakrak? Answering requires calculating numeric distances samples based chemical properties. , questions, need use matrix analyses. , use runMatrixAnalysis(), function loaded R Session run source() command.Matrix analyses can bit difficult set . two things can help us : () use template runMatrixAnalysis() (see ) (ii) critical think data terms samples analytes. Let’s consider Alaska lakes data set:can see dataset comprised measurements various analytes (.e. several chemical elements, well water_temp, pH), different samples (.e. lakes). need tell runMatrixAnalysis() function column relates samples analytes structure. See image explanation.mind, let’s try template:works! Now can plot cluster diagram ggplot add-called ggtree. ’ve seen ggplot takes “data” argument (.e. ggplot(data = <some_data>) + geom_*() etc.). contrast, ggtree takes argument called tr, though ’re using runMatrixAnalysis() function, can treat two (data tr) , , use: ggtree(tr = <output_from_runMatrixAnalysis>) + geom_*() etc.Note ggtree also comes several great new geoms: geom_tiplab() geom_tippoint(). Let’s try :Cool! Though plot use tweaking… let’s try:nice!","code":"\nalaska_lake_data\n## # A tibble: 220 × 7\n##    lake                park  water_temp    pH element mg_per_L\n##    <chr>               <chr>      <dbl> <dbl> <chr>      <dbl>\n##  1 Devil_Mountain_Lake BELA        6.46  7.69 C          3.4  \n##  2 Devil_Mountain_Lake BELA        6.46  7.69 N          0.028\n##  3 Devil_Mountain_Lake BELA        6.46  7.69 P          0    \n##  4 Devil_Mountain_Lake BELA        6.46  7.69 Cl        10.4  \n##  5 Devil_Mountain_Lake BELA        6.46  7.69 S          0.62 \n##  6 Devil_Mountain_Lake BELA        6.46  7.69 F          0.04 \n##  7 Devil_Mountain_Lake BELA        6.46  7.69 Br         0.02 \n##  8 Devil_Mountain_Lake BELA        6.46  7.69 Na         8.92 \n##  9 Devil_Mountain_Lake BELA        6.46  7.69 K          1.2  \n## 10 Devil_Mountain_Lake BELA        6.46  7.69 Ca         5.73 \n## # … with 210 more rows, and 1 more variable:\n## #   element_type <chr>\nAK_lakes_clustered <- runMatrixAnalysis(\n                                \n    data = alaska_lake_data,\n\n    analysis = \"hclust\",\n\n    column_w_names_of_multiple_analytes = \"element\",\n    column_w_values_for_multiple_analytes = \"mg_per_L\",\n    \n    columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n    \n    columns_w_additional_analyte_info = \"element_type\",\n\n    columns_w_sample_ID_info = c(\"lake\", \"park\")\n\n)\nAK_lakes_clustered\n## # A tibble: 39 × 25\n##    sample_unique_ID  lake   park  parent  node branch.length\n##    <chr>             <chr>  <chr>  <int> <int>         <dbl>\n##  1 Devil_Mountain_L… Devil… BELA      33     1          7.25\n##  2 Imuruk_Lake_BELA  Imuru… BELA      32     2          4.91\n##  3 Kuzitrin_Lake_BE… Kuzit… BELA      36     3          3.27\n##  4 Lava_Lake_BELA    Lava_… BELA      35     4          3.02\n##  5 North_Killeak_La… North… BELA      21     5        204.  \n##  6 White_Fish_Lake_… White… BELA      22     6         65.2 \n##  7 Iniakuk_Lake_GAAR Iniak… GAAR      29     7          3.60\n##  8 Kurupa_Lake_GAAR  Kurup… GAAR      31     8          8.57\n##  9 Lake_Matcharak_G… Lake_… GAAR      29     9          3.60\n## 10 Lake_Selby_GAAR   Lake_… GAAR      30    10          5.24\n## # … with 29 more rows, and 19 more variables: label <chr>,\n## #   isTip <lgl>, x <dbl>, y <dbl>, branch <dbl>,\n## #   angle <dbl>, water_temp <dbl>, pH <dbl>, C <dbl>,\n## #   N <dbl>, P <dbl>, Cl <dbl>, S <dbl>, F <dbl>, Br <dbl>,\n## #   Na <dbl>, K <dbl>, Ca <dbl>, Mg <dbl>\nlibrary(ggtree)\nAK_lakes_clustered %>%\nggtree() +\n  geom_tiplab() +\n  geom_tippoint() +\n  theme_classic()\nAK_lakes_clustered %>%\nggtree() +\n    geom_tiplab(aes(label = lake), offset = 10) +\n    geom_tippoint(shape = 21, aes(fill = park), size = 4) +\n    scale_x_continuous(limits = c(0,400))"},{"path":"clustering.html","id":"exercises-3","chapter":"6 clustering","heading":"6.2 exercises","text":"set exercises, please use runMatrixAnalysis() run visualize hierarchical cluster analysis main datasets worked far, except NY_trees. means: algae_data (algae strains similar ?), alaska_lake_data (lakes similar ?). solvents (solvents similar ?). also means use periodic table (elements similar ?), though please don’t use whole periodic table, rather, use periodic_table_subset. , create () tree diagram shows “samples” data set related based numerical data associated , (ii) caption diagram, (iii) describe, two sentences, interesting trend see diagram. can ignore columns contain categorical data, can list columns “additional_analyte_info.”assignment, may find colnames() function square bracket-subsetting useful. list subset column names dataset . example:","code":"\ncolnames(solvents)\n##  [1] \"solvent\"             \"formula\"            \n##  [3] \"boiling_point\"       \"melting_point\"      \n##  [5] \"density\"             \"miscible_with_water\"\n##  [7] \"solubility_in_water\" \"relative_polarity\"  \n##  [9] \"vapor_pressure\"      \"CAS_number\"         \n## [11] \"formula_weight\"      \"refractive_index\"   \n## [13] \"specific_gravity\"    \"category\"\n\ncolnames(solvents)[1:3]\n## [1] \"solvent\"       \"formula\"       \"boiling_point\"\n\ncolnames(solvents)[c(1,5,7)]\n## [1] \"solvent\"             \"density\"            \n## [3] \"solubility_in_water\""},{"path":"PCA.html","id":"PCA","chapter":"7 pca","heading":"7 pca","text":"“analytes driving differences among samples?”addition heirarchical clustering, another way look data cluster context - .e. another way identify clusters samples similar properties based analytes data set. method called k-means, look later, first need look dimensionality reduction techniques, particularly principal components analysis (PCA).explain pca drawing new set axes\npca also answers questions whether variables related\nhclust “closely related ?” PCA clustering","code":""},{"path":"PCA.html","id":"pca","chapter":"7 pca","heading":"7.1 pca","text":"PCA looks variance high dimensional data set chooses new axes within data set align directions containing highest variance. new axes called principal components. Let’s look example:example , three dimensional space can reduced two dimensional space principal components analysis. New axes (principal components) selected (bold arrows left) become x y axes principal components space (right).can run visualize principal components analyses using runMatrixAnalysis() function example :Great! plot can see White Fish Lake North Killeak Lake, BELA park, quite different parks (separated others along dimension 1, .e. first principal component). time, Wild Lake, Iniakuk Lake, Walker Lake, several lakes GAAR park different others (separated others along dimension 2, .e. second principal component).Important question: makes lakes listed different others? Certainly aspect chemistry, since ’s data analysis built upon, determine analyte(s) driving differences among lakes see PCA plot?","code":"\nAK_lakes_pca <- runMatrixAnalysis(\n  data = alaska_lake_data,\n  analysis = c(\"pca\"),\n  column_w_names_of_multiple_analytes = \"element\",\n  column_w_values_for_multiple_analytes = \"mg_per_L\",\n  columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n  columns_w_additional_analyte_info = \"element_type\",\n  columns_w_sample_ID_info = c(\"lake\", \"park\")\n)\n\nggplot(data = AK_lakes_pca, aes(x = Dim.1, y = Dim.2)) +\n  geom_point(aes(fill = park), shape = 21, size = 4, alpha = 0.8) +\n  geom_label_repel(aes(label = lake), alpha = 0.5) +\n  theme_classic()"},{"path":"PCA.html","id":"ordination-plots","chapter":"7 pca","heading":"7.2 ordination plots","text":"Let’s look access information analytes major contributors principal component. important tell analytes associated particular dimensions, extension, analytes associated (markers ) particular groups PCA plot. can determined using ordination plot. Let’s look example. can obtain ordination plot information using runMatrixAnalysis() analysis = \"pca_ord\":can now visualize ordination plot using standard ggplot plotting techniques. Note use geom_label_repel() filter() label certain segments ordination plot. need use geom_label_repel(), use built geom_label(), geom_label_repel() can make labelling segments easier.Great! read ordination plot:considering one analyte’s vector: vector’s projected value axis shows much variance aligned principal component.considering one analyte’s vector: vector’s projected value axis shows much variance aligned principal component.considering two analyte vectors: angle two vectors indicates correlated two variables . point direction, highly correlated. meet 90 degrees, correlated. meet ~180 degrees, negatively correlated. say one analyte “1.9” respect dimension 2 another “-1.9” respect dimension 2. Let’s also say vectors ~“0” respect dimension 1.considering two analyte vectors: angle two vectors indicates correlated two variables . point direction, highly correlated. meet 90 degrees, correlated. meet ~180 degrees, negatively correlated. say one analyte “1.9” respect dimension 2 another “-1.9” respect dimension 2. Let’s also say vectors ~“0” respect dimension 1.ordination plot , can now see abundances K, Cl, Br, Na major contributors variance first principal component (first dimension). abundances elements make White Fish Lake North Killeak Lake different lakes. can also see abundances N, S, Ca major contributors variance teh second dimension, whic means elements ar set Wild Lake, Iniakuk Lake, Walker Lake, several lakes GAAR park apart rest lakes data set.","code":"## # A tibble: 6 × 3\n##   analyte      Dim.1   Dim.2\n##   <chr>        <dbl>   <dbl>\n## 1 water_temp 0.0769  -0.267 \n## 2 pH         0.704    0.0190\n## 3 C          0.297   -0.248 \n## 4 N          0.00446  0.732 \n## 5 P          0.485   -0.0817\n## 6 Cl         0.978    0.0152\nAK_lakes_pca_ord <- runMatrixAnalysis(\n  data = alaska_lake_data,\n  analysis = c(\"pca_ord\"),\n  column_w_names_of_multiple_analytes = \"element\",\n  column_w_values_for_multiple_analytes = \"mg_per_L\",\n  columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n  columns_w_additional_analyte_info = \"element_type\",\n  columns_w_sample_ID_info = c(\"lake\", \"park\")\n)\nhead(AK_lakes_pca_ord)\n## # A tibble: 6 × 3\n##   analyte      Dim.1   Dim.2\n##   <chr>        <dbl>   <dbl>\n## 1 water_temp 0.0769  -0.267 \n## 2 pH         0.704    0.0190\n## 3 C          0.297   -0.248 \n## 4 N          0.00446  0.732 \n## 5 P          0.485   -0.0817\n## 6 Cl         0.978    0.0152\n\nggplot(AK_lakes_pca_ord) +\n  geom_segment(aes(x = 0, y = 0, xend = Dim.1, yend = Dim.2, color = analyte), size = 1) +\n  geom_circle(aes(x0 = 0, y0 = 0, r = 1)) +\n  geom_label_repel(\n    data = filter(AK_lakes_pca_ord, Dim.1 > 0.9, Dim.2 < 0.1, Dim.2 > -0.1),\n    aes(x = Dim.1, y = Dim.2, label = analyte), xlim = c(1,1.5)\n  ) +\n  geom_label_repel(\n    data = filter(AK_lakes_pca_ord, Dim.2 > 0.5),\n    aes(x = Dim.1, y = Dim.2, label = analyte), direction = \"y\", ylim = c(1,1.5)\n  ) +\n  coord_cartesian(xlim = c(-1,1.5), ylim = c(-1,1.5)) +\n  theme_bw()"},{"path":"PCA.html","id":"principal-components","chapter":"7 pca","heading":"7.3 principal components","text":"also can access information much variance data set explained principal component, can plot using ggplot:Cool! can see first principal component retains nearly 50% variance original dataset, second dimension contains 20%.","code":"\nAK_lakes_pca_dim <- runMatrixAnalysis(\n  data = alaska_lake_data,\n  analysis = c(\"pca_dim\"),\n  column_w_names_of_multiple_analytes = \"element\",\n  column_w_values_for_multiple_analytes = \"mg_per_L\",\n  columns_w_values_for_single_analyte = c(\"water_temp\", \"pH\"),\n  columns_w_additional_analyte_info = \"element_type\",\n  columns_w_sample_ID_info = c(\"lake\", \"park\")\n)\nhead(AK_lakes_pca_dim)\n## # A tibble: 6 × 2\n##   principal_component percent_variance_explained\n##                 <dbl>                      <dbl>\n## 1                   1                      48.8 \n## 2                   2                      18.6 \n## 3                   3                      11.6 \n## 4                   4                       7.88\n## 5                   5                       4.68\n## 6                   6                       3.33\n\nggplot(\n  data = AK_lakes_pca_dim, \n  aes(x = principal_component, y = percent_variance_explained)\n) +\n  geom_line() +\n  geom_point() +\n  theme_bw()"},{"path":"PCA.html","id":"exercises-4","chapter":"7 pca","heading":"7.4 exercises","text":"set exercises choose complete ONE options . either option please refer Chapter 12 help principal component ordination plots. Also, filling runMatrixAnalysis() template, can use colnames() function help specify long list column names rather typing hand. example, periodic table data set, can refer set columns (columns 10 20) following command:can use command template, example . notation colnames(periodic_table_subset)[c(5:7,9:25)], can mark columns 5 - 7 9 - 25 columns_w_values_for_single_analyte (note happens run c(5:7,9:25) console, happens run colnames(periodic_table_subset)[c(5:7,9:25)] console). notation colnames(periodic_table_subset)[c(1:4, 8)] can mark columns 1 - 4 column 8 columns_w_sample_ID_info (note happens run c(1:4, 8) console, happens run colnames(periodic_table_subset)[c(1:4, 8)] console).","code":"\ncolnames(periodic_table_subset)[10:20]\n##  [1] \"electronegativity_pauling\"         \n##  [2] \"first_ionization_poten_eV\"         \n##  [3] \"second_ionization_poten_eV\"        \n##  [4] \"third_ionization_poten_eV\"         \n##  [5] \"electron_affinity_eV\"              \n##  [6] \"atomic_radius_ang\"                 \n##  [7] \"ionic_radius_ang\"                  \n##  [8] \"covalent_radius_ang\"               \n##  [9] \"atomic_volume_cm3_per_mol\"         \n## [10] \"electrical_conductivity_mho_per_cm\"\n## [11] \"specific_heat_J_per_g_K\"\ncolnames(periodic_table_subset)[c(18:20, 23:25)]\n## [1] \"atomic_volume_cm3_per_mol\"         \n## [2] \"electrical_conductivity_mho_per_cm\"\n## [3] \"specific_heat_J_per_g_K\"           \n## [4] \"thermal_conductivity_W_per_m_K\"    \n## [5] \"polarizability_A_cubed\"            \n## [6] \"heat_atomization_kJ_per_mol\""},{"path":"PCA.html","id":"option-1-human-metabolomics.","chapter":"7 pca","heading":"7.4.1 option 1: human metabolomics.","text":"first option work dataset describing metabolomics data (.e. abundances > 100 different biochemicals) 93 human patients, Chronic Kidney Disease. choose option, task discover biomarker Chronic Kidney Disease. means need determine metabolite whose abundance strongly associated disease. complete following:Run PCA analysis metabolomics_data (.e. runMatrixAnalysis() analysis = \"pca\")Plot results analysis determine principal component (.e. dimension) separates healthy kidney_disease samples.Obtain ordination plot coordinates analytes PCA analysis (.e. runMatrixAnalysis() analysis = \"pca_ord\").Visualize ordination plot determine analytes strongly associated principal component (.e. dimension) separates healthy kidney_disease samples.Bingo! analytes associated Chronic Kidney Disease biomarkers .","code":""},{"path":"PCA.html","id":"option-2-grape-vine-chemistry","chapter":"7 pca","heading":"7.4.2 option 2: grape vine chemistry","text":"second option work dataset describing metabolomics data (.e. abundances > 100 different biochemicals) 5 different wine grape varieties. choose option, task discover biomarker Chardonnay biomarker Cabernet Sauvignon. means need identify two metabolites, associated one two grape varieties. complete following:Run PCA analysis wine_grape_data (.e. runMatrixAnalysis() analysis = \"pca\")Plot results analysis determine principal component (.e. dimension) separates Chardonnay samples varieties Cabernet Sauvignon samples varieties.Obtain ordination plot coordinates analytes PCA analysis (.e. runMatrixAnalysis() analysis = \"pca_ord\").Visualize ordination plot determine analytes strongly associated principal component (.e. dimension) separates Chardonnay samples varieties Cabernet Sauvignon samples varieties.Bingo! analytes associated varieites biomarkers .","code":""},{"path":"k-means.html","id":"k-means","chapter":"8 k-means","heading":"8 k-means","text":"“samples fall definable clusters?”","code":""},{"path":"k-means.html","id":"theory-1","chapter":"8 k-means","heading":"8.1 theory","text":"One questions ’ve asking “samples closely related?” ’ve answering question using clustering. However, now know run principal components analyses, can use another approach. alternative approach called k-means, can help us decide assign data clusters. generally desirable small number clusters, however, must balanced variance within cluster big. strike balance point, elbow method used. , must first determine maximum within-group variance possible number clusters. illustration shown :One know within-group variances, find “elbow” point - point minimum angle theta - thus picking outcome good balance cluster number within-cluster variance (illustrated B C.)Let’s try k-means using runMatrixAnalysis. can use conjunction analysis = \"pca\" analysis = \"hclust\". Let’s PCA first. include k-means, can just set kmeans = \"auto\". ’s important note kmeans handle NAs. must set something na_replacement argument. One solution ignore variables NAs values, can done setting na_replacement = \"drop\".kmeans = \"auto\" na_replacement = \"drop\", can now run analyssis. output now additional column called kmeans_cluster, indicates cluster sample :can plot results color according group kmeans suggested:Hmmm, looks like elbow algorithm suggesting lots clusters. ? Let’s look elbow plot . , can just set kmeans = \"elbow\":gives us maximum variance within cluster number clusters. Let’s plot :Hmm, looks like aren’t strong elbows plot - probably reason elbow method chooses high number clusters. Suppose want manually set number clusters? can set kmeans = 3 want three clusters output. , let’s just . Let’s also plot results use geom_mark_ellipse.Cool!One important point: using kmeans, output runMatrixAnalysis (specifically kmeans_cluster column) can used create groupings summary statistics. example, suppose want two groups solvents want calculate mean standard deviation boiling points groups:good! Since can use outputs k-means analyses run visualize summary statistics, ’s possible ’ll want see cluster plot (dendrogram pca plot) alongside summary stats plot. can use plot_grid function cowplot package. Let’s check :Now really rockin!!","code":"\nsolvents_pca_kmeans <- runMatrixAnalysis(\n  data = solvents,\n  analysis = c(\"pca\"),\n  column_w_names_of_multiple_analytes = NULL,\n  column_w_values_for_multiple_analytes = NULL,\n  columns_w_values_for_single_analyte = colnames(solvents)[c(3:5, 7:9, 11:12)],\n  columns_w_additional_analyte_info = NULL,\n  columns_w_sample_ID_info = c(\"solvent\", \"formula\", \"miscible_with_water\", \"CAS_number\", \"category\"),\n  transpose = FALSE,\n  kmeans = \"auto\",\n  na_replacement = \"drop\"\n)\n## Dropping any variables in your dataset that have NA as a value.\n## Variables dropped:\n## solubility_in_water vapor_pressure\n\nsolvents_pca_kmeans\n## # A tibble: 32 × 15\n##    sample_unique_ID       solvent   formula miscible_with_w…\n##    <chr>                  <chr>     <chr>   <lgl>           \n##  1 acetic_acid_C2H4O2_TR… acetic_a… C2H4O2  TRUE            \n##  2 acetone_C3H6O_TRUE_67… acetone   C3H6O   TRUE            \n##  3 acetonitrile_C2H3N_TR… acetonit… C2H3N   TRUE            \n##  4 benzene_C6H6_FALSE_71… benzene   C6H6    FALSE           \n##  5 benzonitrile_C7H5N_FA… benzonit… C7H5N   FALSE           \n##  6 1-butanol_C4H10O_FALS… 1-butanol C4H10O  FALSE           \n##  7 2-butanone_C4H8O_FALS… 2-butano… C4H8O   FALSE           \n##  8 carbon_disulfide_CS2_… carbon_d… CS2     FALSE           \n##  9 carbon_tetrachloride_… carbon_t… CCl4    FALSE           \n## 10 chlorobenzene_C6H5Cl_… chlorobe… C6H5Cl  FALSE           \n## # … with 22 more rows, and 11 more variables:\n## #   CAS_number <chr>, category <chr>, Dim.1 <dbl>,\n## #   Dim.2 <dbl>, kmeans_cluster <chr>, boiling_point <dbl>,\n## #   melting_point <dbl>, density <dbl>,\n## #   relative_polarity <dbl>, formula_weight <dbl>,\n## #   refractive_index <dbl>\nggplot(solvents_pca_kmeans) +\n  geom_point(aes(x = Dim.1, y = Dim.2, fill = kmeans_cluster), shape = 21, size = 5, alpha = 0.6)\nsolvents_pca_kmeans_elbow <- runMatrixAnalysis(\n  data = solvents,\n  analysis = c(\"pca\"),\n  column_w_names_of_multiple_analytes = NULL,\n  column_w_values_for_multiple_analytes = NULL,\n  columns_w_values_for_single_analyte = colnames(solvents)[c(3:5, 7:9, 11:12)],\n  columns_w_additional_analyte_info = NULL,\n  columns_w_sample_ID_info = c(\"solvent\", \"formula\", \"miscible_with_water\", \"CAS_number\", \"category\"),\n  transpose = FALSE,\n  kmeans = \"elbow\",\n  na_replacement = \"drop\"\n)\n## Dropping any variables in your dataset that have NA as a value.\n## Variables dropped:\n## solubility_in_water vapor_pressure\n\nsolvents_pca_kmeans_elbow\n## # A tibble: 31 × 2\n##    cluster_number variance_within_cluster\n##             <dbl>                   <dbl>\n##  1              1                 142804.\n##  2              2                  67355.\n##  3              3                  49545.\n##  4              4                  38964.\n##  5              5                  30702.\n##  6              6                  25212.\n##  7              7                  20188.\n##  8              8                  16508.\n##  9              9                  14346.\n## 10             10                  12265.\n## # … with 21 more rows\nggplot(\n  solvents_pca_kmeans_elbow,\n  aes(x = cluster_number, y = variance_within_cluster)\n) +\n  geom_col() +\n  geom_point() +\n  geom_line()\nrunMatrixAnalysis(\n  data = solvents,\n  analysis = c(\"pca\"),\n  column_w_names_of_multiple_analytes = NULL,\n  column_w_values_for_multiple_analytes = NULL,\n  columns_w_values_for_single_analyte = colnames(solvents)[c(3:5, 7:9, 11:12)],\n  columns_w_additional_analyte_info = NULL,\n  columns_w_sample_ID_info = c(\"solvent\", \"formula\", \"miscible_with_water\", \"CAS_number\", \"category\"),\n  transpose = FALSE,\n  kmeans = 3,\n  na_replacement = \"drop\"\n) %>%\n\nggplot(aes(x = Dim.1, y = Dim.2, fill = kmeans_cluster)) +\n  geom_point(shape = 21, size = 5) +\n  geom_mark_ellipse(aes(label = kmeans_cluster), alpha = 0.2) +\n  theme_classic() +\n  coord_cartesian(xlim = c(-4,4), ylim = c(-4,4))\n## Dropping any variables in your dataset that have NA as a value.\n## Variables dropped:\n## solubility_in_water vapor_pressure\nsolvents_clustered <- runMatrixAnalysis(\n  data = solvents,\n  analysis = c(\"pca\"),\n  column_w_names_of_multiple_analytes = NULL,\n  column_w_values_for_multiple_analytes = NULL,\n  columns_w_values_for_single_analyte = colnames(solvents)[c(3:5, 7:9, 11:12)],\n  columns_w_additional_analyte_info = NULL,\n  columns_w_sample_ID_info = c(\"solvent\", \"formula\", \"miscible_with_water\", \"CAS_number\", \"category\"),\n  transpose = FALSE,\n  kmeans = 2,\n  na_replacement = \"drop\"\n)\n## Dropping any variables in your dataset that have NA as a value.\n## Variables dropped:\n## solubility_in_water vapor_pressure\n\nsolvents_clustered_summary <- solvents_clustered %>%\n  group_by(kmeans_cluster) %>%\n  summarize(mean_bp = mean(boiling_point))\n\nggplot() + \n  geom_col(\n    data = solvents_clustered_summary,\n    aes(x = kmeans_cluster, y = mean_bp),\n    color = \"black\", fill = \"white\"\n  ) +\n  geom_point(\n    data = solvents_clustered,\n    aes(x = kmeans_cluster, y = boiling_point)\n  )\nsolvents_clustered <- runMatrixAnalysis(\n  data = solvents,\n  analysis = c(\"pca\"),\n  column_w_names_of_multiple_analytes = NULL,\n  column_w_values_for_multiple_analytes = NULL,\n  columns_w_values_for_single_analyte = colnames(solvents)[c(3:5, 7:9, 11:12)],\n  columns_w_additional_analyte_info = NULL,\n  columns_w_sample_ID_info = c(\"solvent\", \"formula\", \"miscible_with_water\", \"CAS_number\", \"category\"),\n  transpose = FALSE,\n  kmeans = 4,\n  na_replacement = \"drop\"\n)\n## Dropping any variables in your dataset that have NA as a value.\n## Variables dropped:\n## solubility_in_water vapor_pressure\n\ncolors <- c(\"maroon\", \"gold\", \"grey\", \"white\")\n\npca_plot <- ggplot( data = solvents_clustered, aes(x = Dim.1, y = Dim.2, fill = kmeans_cluster) ) +\n  geom_mark_ellipse(\n    aes(label = kmeans_cluster), \n    alpha = 0.5, label.lineheight = 0.2, size = 0.5) +\n  geom_point(shape = 21, size = 2) +\n  theme_classic() +\n  guides(fill = \"none\") +\n  scale_x_continuous(name = \"PCA dimension 1\", breaks = seq(-8,8,1)) +\n  scale_y_continuous(name = \"PCA dimension 2\", breaks = seq(-7,7,1)) +\n  scale_fill_manual(values = colors) +\n  coord_cartesian(xlim = c(-8,8), ylim = c(-7,7))\n\nsolvents_clustered_summary <- solvents_clustered %>%\n  group_by(kmeans_cluster) %>%\n  summarize(mean_bp = mean(boiling_point))\n\nbar_plot <- ggplot() + \n  geom_violin(\n    data = solvents_clustered,\n    aes(x = kmeans_cluster, y = boiling_point, fill = kmeans_cluster),\n    size = 0.5, color = \"black\", alpha = 0.6, width = 0.5\n  ) +\n  geom_crossbar(\n    data = solvents_clustered_summary,\n    aes(x = kmeans_cluster, y = mean_bp, ymin = mean_bp, ymax = mean_bp),\n    color = \"black\", width = 0.5\n  ) +\n  geom_point(\n    data = solvents_clustered,\n    aes(x = kmeans_cluster, y = boiling_point),\n    size = 2, color = \"black\", alpha = 0.6\n  ) +\n  scale_y_continuous(name = \"Boiling point\", breaks = seq(0,250,20)) +\n  scale_x_discrete(name = \"Cluster\") +\n  scale_fill_manual(values = colors) +\n  theme_classic() +\n  coord_flip() +\n  guides(fill = \"none\") +\n  theme(legend.position = \"bottom\")\n\ncowplot::plot_grid(pca_plot, bar_plot, align = \"h\", axis = \"b\", labels = \"AUTO\")"},{"path":"k-means.html","id":"exercises-5","chapter":"8 k-means","heading":"8.2 exercises","text":"Use wine grapes dataset (’s stored wine_grape_data run source(...) command).","code":""},{"path":"k-means.html","id":"question-1","chapter":"8 k-means","heading":"8.2.1 Question 1","text":"Run principal components analysis dataset. Use na_replacement = \"drop\" (variables NA values included analysis) generate clusters automatically using kmeans setting kmeans = \"auto\". Make scatter plot results. many clusters kmeans recommend?","code":""},{"path":"k-means.html","id":"question-2","chapter":"8 k-means","heading":"8.2.2 Question 2","text":"Modify code Question 1 two clusters generated. Plot results. Use geom_mark_ellipse highlight cluster plot (note fill aesthetic required mark groups). varieties put two clusters?","code":""},{"path":"k-means.html","id":"question-3","chapter":"8 k-means","heading":"8.2.3 Question 3","text":"Use ordination plot determine chemicals makes Chardonnay different varieties. class compounds chemical belong?","code":""},{"path":"k-means.html","id":"question-4","chapter":"8 k-means","heading":"8.2.4 Question 4","text":"Modify code Question 2 five clusters generated. Plot results. Use geom_mark_ellipse highlight cluster plot (note fill aesthetic required mark groups). Based plot, grape variety undergoes least amount change, chemically speaking, dry well-watered conditions?","code":""},{"path":"k-means.html","id":"question-5","chapter":"8 k-means","heading":"8.2.5 Question 5","text":"Run heirarchical clustering analysis wine grapes data set, using kmeans create five groups, also continue using na_replacement = \"drop\". Plot results. grape variety undergoes change terms chemistry well-watered dry conditions? (hint: remember x-axis shows distances nodes tips, y-axis meaningless). Compare method used compare sample shifts question 4 (.e. pca+kmeans) versus method used question (.e. hclust+kmeans). better? change depending circumstances?","code":""},{"path":"k-means.html","id":"question-6","chapter":"8 k-means","heading":"8.2.6 Question 6","text":"Google “Quercetin.” kind compound ? Use clusters created heirarchical clustering analysis question 5 groups calculate summary statistics. Calculate mean standard deviation concentration Quercetin group. Plot result using geom_pointrange adjust axis font sizes good proportion size plot. Also specify theme (example, theme_classic()).one cluster large amount variation Quercetin abundance? think might ?","code":""},{"path":"k-means.html","id":"question-7","chapter":"8 k-means","heading":"8.2.7 Question 7","text":"Use cowplot::plot_grid display plots questions 4 5 next .","code":""},{"path":"k-means.html","id":"challenge-optional","chapter":"8 k-means","heading":"8.2.8 Challenge (optional)","text":"Use cowplot display plots questions 4, 5, 6 alongside . Make combined plot attractive possible! Use following:align = TRUE inside geom_tiplab()nrow = 1 inside plot_grid()rel_widths = <your_choice> inside plot_grid()name = <your_choice> inside scale_*_*label = kmeans_cluster inside geom_mark_ellipse()breaks = <your_choice> inside scale_x_continuous() scale_y_continuous() (example, breaks = seq(0,10,1))Also, consider using:guides(fill = \"none\", color = \"none\")Install RColorBrewer package, use one color schemes. example color scheme Set1:scale_fill_brewer(palette = \"Set1\", na.value = \"grey\")scale_color_brewer(palette = \"Set1\", na.value = \"grey\")Save plot png using ggsave().Maybe something like :","code":""},{"path":"models.html","id":"models","chapter":"9 models","heading":"9 models","text":"","code":""},{"path":"models.html","id":"theory-2","chapter":"9 models","heading":"9.1 theory","text":"Next quest develop abilities analytical data exploration modeling. start simplest models - linear models. variety ways build linear models R, use function called buildLinearModel. use , simply give data, tell sets values want compare. tell want compare, give formula form Y = M x X + B, however, B term M implicit, need tell Y = X.Let’s look example. Suppose want know abundances ADP AMP related metabolomics dataset:looks like might relationship! Let’s build linear model relationship:model consists two thigs: metrics data. Let’s look metrics:shows us intercept (b), variable AMP (.e. slope, m), well things (talk second). thing model contains data (). includes input_x y values. raw values ADP AMP, residuals (see details), x y values generated model.Let’s plot model!good. Now let’s talk evaluating quality model. need means assessing well line fits data. use residuals - distance points line.can calculate sum squared residuals:15.39! Let’s call “residual sum squares.” . 15.39.. mean model good? don’t know. compare number something. Let’s compare super simple model just defined mean y value input data.pretty bad model, agree. much better linear model flat line model? Let’s create measure distance point point predicted x value model:40.32! Wow. Let’s call “total sum squares,” now can compare “residual sum squares”:0.68! Alright. R squared value. equal 1 minus ratio “residual sum squares” “total sum squares.” Now, let’s put together make pretty:","code":"\nggplot(metabolomics_data) +\n  geom_point(aes(x = AMP, y = ADP))\nmodel <- buildLinearModel(\n  data = metabolomics_data,\n  formula = \"ADP = AMP\"\n)\nstr(model, strict.width = \"cut\")\n## List of 2\n##  $ metrics:'data.frame': 6 obs. of  4 variables:\n##   ..$ variable: chr [1:6] \"(Intercept)\" \"AMP\" \"median_res\"..\n##   ..$ value   : num [1:6] 0.7842 0.9142 0.0415 40.3224 15...\n##   ..$ type    : chr [1:6] \"coefficient\" \"coefficient\" \"st\"..\n##   ..$ p_value : chr [1:6] \"0.4375\" \"0\" NA NA ...\n##  $ data   :'data.frame': 92 obs. of  7 variables:\n##   ..$ input_x  : num [1:92] 13.2 13.5 14.3 13.3 12 ...\n##   ..$ input_y  : num [1:92] 12.8 13.1 13.3 13.2 11.9 ...\n##   ..$ ADP      : num [1:92] 12.8 13.1 13.3 13.2 11.9 ...\n##   ..$ AMP      : num [1:92] 13.2 13.5 14.3 13.3 12 ...\n##   ..$ residuals: num [1:92] 0.0312 -0.0217 -0.6014 0.2458 ..\n##   ..$ model_y  : num [1:92] 12.8 13.1 13.9 13 11.8 ...\n##   ..$ model_x  : num [1:92] 13.2 13.5 14.3 13.3 12 ...\nmodel$metrics\n##               variable   value        type p_value\n## 1          (Intercept)  0.7842 coefficient  0.4375\n## 2                  AMP  0.9142 coefficient       0\n## 3      median_residual  0.0415   statistic    <NA>\n## 4    total_sum_squares 40.3224   statistic    <NA>\n## 5 residual_sum_squares 15.3901   statistic    <NA>\n## 6            r_squared  0.6183   statistic    <NA>\nhead(model$data)\n##    input_x  input_y      ADP      AMP   residuals  model_y\n## 1 13.15029 12.83791 12.83791 13.15029  0.03119000 12.80672\n## 2 13.48362 13.08980 13.08980 13.48362 -0.02165141 13.11146\n## 3 14.32515 13.27943 13.27943 14.32515 -0.60138528 13.88082\n## 4 13.31191 13.20029 13.20029 13.31191  0.24581244 12.95448\n## 5 11.99764 11.93350 11.93350 11.99764  0.18057517 11.75293\n## 6 12.95966 12.83649 12.83649 12.95966  0.20405638 12.63243\n##    model_x\n## 1 13.15029\n## 2 13.48362\n## 3 14.32515\n## 4 13.31191\n## 5 11.99764\n## 6 12.95966\nggplot(model$data) +\n  geom_point(aes(x = input_x, y = input_y)) +\n  geom_line(aes(x = model_x, y = model_y))\nggplot(model$data) +\n  geom_point(aes(x = input_x, y = input_y)) +\n  geom_line(aes(x = model_x, y = model_y)) +\n  geom_segment(aes(x = input_x, y = input_y, xend = input_x, yend = model_y))\nsum(\n  (model$data$input_y - model$data$model_y)^2\n, na.rm = TRUE)\n## [1] 15.39014\nggplot(metabolomics_data) +\n  geom_point(aes(x = AMP, y = ADP)) +\n  geom_hline(aes(yintercept = mean(ADP, na.rm = TRUE)))\nsum(\n  (metabolomics_data$ADP - mean(metabolomics_data$ADP, na.rm = TRUE))^2\n, na.rm = TRUE)\n## [1] 40.32239\n\nggplot(metabolomics_data) +\n  geom_point(aes(x = AMP, y = ADP)) +\n  geom_hline(aes(yintercept = mean(ADP, na.rm = TRUE))) +\n  geom_segment(aes(x = AMP, y = ADP, xend = AMP, yend = mean(ADP, na.rm = TRUE)))\n1-(15.39/40.32)\n## [1] 0.6183036\ntop <- ggplot(model$data) +\n  geom_point(aes(x = input_x, y = input_y)) +\n  geom_line(aes(x = model_x, y = model_y)) +\n  annotate(geom = \"table\",\n    x = 11.4,\n    y = 16,\n    label = list(model$metrics)\n  ) +\n  coord_cartesian(ylim = c(10,16)) +\n  theme_bw()\n\nbottom <- ggplot(model$data) +\n  geom_col(\n    aes(x = input_x, y = residuals),\n    width = 0.03, color = \"black\", position = \"dodge\", alpha = 0.5\n  ) +\n  theme_bw()\n\ncowplot::plot_grid(top, bottom, ncol = 1, labels = \"AUTO\", rel_heights = c(2,1))"},{"path":"models.html","id":"exercises-6","chapter":"9 models","heading":"9.2 exercises","text":"practice creating linear models, try following:Choose one datasets used far, run principal components analysis . Note output analysis run “pca_ord” contains Dimension 1 coordinate “Dim.1” sample, well abundance analyte sample.Choose one datasets used far, run principal components analysis . Note output analysis run “pca_ord” contains Dimension 1 coordinate “Dim.1” sample, well abundance analyte sample.Using information ordination plot, identify two analytes: one variance strongly positively correlated first principal component (.e. dimension 1), one variance slightly less strongly, still positively correlated first principal component. Using buildLinearModel, create plot two linear models, one regresses analytes dimension 1. greater r-squared value? Based know PCA, make sense?Using information ordination plot, identify two analytes: one variance strongly positively correlated first principal component (.e. dimension 1), one variance slightly less strongly, still positively correlated first principal component. Using buildLinearModel, create plot two linear models, one regresses analytes dimension 1. greater r-squared value? Based know PCA, make sense?Choose two analytes: one one analytes question 2 , analyte , according PCA ordination analysis, negatively correlated first principal component. Using buildLinearModel create plots showing two analytes correlated dimension 1. One positively correlated, negatively correlated. Enhance plots including visual represetation residuals.Choose two analytes: one one analytes question 2 , analyte , according PCA ordination analysis, negatively correlated first principal component. Using buildLinearModel create plots showing two analytes correlated dimension 1. One positively correlated, negatively correlated. Enhance plots including visual represetation residuals.","code":""},{"path":"comparing-means.html","id":"comparing-means","chapter":"10 comparing means","heading":"10 comparing means","text":"shapiroTest\nleveneTest\ntTest\nwilcoxTest\nanovaTest\ntukeyTest\nkruskalTest\ndunnTest“two things ?”Often, want know study subjects contain different amounts certain analytes. example, “lake contain potassium lake ?” , need statistical tests. , look comparing mean values analyte abundance situations two samples situations two samples.find many concepts discussed chapter easier think example mind. , suppose analytical chemist Hawaii studying chemistry island’s aquifers. data set hawaii_aquifers. can see output structure data set - 990 measurements 9 different analytes multiple wells draw set 10 aquifers.Importantly, many wells draw aquifer, shown graph .","code":"\nhawaii_aquifers\n## # A tibble: 990 × 6\n##    aquifer_code well_name      longitude latitude analyte   \n##    <chr>        <chr>              <dbl>    <dbl> <chr>     \n##  1 aquifer_1    Alewa_Heights…        NA       NA SiO2      \n##  2 aquifer_1    Alewa_Heights…        NA       NA Cl        \n##  3 aquifer_1    Alewa_Heights…        NA       NA Mg        \n##  4 aquifer_1    Alewa_Heights…        NA       NA Na        \n##  5 aquifer_1    Alewa_Heights…        NA       NA K         \n##  6 aquifer_1    Alewa_Heights…        NA       NA SO4       \n##  7 aquifer_1    Alewa_Heights…        NA       NA HCO3      \n##  8 aquifer_1    Alewa_Heights…        NA       NA dissolved…\n##  9 aquifer_1    Alewa_Heights…        NA       NA Ca        \n## 10 aquifer_1    Beretania_Hig…        NA       NA SiO2      \n## # … with 980 more rows, and 1 more variable:\n## #   abundance <dbl>\nunique(hawaii_aquifers$aquifer_code)\n##  [1] \"aquifer_1\"  \"aquifer_2\"  \"aquifer_3\"  \"aquifer_4\" \n##  [5] \"aquifer_5\"  \"aquifer_6\"  \"aquifer_7\"  \"aquifer_8\" \n##  [9] \"aquifer_9\"  \"aquifer_10\"\nhawaii_aquifers %>%\n  select(aquifer_code, well_name) %>%\n  group_by(aquifer_code) %>%\n  summarize(n_wells = length(unique(well_name))) -> aquifers_summarized\n\naquifers_summarized\n## # A tibble: 10 × 2\n##    aquifer_code n_wells\n##    <chr>          <int>\n##  1 aquifer_1         12\n##  2 aquifer_10         7\n##  3 aquifer_2          5\n##  4 aquifer_3          3\n##  5 aquifer_4         16\n##  6 aquifer_5          4\n##  7 aquifer_6         12\n##  8 aquifer_7          9\n##  9 aquifer_8          3\n## 10 aquifer_9         30\n\nggplot(aquifers_summarized) + geom_col(aes(x = n_wells, y = aquifer_code))"},{"path":"comparing-means.html","id":"definitions","chapter":"10 comparing means","heading":"10.1 definitions","text":"populations independent measurements: comparing means, comparing two sets values. important consider values came first place. particular, usually useful think values representatives larger populations. example aquifer data set, can think measurements different wells drawing aquifer independent measurements “population” (.e. aquifer).populations independent measurements: comparing means, comparing two sets values. important consider values came first place. particular, usually useful think values representatives larger populations. example aquifer data set, can think measurements different wells drawing aquifer independent measurements “population” (.e. aquifer).null hypothesis: conduct statistical test, testing null hypothesis. null (think “default”) hypothesis difference bewteen means (hence name “null”). example aquifers, let’s say ’re interested whether two aquifers different abundances potassium - case null hypothesis differ, words, amount potassium.null hypothesis: conduct statistical test, testing null hypothesis. null (think “default”) hypothesis difference bewteen means (hence name “null”). example aquifers, let’s say ’re interested whether two aquifers different abundances potassium - case null hypothesis differ, words, amount potassium.p value: p value represents probability getting data extreme results null hypothesis true. words - p value probability observe differences , fact differences means . continue example: suppose measure potassium levels 10% wells access aquifer find aquifer_1 potassium levels 14 +/- 2 aquifer_2 potassium levels 12 +/- 1. Suppose conduct statistical test get p value 0.04. means , assuming aquifers magneisum levels (.e. assuming null hypothesis true), 4% chance get measured values . words, aquifers potassium abundance, pretty unlikely obtained measurements .p value: p value represents probability getting data extreme results null hypothesis true. words - p value probability observe differences , fact differences means . continue example: suppose measure potassium levels 10% wells access aquifer find aquifer_1 potassium levels 14 +/- 2 aquifer_2 potassium levels 12 +/- 1. Suppose conduct statistical test get p value 0.04. means , assuming aquifers magneisum levels (.e. assuming null hypothesis true), 4% chance get measured values . words, aquifers potassium abundance, pretty unlikely obtained measurements .Please note p value probability detected difference false positive. probability false positive requires additional information order calculated. discussion please see end chapter.","code":""},{"path":"comparing-means.html","id":"test-selection","chapter":"10 comparing means","heading":"10.2 test selection","text":"many different types statistical tests. flow chart illustrating recommended statistical tests used course. can see three regimes tests: variance normality tests (blue), parametric tests (green), non-parametric tests (orange):comparing means, need first determine kind statistical tests can use data. () data can reasonably modelled normal distribution (ii) variances two means similar, can use powerful “parametric” tests (.e. tests likely detect difference means, assuming one exists). one criteria met, need use less powerful “non-parametric” tests.can check data normality similar variances using Shapiro test Levene test. Let’s use hawaii_aquifers data example, let’s consider element potassium:work two means, let’s just look aquifers 1 6:data normally distributed? similar variance? Let’s get first approximation looking plot:Based graphic, ’s hard say! Let’s use statistical test help. want run Shaprio test, looking see group normally distributed (group “aquifer_code,” .e. aquifer_1 aquifer_6). means need group_by(aquifer_code) run test:p-values 0.05! means distributions significantly different normal distribution. variances two means? similar? need Levene test. test, looking within group, rather across groups - means need group_by(aquifer_code) specify y ~ x formula instead:p-value test 0.596! means variances significantly different.","code":"\nK_data <- hawaii_aquifers %>%\n  filter(analyte == \"K\")\n  K_data\n## # A tibble: 110 × 6\n##    aquifer_code well_name         longitude latitude analyte\n##    <chr>        <chr>                 <dbl>    <dbl> <chr>  \n##  1 aquifer_1    Alewa_Heights_Sp…       NA      NA   K      \n##  2 aquifer_1    Beretania_High_S…       NA      NA   K      \n##  3 aquifer_1    Beretania_Low_Se…       NA      NA   K      \n##  4 aquifer_1    Kuliouou_Well         -158.     21.3 K      \n##  5 aquifer_1    Manoa_Well_II         -158.     21.3 K      \n##  6 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  7 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  8 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  9 aquifer_1    Nuuanu_Aerator_W…     -158.     21.4 K      \n## 10 aquifer_1    Palolo_Tunnel         -158.     21.3 K      \n## # … with 100 more rows, and 1 more variable:\n## #   abundance <dbl>\nK_data_1_2 <- K_data %>%\n    filter(aquifer_code %in% c(\"aquifer_1\", \"aquifer_6\"))\n\nK_data_1_2\n## # A tibble: 24 × 6\n##    aquifer_code well_name         longitude latitude analyte\n##    <chr>        <chr>                 <dbl>    <dbl> <chr>  \n##  1 aquifer_1    Alewa_Heights_Sp…       NA      NA   K      \n##  2 aquifer_1    Beretania_High_S…       NA      NA   K      \n##  3 aquifer_1    Beretania_Low_Se…       NA      NA   K      \n##  4 aquifer_1    Kuliouou_Well         -158.     21.3 K      \n##  5 aquifer_1    Manoa_Well_II         -158.     21.3 K      \n##  6 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  7 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  8 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  9 aquifer_1    Nuuanu_Aerator_W…     -158.     21.4 K      \n## 10 aquifer_1    Palolo_Tunnel         -158.     21.3 K      \n## # … with 14 more rows, and 1 more variable: abundance <dbl>\n\nggplot(K_data_1_2, aes(x = aquifer_code, y = abundance)) +\n    geom_boxplot() +\n    geom_point()\nK_data_1_2 %>%\n  ggplot(aes(x = abundance)) + \n    geom_histogram(bins = 30) +\n    facet_wrap(~aquifer_code) +\n    geom_density(aes(y = ..density..*10), color = \"blue\")\nK_data_1_2 %>%\n  group_by(aquifer_code) %>% \n  shapiro_test(abundance)\n## # A tibble: 2 × 4\n##   aquifer_code variable  statistic     p\n##   <chr>        <chr>         <dbl> <dbl>\n## 1 aquifer_1    abundance     0.885 0.102\n## 2 aquifer_6    abundance     0.914 0.239\nK_data_1_2 %>%\n  levene_test(abundance ~ aquifer_code)\n## # A tibble: 1 × 4\n##     df1   df2 statistic     p\n##   <int> <int>     <dbl> <dbl>\n## 1     1    22     0.289 0.596"},{"path":"comparing-means.html","id":"two-means","chapter":"10 comparing means","heading":"10.3 two means","text":"Now, since data passed test, means can use normal t-test. t-test parametric test. means relies modelling data using normal distribution order make comparisons. also powerful test. means likely detect difference means, assuming one present. Let’s try :p-value 0.012! 0.05, meaning 95% chance two means different. Suppose data passed Shapiro /Levene tests. need use Wilcox test. Wilcox test non-parametric test, means use normal distribution model data order make comparisons. means less powerful test t-test, means less likely detect difference means, assuming one. fun, let’s try one compare p-values two methods:p-value 0.028! higher value given t-test (0.012). Wilcox test less powerful test: less likely detect differences means, assuming exist.","code":"\nK_data_1_2 %>%\n  t_test(abundance ~ aquifer_code)\n## # A tibble: 1 × 8\n##   .y.       group1 group2    n1    n2 statistic    df      p\n## * <chr>     <chr>  <chr>  <int> <int>     <dbl> <dbl>  <dbl>\n## 1 abundance aquif… aquif…    12    12     -2.75  20.5 0.0121\nK_data_1_2 %>%\n  wilcox_test(abundance ~ aquifer_code)\n## # A tibble: 1 × 7\n##   .y.       group1    group2       n1    n2 statistic      p\n## * <chr>     <chr>     <chr>     <int> <int>     <dbl>  <dbl>\n## 1 abundance aquifer_1 aquifer_6    12    12      33.5 0.0282"},{"path":"comparing-means.html","id":"more-than-two-means","chapter":"10 comparing means","heading":"10.4 more than two means","text":"previous section compared two means. want compare means two study subjects? first step determine tests use. Let’s consider hawaii aquifer data , though time let’s use aquifers, just two:Let’s check visually see group normally distributed see roughly equal variance:, somewhat hard tell visually data normally distributed. seems pretty likely different variances means, let’s check using Shapiro Levene tests. Don’t forget: Shaprio test, looking within group need group_by(), Levene test, looking across groups, need provide y~x formula:Based tests, looks like data aquifer 9 significantly different normal distribution (Shaprio test p = 0.000008), variances certainly different one another (Levene test p = 0.002).Let’s assume second data passed tests. means reasonably model data normal distributions use parametric test compare means. means can use ANOVA test differences means.","code":"\nK_data <- hawaii_aquifers %>%\n  filter(analyte == \"K\")\n\nK_data\n## # A tibble: 110 × 6\n##    aquifer_code well_name         longitude latitude analyte\n##    <chr>        <chr>                 <dbl>    <dbl> <chr>  \n##  1 aquifer_1    Alewa_Heights_Sp…       NA      NA   K      \n##  2 aquifer_1    Beretania_High_S…       NA      NA   K      \n##  3 aquifer_1    Beretania_Low_Se…       NA      NA   K      \n##  4 aquifer_1    Kuliouou_Well         -158.     21.3 K      \n##  5 aquifer_1    Manoa_Well_II         -158.     21.3 K      \n##  6 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  7 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  8 aquifer_1    Moanalua_Wells_P…     -158.     21.4 K      \n##  9 aquifer_1    Nuuanu_Aerator_W…     -158.     21.4 K      \n## 10 aquifer_1    Palolo_Tunnel         -158.     21.3 K      \n## # … with 100 more rows, and 1 more variable:\n## #   abundance <dbl>\n\nggplot(data = K_data, aes(y = aquifer_code, x = abundance)) +\n  geom_boxplot() +\n  geom_point(color = \"maroon\", alpha = 0.6, size = 3)\nK_data %>%\n  group_by(aquifer_code) %>%\n  ggplot(aes(x = abundance)) + \n    geom_histogram(bins = 30) +\n    facet_wrap(~aquifer_code) +\n    geom_density(aes(y = ..density..*10), colour = \"blue\")\nK_data %>%\n  group_by(aquifer_code) %>% \n  shapiro_test(abundance)\n## # A tibble: 10 × 4\n##    aquifer_code variable  statistic          p\n##    <chr>        <chr>         <dbl>      <dbl>\n##  1 aquifer_1    abundance     0.885 0.102     \n##  2 aquifer_10   abundance     0.864 0.163     \n##  3 aquifer_2    abundance     0.913 0.459     \n##  4 aquifer_3    abundance     0.893 0.363     \n##  5 aquifer_4    abundance     0.948 0.421     \n##  6 aquifer_5    abundance     0.902 0.421     \n##  7 aquifer_6    abundance     0.914 0.239     \n##  8 aquifer_7    abundance     0.915 0.355     \n##  9 aquifer_8    abundance     0.842 0.220     \n## 10 aquifer_9    abundance     0.786 0.00000866\nK_data %>%\n  levene_test(abundance ~ aquifer_code)\n## # A tibble: 1 × 4\n##     df1   df2 statistic       p\n##   <int> <int>     <dbl>   <dbl>\n## 1     9   100      3.12 0.00239"},{"path":"comparing-means.html","id":"anova-tukey-tests","chapter":"10 comparing means","heading":"10.4.1 ANOVA, Tukey tests","text":"use anova_test function package rstatix. tell us means data statistically different one another. However, differences means, tell us different.p-value 7.7e-11! definitely significant differences among group. , different one another though? , need run Tukey’s Honest Significant Difference test (implemented using tukey_hsd). essentially run t-test pairs study subjects can derive data set (example, aquifer_1 vs. aquifer_2, aquifer_1 vs. aquifer_3, etc.). , correct p-values according number comparisons performed. controls rate type error can expect test. corrected values provided us p.adj column.Using output tukey test, can determine means similar. can using p_groups function:can use output p_groups annotate plot:Excellent! plot shows us, using letters line aquifer, means different. letter shared among labels line two aquifers, means means differ significantly. example, aquifer 2 aquifer 6 “b” labels, means different - aquifers 3 10.","code":"\nK_data %>%\n  anova_test(abundance ~ aquifer_code)\n## Coefficient covariances computed by hccm()\n## ANOVA Table (type II tests)\n## \n##         Effect DFn DFd      F        p p<.05   ges\n## 1 aquifer_code   9 100 10.021 7.72e-11     * 0.474\nK_data %>%\n  tukey_hsd(abundance ~ aquifer_code)\n## # A tibble: 45 × 9\n##    term         group1     group2 null.value estimate conf.low\n##  * <chr>        <chr>      <chr>       <dbl>    <dbl>    <dbl>\n##  1 aquifer_code aquifer_1  aquif…          0  0.00357   -2.00 \n##  2 aquifer_code aquifer_1  aquif…          0  1.44      -0.668\n##  3 aquifer_code aquifer_1  aquif…          0  0.375     -2.35 \n##  4 aquifer_code aquifer_1  aquif…          0 -1.15      -2.75 \n##  5 aquifer_code aquifer_1  aquif…          0 -0.845     -3.09 \n##  6 aquifer_code aquifer_1  aquif…          0  1.98       0.261\n##  7 aquifer_code aquifer_1  aquif…          0  2.70       0.837\n##  8 aquifer_code aquifer_1  aquif…          0 -0.125     -2.85 \n##  9 aquifer_code aquifer_1  aquif…          0 -0.378     -1.78 \n## 10 aquifer_code aquifer_10 aquif…          0  1.44      -0.910\n## # … with 35 more rows, and 3 more variables:\n## #   conf.high <dbl>, p.adj <dbl>, p.adj.signif <chr>\ngroups_based_on_tukey <- K_data %>%\n  tukey_hsd(abundance ~ aquifer_code) %>%\n  p_groups()\ngroups_based_on_tukey\n##             treatment group spaced_group\n## aquifer_1   aquifer_1    ab         ab  \n## aquifer_10 aquifer_10   abc         abc \n## aquifer_2   aquifer_2   acd         a cd\n## aquifer_3   aquifer_3  abcd         abcd\n## aquifer_4   aquifer_4     b          b  \n## aquifer_5   aquifer_5    ab         ab  \n## aquifer_6   aquifer_6    cd           cd\n## aquifer_7   aquifer_7     d            d\n## aquifer_8   aquifer_8   abc         abc \n## aquifer_9   aquifer_9    ab         ab\nggplot(data = K_data, aes(y = aquifer_code, x = abundance)) +\n  geom_boxplot() +\n  geom_point(color = \"maroon\", alpha = 0.6, size = 3) +\n  geom_text(data = groups_based_on_tukey, aes(y = treatment, x = 9, label = group))"},{"path":"comparing-means.html","id":"kruskal-dunn-tests","chapter":"10 comparing means","heading":"10.4.2 Kruskal, Dunn tests","text":"ANOVA example great, remember - data pass Shapiro Levene tests. means data can modelled normal distribution taht need use non-parametric test. non-parametric alternative ANOVA called Kruskal test. Like Wilcox test, less powerful parametric relative, meaning less likely detected differences, exist. However, since data pass Shapiro/Levene tests, resort Kruskal test. Let’s try :p-value 3.9e-9! higher p-value running ANOVA data (remember, Kruskal test less powerful). Never less, value still well 0.05, meaning means different. , determine different one another? ran ANOVA follow-test (post hoc test) Tukey’s HSD. Kruskal test, post hoc test use Dunn test. Let’s try:gives us adjusted p-values pairwise comparisons. , can use p_groups() give us compact letter display group, can used annotate plot:Note groupings different generated ANOVA/Tukey.","code":"\nK_data %>%\n  kruskal_test(abundance ~ aquifer_code)\n## # A tibble: 1 × 6\n##   .y.           n statistic    df            p method       \n## * <chr>     <int>     <dbl> <int>        <dbl> <chr>        \n## 1 abundance   110      57.7     9 0.0000000037 Kruskal-Wall…\nK_data %>%\n  dunn_test(abundance ~ aquifer_code)\n## # A tibble: 45 × 9\n##    .y.    group1 group2    n1    n2 statistic       p  p.adj\n##  * <chr>  <chr>  <chr>  <int> <int>     <dbl>   <dbl>  <dbl>\n##  1 abund… aquif… aquif…    12     7    -0.205 0.838   1     \n##  2 abund… aquif… aquif…    12     6     2.25  0.0242  0.702 \n##  3 abund… aquif… aquif…    12     3     0.911 0.362   1     \n##  4 abund… aquif… aquif…    12    17    -2.70  0.00702 0.232 \n##  5 abund… aquif… aquif…    12     5    -1.15  0.252   1     \n##  6 abund… aquif… aquif…    12    12     2.53  0.0113  0.351 \n##  7 abund… aquif… aquif…    12     9     3.02  0.00254 0.0967\n##  8 abund… aquif… aquif…    12     3     0.182 0.855   1     \n##  9 abund… aquif… aquif…    12    36    -0.518 0.605   1     \n## 10 abund… aquif… aquif…     7     6     2.20  0.0278  0.777 \n## # … with 35 more rows, and 1 more variable:\n## #   p.adj.signif <chr>\ngroups_based_on_dunn <- K_data %>%\n  dunn_test(abundance ~ aquifer_code) %>%\n  p_groups()\ngroups_based_on_dunn\n##             treatment group spaced_group\n## aquifer_1   aquifer_1  abcd         abcd\n## aquifer_10 aquifer_10  abcd         abcd\n## aquifer_2   aquifer_2   abc         abc \n## aquifer_3   aquifer_3  abcd         abcd\n## aquifer_4   aquifer_4     d            d\n## aquifer_5   aquifer_5   acd         a cd\n## aquifer_6   aquifer_6    ab         ab  \n## aquifer_7   aquifer_7     b          b  \n## aquifer_8   aquifer_8  abcd         abcd\n## aquifer_9   aquifer_9    cd           cd\n\nggplot(data = K_data, aes(y = aquifer_code, x = abundance)) +\n  geom_boxplot() +\n  geom_point(color = \"black\", alpha = 0.4, size = 2) +\n  scale_x_continuous(name = \"Potassium abundance\", breaks = seq(0,10,1)) +\n  scale_y_discrete(name = \"Aquifer code\") +\n  geom_text(data = groups_based_on_dunn, aes(y = treatment, x = 9, label = group)) +\n  theme_bw()"},{"path":"comparing-means.html","id":"pairs-of-means","chapter":"10 comparing means","heading":"10.5 pairs of means","text":"Oftentimes two means compare, rather wanting compare means , want compare pairwise fashion. example, suppose want know aquifers contain different amounts Na Cl. interested testing differences among values Na Cl, rather, want test pairs Na Cl values arising aquifer. say, want compare means facet plot :Fortunately, can use approach similar ’ve learned earlier portions chapter, just minor modifications. Let’s look! start Shapiro Levene tests, usual (note group using two variables using Shapiro test analyte within aquifer considered individual distribution):Looks like distributions significantly different normal! Let’s run levene test anyway. Note particular case Levene test, interested testing whether pair distributions similar variances. need feed Levene test data grouped aquifer_code (tests pair group), need specify y ~ x formula (case abundance ~ analyte):looks like variances pair aquifer 1 significantly different variances. - sure need using non-parametric testing. simple case two means use wilcox_test, may pairs, use pairwise_wilcox_test (note test options various styles controlling multiple comparisons, see: ?pairwise_wilcox_test):Excellent! looks like statistically significant difference means abundances Cl Na aquifer_2 (surprisingly?) aquifer_9 (perhaps due large number observations?).done Shaprio Levene tests revealed significant differences? Well, pairwise_t_test course!Excellent, now see run parametric non-parametric pairwise comparisons. annotate plots output tests? example:","code":"\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  ggplot(aes(x = analyte, y = abundance)) + geom_violin() + geom_point() + facet_grid(.~aquifer_code)\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  group_by(analyte, aquifer_code) %>%\n  shapiro_test(abundance)\n## # A tibble: 20 × 5\n##    aquifer_code analyte variable  statistic        p\n##    <chr>        <chr>   <chr>         <dbl>    <dbl>\n##  1 aquifer_1    Cl      abundance     0.900 1.59e- 1\n##  2 aquifer_10   Cl      abundance     0.486 1.09e- 5\n##  3 aquifer_2    Cl      abundance     0.869 2.24e- 1\n##  4 aquifer_3    Cl      abundance     0.75  0       \n##  5 aquifer_4    Cl      abundance     0.903 7.49e- 2\n##  6 aquifer_5    Cl      abundance     0.767 4.22e- 2\n##  7 aquifer_6    Cl      abundance     0.741 2.15e- 3\n##  8 aquifer_7    Cl      abundance     0.893 2.12e- 1\n##  9 aquifer_8    Cl      abundance     0.878 3.17e- 1\n## 10 aquifer_9    Cl      abundance     0.414 7.58e-11\n## 11 aquifer_1    Na      abundance     0.886 1.06e- 1\n## 12 aquifer_10   Na      abundance     0.593 2.26e- 4\n## 13 aquifer_2    Na      abundance     0.884 2.88e- 1\n## 14 aquifer_3    Na      abundance     0.822 1.69e- 1\n## 15 aquifer_4    Na      abundance     0.933 2.41e- 1\n## 16 aquifer_5    Na      abundance     0.782 5.71e- 2\n## 17 aquifer_6    Na      abundance     0.764 3.80e- 3\n## 18 aquifer_7    Na      abundance     0.915 3.51e- 1\n## 19 aquifer_8    Na      abundance     0.855 2.53e- 1\n## 20 aquifer_9    Na      abundance     0.544 2.09e- 9\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  group_by(aquifer_code) %>%\n  levene_test(abundance ~ analyte)\n## # A tibble: 10 × 5\n##    aquifer_code   df1   df2 statistic       p\n##    <chr>        <int> <int>     <dbl>   <dbl>\n##  1 aquifer_1        1    22   10.5    0.00375\n##  2 aquifer_10       1    12    0.0535 0.821  \n##  3 aquifer_2        1    10    0.0243 0.879  \n##  4 aquifer_3        1     4    0.320  0.602  \n##  5 aquifer_4        1    32    1.57   0.219  \n##  6 aquifer_5        1     8    0.474  0.511  \n##  7 aquifer_6        1    22    1.03   0.322  \n##  8 aquifer_7        1    16    1.54   0.232  \n##  9 aquifer_8        1     4    0.515  0.512  \n## 10 aquifer_9        1    70    1.07   0.304\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  group_by(aquifer_code) %>%\n  pairwise_wilcox_test(abundance~analyte)\n## # A tibble: 10 × 10\n##    aquifer_code .y.       group1 group2    n1    n2 statistic\n##  * <chr>        <chr>     <chr>  <chr>  <int> <int>     <dbl>\n##  1 aquifer_1    abundance Cl     Na        12    12      99.5\n##  2 aquifer_10   abundance Cl     Na         7     7      14  \n##  3 aquifer_2    abundance Cl     Na         6     6      36  \n##  4 aquifer_3    abundance Cl     Na         3     3       3  \n##  5 aquifer_4    abundance Cl     Na        17    17     189  \n##  6 aquifer_5    abundance Cl     Na         5     5      17.5\n##  7 aquifer_6    abundance Cl     Na        12    12      53  \n##  8 aquifer_7    abundance Cl     Na         9     9      42  \n##  9 aquifer_8    abundance Cl     Na         3     3       6  \n## 10 aquifer_9    abundance Cl     Na        36    36     248. \n## # … with 3 more variables: p <dbl>, p.adj <dbl>,\n## #   p.adj.signif <chr>\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  group_by(aquifer_code) %>%\n  pairwise_t_test(abundance~analyte) -> test_output\n  test_output\n## # A tibble: 10 × 10\n##    aquifer_code .y.       group1 group2    n1    n2        p\n##  * <chr>        <chr>     <chr>  <chr>  <int> <int>    <dbl>\n##  1 aquifer_1    abundance Cl     Na        12    12  4.69e-2\n##  2 aquifer_10   abundance Cl     Na         7     7  8.82e-1\n##  3 aquifer_2    abundance Cl     Na         6     6  3.75e-5\n##  4 aquifer_3    abundance Cl     Na         3     3  6.83e-1\n##  5 aquifer_4    abundance Cl     Na        17    17  1.03e-1\n##  6 aquifer_5    abundance Cl     Na         5     5  1.45e-1\n##  7 aquifer_6    abundance Cl     Na        12    12  5.66e-1\n##  8 aquifer_7    abundance Cl     Na         9     9  5.21e-1\n##  9 aquifer_8    abundance Cl     Na         3     3  4.28e-1\n## 10 aquifer_9    abundance Cl     Na        36    36  9.48e-1\n## # … with 3 more variables: p.signif <chr>, p.adj <dbl>,\n## #   p.adj.signif <chr>\n\nanno <- data.frame(\n  xmin = test_output$group1,\n  xmax = test_output$group2,\n  y_position = c(150, 150, 150, 175, 80, 50, 300, 150, 50, 125),\n  text = test_output$p.signif,\n  text_size = 10,\n  text_vert_offset = 10,\n  text_horiz_offset = 1.5,\n  tip_length_xmin = 5,\n  tip_length_xmax = 5,\n  aquifer_code = test_output$aquifer_code\n)\n\nhawaii_aquifers %>%\n  filter(analyte %in% c(\"Na\", \"Cl\")) %>%\n  ggplot(aes(x = analyte, y = abundance)) +\n  geom_violin(fill = \"gold\", color = \"black\") +\n  geom_point(shape = 21, fill = \"maroon\", color = \"black\") +\n  facet_grid(.~aquifer_code) +\n  geomSignif(data = anno) +\n  scale_x_discrete(name = \"Analyte\") +\n  scale_y_continuous(name = \"Abundance\") +\n  theme_bw() +\n  theme(\n    text = element_text(size = 16)\n    )"},{"path":"comparing-means.html","id":"further-reading","chapter":"10 comparing means","heading":"10.6 further reading","text":"comparing multiple means R: www.datanovia.comFor parametric versus non-parametric tests: Statistics JimFor interpreting p values: [p value wars () Ulrich Dirnagl]","code":""},{"path":"comparing-means.html","id":"exercises-7","chapter":"10 comparing means","heading":"10.7 exercises","text":"Using hawaii_aquifers data set, please complete following:Choose one analyte filter data rows analyte shown.Choose one analyte filter data rows analyte shown.Choose two aquifers. mean abundances chosen analyte different two aquifers? Don’t forget test data normality homogeneity variance selecting statistical test. Use plot illustrate whether means similar different.Choose two aquifers. mean abundances chosen analyte different two aquifers? Don’t forget test data normality homogeneity variance selecting statistical test. Use plot illustrate whether means similar different.Choose second analyte, different first one chose. Considering aquifers dataset, abundance analyte? , don’t forget normality homogeneity variance tests. Use plot illustrate answer.Choose second analyte, different first one chose. Considering aquifers dataset, abundance analyte? , don’t forget normality homogeneity variance tests. Use plot illustrate answer.Repeat #3 , switch type test used (.e. use non-parametric used parametric #3 vice-versa). Compare p values p groups obtained two methods. Use graphic illustrate . different?Repeat #3 , switch type test used (.e. use non-parametric used parametric #3 vice-versa). Compare p values p groups obtained two methods. Use graphic illustrate . different?","code":""},{"path":"section-3.html","id":"section-3","chapter":"","heading":"","text":"","code":""},{"path":"a-mini-manuscript.html","id":"a-mini-manuscript","chapter":"a mini manuscript","heading":"a mini manuscript","text":"final project course use techniques learned class analyze large dataset, prepare high quality figures, write miniature manuscript describing results.manuscript comprised title, abstract, introduction, results discussion section, figures captions, conclusions section, least five references. Please note following preparing manuscript:orders presentation preparation ! instances scientist may choose write components manuscript order appear page, always case. order preparation suggsted designed minimize amount revision / re-writing needs performed manuscript preparation process. Note suggested order composition line class schedule rest semester.","code":""},{"path":"figures-captions.html","id":"figures-captions","chapter":"11 figures & captions","heading":"11 figures & captions","text":"high quality figure one , example, axes tick labels overlap also fill space available , colors used, raw data plotted (possible), axes labels customized, appropriate theme chosen, geoms chosen carefully. plots visually attractive professional.Components caption:Title - overall description shownFor subplot:type plot (line plot, bar chart, etc.)Describe plotted y vs x words.Describe data .Describe bar, point, error bar represents.applicable, describe number independent samples measurements (sometimes called “replicates”) underlie given geometric feature summary statistic.Avoid abbreviations, use , specify mean.example:Fig. 1: Carbon, nitrogen, phosphorous Alaskan lakes. bar chart showing abundance (mg per L, x-axis) C, N, P various Alaskan lakes (lake names y-axis) located one three parks Alaska (park names right y groupings). data public chemistry data repository. bar represents result single measurement single analyte, identity coded using color shown color legend. Abbreviations: BELA - Bering Land Bridge National Preserve, GAAR - Gates Arctic National Park & Preserve, NOAT - Noatak National Preserve. –>","code":"\nggplot(\n  data = filter(alaska_lake_data, element_type == \"bound\"),\n  aes(y = lake, x = mg_per_L)\n) +\n  geom_col(\n    aes(fill = element),\n    alpha = 0.5, size = 0.5, position = \"dodge\",\n    color = \"black\"\n  ) +\n  facet_grid(park~., scales = \"free\", space = \"free\") +\n  theme_bw() +\n  scale_fill_brewer(palette = \"Set1\") +\n  scale_y_discrete(name = \"Lake Name\") +\n  scale_x_continuous(name = \"Abundance mg/L)\") +\n  theme(\n    text = element_text(size = 14)\n  )"},{"path":"results-and-discussion.html","id":"results-and-discussion","chapter":"12 results and discussion","heading":"12 results and discussion","text":"Objective: Walk reader results, drawing conclusions making interpretations go.go: make notes go introduction.","code":""},{"path":"results-and-discussion.html","id":"structure","chapter":"12 results and discussion","heading":"12.1 structure","text":"Key: number suggested sentences: purpose: “example”Key: number suggested sentences: purpose: “example”Introductory paragraph:\n1: Review aim paper: “order understand…”\n3-4: Combine methods summary (generalized summary results?) call subsections: “used method X quantify property Y study subject (section 2.1)”\n\n\nIntroductory paragraph:1: Review aim paper: “order understand…”3-4: Combine methods summary (generalized summary results?) call subsections: “used method X quantify property Y study subject (section 2.1)”\n\nsubsection paragraph:\n\n1: Purpose work described paragraph: “order determine…”\n1: Review methods experimental design specific subsection (necessary)\n4-5: Results method experiment (.e. data features)\n1-2: Comparison new results literature (possible)\n1-2: Conclusion combined results concluding remark “Thus, analysis X revealed …”\n1: Interpretation conclusion larger context (possible / reasonable)\nsubsection paragraph:\n1: Purpose work described paragraph: “order determine…”1: Review methods experimental design specific subsection (necessary)4-5: Results method experiment (.e. data features)1-2: Comparison new results literature (possible)1-2: Conclusion combined results concluding remark “Thus, analysis X revealed …”1: Interpretation conclusion larger context (possible / reasonable)Let’s look example:Let’s look example:2. Results Discussion.order better understand pollution state Minnesota, study focused detailed analyses chemical measurements soil samples 300 sites around state. analyses consisted principal components analysis determine sites similar one another (Section 2.1) followed statistical tests see whether differences detected sites’ chemistry (Section 2.2).2.1 Principal Components AnalysisTo understand relationships sites soil chemistry sampled, principal components analysis used. 20 different analytes, contained halogen atoms, included analysis. scatter plot showing position 300 samples space defined dimesions 1 2 (explain 54% 35% total variance dataset, respectively), revealed two major clusters present, small number outliers (Fig. 1). color coding two clusters according whether samples collected rural versus urban areas, possible see first cluster made almost exclusively samples urban areas, second cluster made almost entirely samples rural areas. suggested variance pollutant chemistry among samples collected assocaited urban versus rural environments.2.2 Statistical AnalysesUsing groupings identified via principal components analysis, statistical tests conducted determine chemical abundances differed groups. Tests normality homogeneity variance (Shapiro Levene tests) revealed data assessed using ANOVA instead required use non-parametric test. Accordingly, Kruskall-Wallis test followed post-hoc Dunn tests applied, showed abundances halogenated pollutants significantly higher urban versus rural areas (p = 0.0035, Fig. 2A). direct observations consistent conclusions drawn others recent literature reviews focused hydrocarbon compounds (Petrucci et al., 2018; Hendrix et al., 2019). Thus, new chemical analyses presented demonstrate discrepancy urban versus rural pollution true hydrocarbon compounds (found previously), also halogenated compounds. Together, findings strongly suggest either cities source pollution mechanism concentrates pollution cities.","code":""},{"path":"results-and-discussion.html","id":"suggestions","chapter":"12 results and discussion","heading":"12.2 suggestions","text":"Create paragraph outlines:Identify “data features” figures, possible conclusions lead . Example:\n“GC-MS data presented indicates cities higher levels pollution rural areas (Fig. 1),” (data feature)\n“suggesting either cities source pollution mechanism concentrates pollution cities.” (conclusion)\n“GC-MS data presented indicates cities higher levels pollution rural areas (Fig. 1),” (data feature)“suggesting either cities source pollution mechanism concentrates pollution cities.” (conclusion)Expand “data feature” -> “conclusion” combinations “supplementary information” “literature information.” Example:\n“GC-MS data presented indicates cities higher levels pollution rural areas.” (data feature)\n“direct observations consistent conclusions drawn others recent literature reviews (Petrucci., 2018; Hendrix et al., 2019)”\n“Overall, suggests either cities source pollution mechanism concentrates pollution cities.”\n“GC-MS data presented indicates cities higher levels pollution rural areas.” (data feature)“direct observations consistent conclusions drawn others recent literature reviews (Petrucci., 2018; Hendrix et al., 2019)”“Overall, suggests either cities source pollution mechanism concentrates pollution cities.”Write drafts paragraphs:Combine “data feature” -> “supp/lit info” -> “conclusion” combinations single paragraph.Consider editing paragraph highlights new contribution data makes situation. Example (note sentence italics highlights new findings):\n\"GC-MS data presented indicates cities higher levels pollution rural areas (Fig. 1). direct observations consistent meta-analyses previously published observations (Supplemental Figure 1), well conclusions drawn others recent literature reviews (et al., 2018; person et al., 2019). new chemical analyses presented demonstrate true hydrocarbon compounds (found previously), also halogenated compounds atmosphere. Together findings strongly suggest either cities source pollution mechanism concentrates pollution cities.\n\"GC-MS data presented indicates cities higher levels pollution rural areas (Fig. 1). direct observations consistent meta-analyses previously published observations (Supplemental Figure 1), well conclusions drawn others recent literature reviews (et al., 2018; person et al., 2019). new chemical analyses presented demonstrate true hydrocarbon compounds (found previously), also halogenated compounds atmosphere. Together findings strongly suggest either cities source pollution mechanism concentrates pollution cities.Order paragraphs:Identify characteristics paragraphs can help determine order go :\nWhether paragraphs prerequisites others.\nWhether paragraphs can grouped according topic.\nIdentify characteristics paragraphs can help determine order go :Whether paragraphs prerequisites others.Whether paragraphs can grouped according topic.Group paragraphs according topic prerequisite dependencies (putting prereq dependencies close eachother possible.)Group paragraphs according topic prerequisite dependencies (putting prereq dependencies close eachother possible.)Rearrange groups seems like natural flow. Consider:\nStarting group paragraphs relevant overall pitch/goal paper\nEnding group paragraphs future perspective\nEnding strong suit (.e. something speculative)\nRearrange groups seems like natural flow. Consider:Starting group paragraphs relevant overall pitch/goal paperEnding group paragraphs future perspectiveEnding strong suit (.e. something speculative), orphaned paragraphs, consider putting (shortened version ) conclusion section., orphaned paragraphs, consider putting (shortened version ) conclusion section.Throughout process, read lots literature incorporate discussion section. Place research context done previously.Throughout process, read lots literature incorporate discussion section. Place research context done previously.Edit results discussion section whole:Edit paragraph, particularly first last sentences, connect paragraphs flowing document. Specifically, means several things:\nimplicit cross-paragraph references (.e. new paragraph begin “compound described exhibited interesting properties,” rather, “3-hydroxycinnamic acid exhibited interesting properties.”).\nabrupt jumps subject paragraphs, consider breaking discussion subsections help reader identify logical resting points.\ndiscussion require reader go back read first half order understand second half.\n\nimplicit cross-paragraph references (.e. new paragraph begin “compound described exhibited interesting properties,” rather, “3-hydroxycinnamic acid exhibited interesting properties.”).abrupt jumps subject paragraphs, consider breaking discussion subsections help reader identify logical resting points.discussion require reader go back read first half order understand second half.\n","code":""},{"path":"conclusion-and-introduction.html","id":"conclusion-and-introduction","chapter":"13 conclusion and introduction","heading":"13 conclusion and introduction","text":"Objective (conclusion): convey short statement take-home messages study. important things want reader remember study?Objective (conclusion): convey short statement take-home messages study. important things want reader remember study?Objective (introduciton): prepare reader giving reader sufficient background understand study whole. therefore contain information pertinent understanding study broader significance.Objective (introduciton): prepare reader giving reader sufficient background understand study whole. therefore contain information pertinent understanding study broader significance.Make sure scope introduction -line scope conclusion. way, reader underwhelmed, work undersold.Make sure scope introduction -line scope conclusion. way, reader underwhelmed, work undersold.","code":""},{"path":"conclusion-and-introduction.html","id":"structure-1","chapter":"13 conclusion and introduction","heading":"13.1 structure","text":"Conclusion:One paragraph\n\n2-3: Summarize -arching conclusions section paper (omit details described results discussion)\n2-3: Based general description findings, use pros cons argue , possible, alternative hypotheses.\n1-2: Suggest experiments test hypotheses.\n1-2: Describe future directions.\n\n2-3: Summarize -arching conclusions section paper (omit details described results discussion)2-3: Based general description findings, use pros cons argue , possible, alternative hypotheses.1-2: Suggest experiments test hypotheses.1-2: Describe future directions.\nIntroduction:Paragraph 1: Introduce topic\n1: Introduce topic , ideally, application research describe. Grab reader’s attention.\n1: State topic important.\n1: Describe known topic (least, pertains work hand).\n1: Identify gap knowledge: “despite research area, don’t know topic.”\n1: List negative things happen don’t fill gap knowledge.\n1: Introduce topic , ideally, application research describe. Grab reader’s attention.1: State topic important.1: Describe known topic (least, pertains work hand).1: Identify gap knowledge: “despite research area, don’t know topic.”1: List negative things happen don’t fill gap knowledge.Paragraph 2: Provide background information\n3-5: Describe, moderate detail, background information (concepts, literature) relevant study.\n1: End saying details just described relate application/topic described first paragraph.\n3-5: Describe, moderate detail, background information (concepts, literature) relevant study.1: End saying details just described relate application/topic described first paragraph.Paragraph 3: Objectives study\n1: State objective study.\n1: Briefly describe done techniques instruments used.\n1-2: project, briefly describe got data, cleaned , merged multiple datasets, etc.\n1: (optional) State major conclusion work means application described paragraph 1.\n1: State objective study.1: Briefly describe done techniques instruments used.1-2: project, briefly describe got data, cleaned , merged multiple datasets, etc.1: (optional) State major conclusion work means application described paragraph 1.","code":""},{"path":"conclusion-and-introduction.html","id":"suggestions-1","chapter":"13 conclusion and introduction","heading":"13.2 suggestions","text":"something well-established, say .clear speculation.Last paragraph can mention objectives list form.Last sentence can briefly mention methods (specific techniques instruments) used.","code":""},{"path":"abstract-and-title.html","id":"abstract-and-title","chapter":"14 abstract and title","heading":"14 abstract and title","text":"","code":""},{"path":"abstract-and-title.html","id":"abstract","chapter":"14 abstract and title","heading":"14.1 abstract","text":"Structure One paragraph Use 200 - 500 words (ideally 400 words)\n1-2 sentences: Introduction: Describe topic, motivation, overall purpose research (research interesting important? gap knowledge fill?)\n1-2 sentences: Objective: Specific research objective, potentially hypotheses/predictions, .\n1-2 sentences: Methods: concise overview methods used address research questions.\n2-3 sentences: Results/Discussion: Describe major results (found) interpretation results (results mean).\n1-2 sentences: Conclusions: Synthesizes major contributions study context larger field study belongs. learn bigger picture field general study?\n1-2 sentences: Introduction: Describe topic, motivation, overall purpose research (research interesting important? gap knowledge fill?)1-2 sentences: Objective: Specific research objective, potentially hypotheses/predictions, .1-2 sentences: Methods: concise overview methods used address research questions.2-3 sentences: Results/Discussion: Describe major results (found) interpretation results (results mean).1-2 sentences: Conclusions: Synthesizes major contributions study context larger field study belongs. learn bigger picture field general study?Function: abstract proves short summary entire study. abstract include motivation reason conducting study, research question hypothesis , experiments conducted, results , results interpreted light research question hypothesis, concluding sentence general contribution importance study. good abstract :\nInform readers article’s content\nSummarize complex information clear, concise manner\nHelp readers decide whether read article\nUsed conferences summarize speaker say /presentation\nInform readers article’s contentSummarize complex information clear, concise mannerHelp readers decide whether read articleUsed conferences summarize speaker say /presentation","code":""},{"path":"abstract-and-title.html","id":"title","chapter":"14 abstract and title","heading":"14.2 title","text":"Structure One sentence Use 75-140 characters (ideally 125 characters). essentially two types titles: descriptive titles mechanistic titles.\nmanuscript exploratory research, consider using descriptive title. example:\n“Comparative analysis carbon, sulfur, phoshorous chemistry six Alaskan lakes.”\n\nmanuscript hypothesis-driven research, consider using mechanistic title. example:\n“Dissolved organic carbon Alaskan lakes heavily influenced water pH temperature.”\n\nmanuscript exploratory research, consider using descriptive title. example:\n“Comparative analysis carbon, sulfur, phoshorous chemistry six Alaskan lakes.”\n“Comparative analysis carbon, sulfur, phoshorous chemistry six Alaskan lakes.”manuscript hypothesis-driven research, consider using mechanistic title. example:\n“Dissolved organic carbon Alaskan lakes heavily influenced water pH temperature.”\n“Dissolved organic carbon Alaskan lakes heavily influenced water pH temperature.”Function: title captures attention highlight research question(s). good title :\nindicative content paper\nAttract interest potential readers\nReflect whether article deascriptive mechanistic\nInclude important keywords\nindicative content paperAttract interest potential readersReflect whether article deascriptive mechanisticInclude important keywords","code":""},{"path":"abstract-and-title.html","id":"further-reading-1","chapter":"14 abstract and title","heading":"14.3 further reading","text":"Titles Guide","code":""},{"path":"section-4.html","id":"section-4","chapter":"","heading":"","text":"","code":""},{"path":"image-analysis.html","id":"image-analysis","chapter":"IMAGE ANALYSIS","heading":"IMAGE ANALYSIS","text":"","code":""},{"path":"image-color-analysis.html","id":"image-color-analysis","chapter":"15 image color analysis","heading":"15 image color analysis","text":"analyze color images use interactive app called analyzeImage(). takes two arguments: share_link, monolist_out_path. share_link Google Drive share link photo wish analyze. share_link can also share link Google Drive folder, case app allow cycle photos folder one--one. monolist_out_path path new existing .csv file local sytem results saved work. example. Remember, Mac use path single slashes, example: /Users/bust0037/Desktop/output.csv. PC use path double slashes, example: C://Users//Busta_Lab//Desktop//output.csv.","code":"\nanalyzeImage(\n  share_link = \"https://drive.google.com/file/d/1rvfh9_DqEWlpaegGwfLZLdjjYEDlM0ZL/view?usp=sharing\",\n  monolist_out_path = \"/Users/bust0037/Desktop/output.csv\"\n)"},{"path":"images-of-mass-spectra.html","id":"images-of-mass-spectra","chapter":"16 images of mass spectra","heading":"16 images of mass spectra","text":"","code":"\nanalyzeMassSpectralImages()"},{"path":"phylochemistry-2.html","id":"phylochemistry-2","chapter":"17 phylochemistry","heading":"17 phylochemistry","text":"phylochemistry set functions chemical, transcriptomic, genomic analysis. tools provided though combination new computational functions wrapped features previously developed packages. number new organizational data handling functions streamline analyses interdisciplinary space also provided. page provides access latest version phylochemistry.","code":""},{"path":"phylochemistry-2.html","id":"requirements","chapter":"17 phylochemistry","heading":"17.1 requirements","text":"run phylochemistry, need R RStudio installed. instructions install , please see page.","code":""},{"path":"phylochemistry-2.html","id":"load-phylochemistry","chapter":"17 phylochemistry","heading":"17.2 load phylochemistry","text":"Phylochemistry R package, rather set components can add R environment running R script hosted site. phylochemistry requires number existing R packages order run, don’t worry,phylochemistry help install packages installed already.Load phylochemistry directly R session running following command RStudio:\nSometimes running command generates message “need install following packages proceeding […] Run: installPhylochemistry() automatically install required packages.” means prerequisite packages phylochemistry needs installed. happens, run following:\ncomplete, try source() command :","code":"\nsource(\"http://thebustalab.github.io/phylochemistry/phylochemistry.R\")\ninstallPhylochemistry()\nsource(\"http://thebustalab.github.io/phylochemistry/phylochemistry.R\")"},{"path":"phylochemistry-2.html","id":"r-scripts-on-google-drive","chapter":"17 phylochemistry","heading":"17.3 R scripts on Google Drive","text":"Sometimes want save R scripts Google Drive. R script Google Drive want open RStudio, get share link file use following command:\n, \"IN_USE___\" appear front file name Google Drive, others know using . done using file, can save close using:","code":"\nopenRGD(\"file_share_link_here\")\ncloseRGD(\"file_share_link_here\")"},{"path":"phylochemistry-2.html","id":"new-features","chapter":"17 phylochemistry","heading":"17.4 new features","text":"Shiny app GC-FID GC-MS data analysis, including large MS library.Open reading frame extraction multiple fasta files.BLAST searches export .fasta files hits store results .csv file.Minor ticks ggplot2 axes.Phylogenetic signal discrete traits.Analyze multiple sequence alignments sites associated user-defined functionMultiple column name, multiple row name data structures (aka “polylists”).Draw annotated multiple sequence alignments.Use image analysis automatically get csv mass spectrum published image.Draw chemical structures R csv molecular coordinates.","code":""},{"path":"phylochemistry-2.html","id":"wrapped-features","chapter":"17 phylochemistry","heading":"17.5 wrapped features","text":"BLAST transcriptomes, via NCBI BLAST+.Multiple sequence alignments codon alignments amino acid nucleotide sequences, via msa orthologr.Phylogenetic tree construction (including g-blocks trimming, pruning, ancestral states reconstruction), via phangorn.Systematic read/write functions (csv, newick, wide tables, fasta, summary statistic tables, GFFs, chromatograms, mass spectra).Phylogenetic signal continuous traits, via picante.","code":""},{"path":"mass-spectrometric-analysis.html","id":"mass-spectrometric-analysis","chapter":"18 mass spectrometric analysis","heading":"18 mass spectrometric analysis","text":"","code":""},{"path":"mass-spectrometric-analysis.html","id":"integrationapplite","chapter":"18 mass spectrometric analysis","heading":"18.1 integrationAppLite","text":"phylochemistry provides simple application integrating analyzing GC-MS data. , can analyze .CDF files, contain essentially data GC-MS run, can exported GC-MS systems using software provided manufacturer. Instructions provided end chapter. run lite version integration app, use following guidelines:Create new folder hard drive place CDF file folder. doesn’t matter name folder , must contain special characters (including space  name). example, CDF file called “sorghum_bicolor.CDF,” might create folder called gc_data hard drive, place “sorghum_bicolor.CDF” file folder.Create new folder hard drive place CDF file folder. doesn’t matter name folder , must contain special characters (including space  name). example, CDF file called “sorghum_bicolor.CDF,” might create folder called gc_data hard drive, place “sorghum_bicolor.CDF” file folder.RStudio, run source command load phylochemistry:RStudio, run source command load phylochemistry:RStudio, run integrationAppLite command folder contains CDF file.Mac, use single forward slashes. example:PC, use double back slashes. example:first time open datafile, may take load. normal - program analyzing data points data file. typical exploratory GC-MS run around 60 minutes, 2.5 million data points! please patient. open data file , subsequent openings take long.Please watch overview video demonstration use integration app.reference, key commands used operate integration app. information covered overview video.control chromatogram window:shift + q = updateshift + = add selected peakshift + r = remove selected peakshift + f = forwardshift + d = backwardshift + c = zoom inshift + v = zoom outshift + z = save tableTo control mass spectrum window:shift+1 = extract mass spectra highlighted chromatogram region, plot average mass spectrum panel 1.shift+2 = refresh mass spectrum panel 1. used zooming region mass spectrum highlighted. spectrum needs first extracted possible.shift+3 = extract mass spectra highlighted chromatogram region, subtract average mass spectrum panel 1.shift+4 = search current spectrum panel 1 library mass spectra.","code":"\nsource(\"http://thebustalab.github.io/phylochemistry/phylochemistry.R\")\nintegrationAppLite(\"/Volumes/My_Drive/gc_data\")\nintegrationAppLite(\"C:\\\\Users\\\\My Profile\\\\gc_data\")"},{"path":"mass-spectrometric-analysis.html","id":"cdf-export","chapter":"18 mass spectrometric analysis","heading":"18.2 CDF export","text":"GC-MS computer, open Enhanced Data AnalysisFile > Export Data .AIA Format, Create New Directory (“OK”) > Desktop (create folder name remember)Select datafiles wish analyze process , saving output folder just createdCopy .D files samples wish analyze folderMove folder personal computerCreate one folder sample, put corresponding .CDF file folder.\n","code":""},{"path":"transcriptomic-analyses.html","id":"transcriptomic-analyses","chapter":"19 transcriptomic analyses","heading":"19 transcriptomic analyses","text":"","code":""},{"path":"transcriptomic-analyses.html","id":"blast","chapter":"19 transcriptomic analyses","heading":"19.1 BLAST","text":"","code":""},{"path":"genomic-analyses.html","id":"genomic-analyses","chapter":"20 genomic analyses","heading":"20 genomic analyses","text":"","code":""},{"path":"genomic-analyses.html","id":"loading-gff-files","chapter":"20 genomic analyses","heading":"20.1 loading GFF files","text":"","code":""},{"path":"evolutionary-analyses.html","id":"evolutionary-analyses","chapter":"21 evolutionary analyses","heading":"21 evolutionary analyses","text":"","code":""},{"path":"evolutionary-analyses.html","id":"buildtree","chapter":"21 evolutionary analyses","heading":"21.1 buildTree","text":"","code":""},{"path":"evolutionary-analyses.html","id":"simple-template","chapter":"21 evolutionary analyses","heading":"21.1.1 Simple template","text":"","code":"\nbuildTree(\n  scaffold_type = \"newick\",\n  scaffold_in_path = NULL,\n  members = NULL\n)"},{"path":"evolutionary-analyses.html","id":"full-template","chapter":"21 evolutionary analyses","heading":"21.1.2 Full template","text":"","code":"\nbuildTree(\n  scaffold_type = c(\"amin_alignment\", \"nucl_alignment\", \"newick\"),\n  scaffold_in_path = NULL,\n  members = NULL,\n  gblocks = FALSE, \n  gblocks_path = NULL,\n  ml = FALSE, \n  model_test = FALSE,\n  bootstrap = FALSE,\n  rois = FALSE, \n  rois_data = NULL,\n  ancestral_states = FALSE,\n  root = NULL\n)"},{"path":"evolutionary-analyses.html","id":"collapsetree","chapter":"21 evolutionary analyses","heading":"21.2 collapseTree","text":"","code":""},{"path":"section-5.html","id":"section-5","chapter":"","heading":"","text":"","code":""},{"path":"appendix.html","id":"appendix","chapter":"APPENDIX","heading":"APPENDIX","text":"","code":""},{"path":"links.html","id":"links","chapter":"22 links","heading":"22 links","text":"","code":""},{"path":"links.html","id":"geoms-1","chapter":"22 links","heading":"22.1 geoms","text":"geoms ggplot2 cheatsheet","code":""},{"path":"links.html","id":"colors","chapter":"22 links","heading":"22.2 colors","text":"ColorBrewer2","code":""},{"path":"faq.html","id":"faq","chapter":"23 faq","heading":"23 faq","text":"","code":""},{"path":"faq.html","id":"filtering","chapter":"23 faq","heading":"23.1 filtering","text":"filter(<data>, <variable> < 18) ## less 18filter(<data>, <variable> <= 18) ## less equal 18filter(<data>, <variable> > 18) ## greater 18filter(<data>, <variable> >= 18) ## greater equal 18filter(<data>, <variable> == 18) ## equals 18filter(<data>, <variable> != 18) ## equal 18filter(<data>, <variable> == 18 | <variable> == 19) ## equal 18 19","code":""},{"path":"faq.html","id":"ordering","chapter":"23 faq","heading":"23.2 ordering","text":"list numeric element inherent order : -inf -> +inf. list character element also inherent order : -> Z, ’s mixed number letter list (interpreted R character list): 0 -> 9 -> -> Z.However, cases want list character elements order -> Z. cases, want convert list character elements list factor elements. Factors lists character elements inherent order -> Z. example, plot , y axis , perhaps, “correct” order:fix ? need convert column group_number list factors correct order (see ). , use command factor, accept argument called levels can define order characters :Notice now look type data contained column group_number says “” great! means converted column list factors, instead characters. Now happens make plot?VICTORY!","code":"\nggplot(periodic_table) +\n  geom_point(aes(y = group_number, x = atomic_mass_rounded))\nperiodic_table$group_number <- factor(\n  periodic_table$group_number,\n  levels = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"lanthanides\", \"actinides\")\n)\n\nperiodic_table\n## # A tibble: 118 × 41\n##    atomic_number element_name atomic_symbol group_number\n##            <dbl> <chr>        <chr>         <fct>       \n##  1             1 hydrogen     H             1           \n##  2             2 helium       He            18          \n##  3             3 lithium      Li            1           \n##  4             4 beryllium    Be            2           \n##  5             5 boron        B             13          \n##  6             6 carbon       C             14          \n##  7             7 nitrogen     N             15          \n##  8             8 oxygen       O             16          \n##  9             9 fluorine     F             17          \n## 10            10 neon         Ne            18          \n## # … with 108 more rows, and 37 more variables:\n## #   period <dbl>, atomic_mass_rounded <dbl>,\n## #   melting_point_C <dbl>, boiling_point_C <dbl>,\n## #   state_at_RT <chr>, density_g_per_mL <dbl>,\n## #   electronegativity_pauling <dbl>,\n## #   first_ionization_poten_eV <dbl>,\n## #   second_ionization_poten_eV <dbl>, …\nggplot(periodic_table) +\n  geom_point(aes(y = group_number, x = atomic_mass_rounded))"},{"path":"faq.html","id":"column-manipulation","chapter":"23 faq","heading":"23.3 column manipulation","text":"select specific columns:remove certain columns:","code":"\nalaska_lake_data %>%\n  select(water_temp, pH)\n## # A tibble: 220 × 2\n##    water_temp    pH\n##         <dbl> <dbl>\n##  1       6.46  7.69\n##  2       6.46  7.69\n##  3       6.46  7.69\n##  4       6.46  7.69\n##  5       6.46  7.69\n##  6       6.46  7.69\n##  7       6.46  7.69\n##  8       6.46  7.69\n##  9       6.46  7.69\n## 10       6.46  7.69\n## # … with 210 more rows\nalaska_lake_data %>%\n  select(!water_temp)\n## # A tibble: 220 × 6\n##    lake                park     pH element mg_per_L element_type\n##    <chr>               <chr> <dbl> <chr>      <dbl> <chr>       \n##  1 Devil_Mountain_Lake BELA   7.69 C          3.4   bound       \n##  2 Devil_Mountain_Lake BELA   7.69 N          0.028 bound       \n##  3 Devil_Mountain_Lake BELA   7.69 P          0     bound       \n##  4 Devil_Mountain_Lake BELA   7.69 Cl        10.4   free        \n##  5 Devil_Mountain_Lake BELA   7.69 S          0.62  free        \n##  6 Devil_Mountain_Lake BELA   7.69 F          0.04  free        \n##  7 Devil_Mountain_Lake BELA   7.69 Br         0.02  free        \n##  8 Devil_Mountain_Lake BELA   7.69 Na         8.92  free        \n##  9 Devil_Mountain_Lake BELA   7.69 K          1.2   free        \n## 10 Devil_Mountain_Lake BELA   7.69 Ca         5.73  free        \n## # … with 210 more rows"},{"path":"templates.html","id":"templates","chapter":"24 templates","heading":"24 templates","text":"","code":""},{"path":"templates.html","id":"matrix-analyses","chapter":"24 templates","heading":"24.1 matrix analyses","text":"","code":""},{"path":"templates.html","id":"basic-runmatrixanalysis-template","chapter":"24 templates","heading":"24.1.1 basic runMatrixAnalysis() template","text":"","code":"\n\nrunMatrixAnalysis(\n                \n  data = NULL,\n\n  analysis = c(\"hclust\", \"pca\", \"pca_ord\", \"pca_dim\"),\n\n  column_w_names_of_multiple_analytes = NULL,\n  column_w_values_for_multiple_analytes = NULL,\n    \n  columns_w_values_for_single_analyte = NULL,\n\n  columns_w_sample_ID_info = NULL\n\n)"},{"path":"templates.html","id":"advanced-runmatrixanalysis-template","chapter":"24 templates","heading":"24.1.2 advanced runMatrixAnalysis() template","text":"","code":"\n\nrunMatrixAnalysis(\n  data = NULL, # the data set to work on\n  analysis = c(\"hclust\", \"pca\", \"pca_ord\", \"pca_dim\"), # the analysis to conduct\n  column_w_names_of_multiple_analytes = NULL, # a column with names of multiple analytes\n  column_w_values_for_multiple_analytes = NULL, # a column with quantities measured for multiple analytes\n  columns_w_values_for_single_analyte = NULL, # a column with quantities measured for a single analyte\n  columns_w_additional_analyte_info = NULL, # a column with character or numeric information about analytes that was not \"measured\" as part of the experiment.\n  columns_w_sample_ID_info = NULL, # a column with information about the sample (i.e. contents from the test tube's label)\n  transpose = FALSE,\n  kmeans = c(\"none\", \"auto\", \"elbow\", \"1\", \"2\", \"3\", \"etc.\"),\n  na_replacement = c(\"none\", \"mean\", \"zero\", \"drop\")\n)"}]
